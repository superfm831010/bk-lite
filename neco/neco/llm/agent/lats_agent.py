import math
import time
from collections import deque
from dataclasses import dataclass
from enum import Enum
from typing import TypedDict, Annotated, Optional, List, Tuple, Dict, Any

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig
from langgraph.constants import END
from langgraph.graph import StateGraph, add_messages
from pydantic import BaseModel, Field, ConfigDict
from loguru import logger

from neco.core.utils.template_loader import TemplateLoader
from neco.llm.chain.entity import BasicLLMRequest, BasicLLMResponse
from neco.llm.chain.graph import BasicGraph
from neco.llm.chain.node import ToolsNodes

class LatsAgentResponse(BasicLLMResponse):
    pass


class LatsAgentRequest(BasicLLMRequest):
    pass

class SearchStrategy(Enum):
    """æœç´¢ç­–ç•¥æšä¸¾"""
    PURE_LATS = "pure_lats"              # çº¯LATSæ ‘æœç´¢

class SearchPhase(Enum):
    """æœç´¢é˜¶æ®µæšä¸¾"""
    INITIALIZATION = "initialization"
    COMPLETED = "completed"

@dataclass
class LATSConfig:
    """LATSæœç´¢å¼•æ“é…ç½®"""
    # æœç´¢å‚æ•°
    max_candidates: int = 3              # æ¯æ¬¡æ‰©å±•çš„å€™é€‰æ•°é‡
    max_tree_depth: int = 3              # æœ€å¤§æœç´¢æ·±åº¦
    exploration_weight: float = 1.414    # UCBæ¢ç´¢æƒé‡(âˆš2)
    
    # è´¨é‡é˜ˆå€¼
    solution_threshold: float = 8.0      # è§£å†³æ–¹æ¡ˆåˆ†æ•°é˜ˆå€¼
    early_stop_threshold: float = 9.0    # æ—©åœåˆ†æ•°é˜ˆå€¼
    
    # æ€§èƒ½é…ç½®
    max_search_time: float = 20.0        # æœ€å¤§æœç´¢æ—¶é—´(ç§’)
    enable_pruning: bool = True          # å¯ç”¨æœç´¢å‰ªæ

class MultiDimensionalReflection(BaseModel):
    """å¤šç»´åº¦åæ€è¯„ä¼°æ¨¡å‹"""
    model_config = ConfigDict(arbitrary_types_allowed=True)
    
    # æ ¸å¿ƒè¯„ä¼°ç»´åº¦
    accuracy: float = Field(ge=0, le=10, description="ç­”æ¡ˆå‡†ç¡®æ€§è¯„åˆ†")
    completeness: float = Field(ge=0, le=10, description="ç­”æ¡ˆå®Œæ•´æ€§è¯„åˆ†")
    relevance: float = Field(ge=0, le=10, description="ç­”æ¡ˆç›¸å…³æ€§è¯„åˆ†")
    clarity: float = Field(ge=0, le=10, description="è¡¨è¾¾æ¸…æ™°åº¦è¯„åˆ†")
    
    # é«˜çº§è¯„ä¼°ç»´åº¦
    creativity: float = Field(ge=0, le=10, description="åˆ›æ–°æ€§å’Œç‹¬ç‰¹è§è§£")
    actionability: float = Field(ge=0, le=10, description="å¯æ‰§è¡Œæ€§å’Œå®ç”¨æ€§")
    
    # ç»¼åˆè¯„ä¼°
    overall_score: float = Field(ge=0, le=10, description="åŠ æƒç»¼åˆè¯„åˆ†")
    confidence: float = Field(ge=0, le=1, description="è¯„ä¼°ç½®ä¿¡åº¦")
    
    # åæ€å†…å®¹
    strengths: List[str] = Field(description="å›ç­”çš„ä¼˜ç‚¹")
    weaknesses: List[str] = Field(description="å›ç­”çš„ä¸è¶³")
    suggestions: List[str] = Field(description="æ”¹è¿›å»ºè®®")
    
    # å†³ç­–æ ‡å¿—
    found_solution: bool = Field(description="æ˜¯å¦æ‰¾åˆ°æ»¡æ„è§£å†³æ–¹æ¡ˆ")
    needs_tools: bool = Field(description="æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨")
    
    def as_message(self) -> HumanMessage:
        """è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼ç”¨äºä¸Šä¸‹æ–‡ä¼ é€’"""
        reflection_text = f"""
        **è¯„ä¼°ç»“æœ** (ç½®ä¿¡åº¦: {self.confidence:.2f})
        - å‡†ç¡®æ€§: {self.accuracy}/10 | å®Œæ•´æ€§: {self.completeness}/10
        - ç›¸å…³æ€§: {self.relevance}/10 | æ¸…æ™°åº¦: {self.clarity}/10
        - åˆ›æ–°æ€§: {self.creativity}/10 | å®ç”¨æ€§: {self.actionability}/10
        
        **ç»¼åˆè¯„åˆ†**: {self.overall_score}/10
        
        **ä¼˜ç‚¹**: {'; '.join(self.strengths)}
        **ä¸è¶³**: {'; '.join(self.weaknesses)}
        **å»ºè®®**: {'; '.join(self.suggestions)}
        """
        return HumanMessage(content=reflection_text.strip())
    
    @property
    def normalized_score(self) -> float:
        return self.overall_score / 10.0
    
    @classmethod
    def create_default(cls, basic_score: float = 5.0) -> "MultiDimensionalReflection":
        """åˆ›å»ºé»˜è®¤è¯„ä¼°ç»“æœ"""
        return cls(
            accuracy=basic_score,
            completeness=basic_score, 
            relevance=basic_score,
            clarity=basic_score,
            creativity=basic_score * 0.8,
            actionability=basic_score * 0.9,
            overall_score=basic_score,
            confidence=0.6,
            strengths=["åŸºç¡€å›ç­”ç»“æ„åˆç†"],
            weaknesses=["éœ€è¦æ›´æ·±å…¥åˆ†æ"],
            suggestions=["å¢åŠ å…·ä½“ç»†èŠ‚å’Œä¾‹è¯"],
            found_solution=basic_score >= 7.0,
            needs_tools=False
        )


class LATSTreeNode:
    """LATSæ ‘æœç´¢èŠ‚ç‚¹ - ä¸“ä¸šåŒ–å®ç°"""
    
    def __init__(
            self,
            messages: List[BaseMessage],
            reflection: MultiDimensionalReflection,
            parent: Optional["LATSTreeNode"] = None,
            node_id: str = None,
    ):
        self.messages = messages
        self.parent = parent
        self.children: List["LATSTreeNode"] = []
        self.reflection = reflection
        
        # èŠ‚ç‚¹æ ‡è¯†å’Œå±‚çº§
        self.node_id = node_id or f"node_{id(self)}"
        self.depth = parent.depth + 1 if parent is not None else 1
        
        # MCTSç»Ÿè®¡ä¿¡æ¯
        self.visits = 0
        self.total_reward = 0.0
        self.average_reward = 0.0
        
        # çŠ¶æ€æ ‡å¿—
        self._is_solved = reflection.found_solution if reflection else False
        self._creation_time = time.time()
        
        # åˆå§‹åŒ–æ—¶è¿›è¡Œåå‘ä¼ æ’­
        if self._is_solved:
            self._mark_tree_as_solved()
        self.backpropagate(reflection.normalized_score)

    def __repr__(self) -> str:
        return (
            f"<LATSTreeNode id={self.node_id}, depth={self.depth}, "
            f"visits={self.visits}, avg_reward={self.average_reward:.3f}, "
            f"solved={self.is_solved}>"
        )

    @property
    def is_solved(self) -> bool:
        """èŠ‚ç‚¹æ˜¯å¦å·²æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ"""
        return self._is_solved

    @property
    def is_terminal(self) -> bool:
        """èŠ‚ç‚¹æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹"""
        return not self.children

    @property
    def is_fully_expanded(self) -> bool:
        """èŠ‚ç‚¹æ˜¯å¦å·²å®Œå…¨æ‰©å±•(æœ‰å…·ä½“çš„å®ç°ä¾æ®)"""
        # ç®€å•å¯å‘å¼ï¼šå¦‚æœæœ‰5ä¸ªæˆ–æ›´å¤šå­èŠ‚ç‚¹ï¼Œè®¤ä¸ºå·²å……åˆ†æ‰©å±•
        return len(self.children) >= 5

    @property
    def best_child(self) -> Optional["LATSTreeNode"]:
        """è¿”å›æœ€ä½³å­èŠ‚ç‚¹"""
        if not self.children:
            return None
        return max(
            self.children,
            key=lambda child: (
                int(child.is_solved) * 100 +  # ä¼˜å…ˆè€ƒè™‘è§£å†³æ–¹æ¡ˆ
                child.average_reward * 10 +    # ç„¶åè€ƒè™‘è´¨é‡
                child.reflection.confidence    # æœ€åè€ƒè™‘ç½®ä¿¡åº¦
            )
        )

    @property
    def height(self) -> int:
        """è¿”å›ä»¥æ­¤èŠ‚ç‚¹ä¸ºæ ¹çš„å­æ ‘é«˜åº¦"""
        if not self.children:
            return 1
        return 1 + max(child.height for child in self.children)

    @property
    def tree_size(self) -> int:
        """è¿”å›ä»¥æ­¤èŠ‚ç‚¹ä¸ºæ ¹çš„å­æ ‘å¤§å°"""
        if not self.children:
            return 1
        return 1 + sum(child.tree_size for child in self.children)

    def upper_confidence_bound(self, exploration_weight: float = 1.414) -> float:
        """è®¡ç®—UCBå€¼ï¼Œå¹³è¡¡æ¢ç´¢ä¸å¼€å‘"""
        if self.parent is None:
            raise ValueError("æ ¹èŠ‚ç‚¹æ— æ³•è®¡ç®—UCBå€¼")
        
        if self.visits == 0:
            return float('inf')  # æœªè®¿é—®èŠ‚ç‚¹ä¼˜å…ˆçº§æœ€é«˜
        
        # UCB1å…¬å¼: avg_reward + c * sqrt(ln(parent_visits) / visits)
        exploitation_term = self.average_reward
        exploration_term = exploration_weight * math.sqrt(
            math.log(self.parent.visits) / self.visits
        )
        
        # åŠ å…¥å¤šç»´åº¦å¥–åŠ±
        quality_bonus = self.reflection.confidence * 0.1
        
        return exploitation_term + exploration_term + quality_bonus

    def backpropagate(self, reward: float) -> None:
        """åå‘ä¼ æ’­å¥–åŠ±å€¼åˆ°æ‰€æœ‰ç¥–å…ˆèŠ‚ç‚¹"""
        current_node = self
        
        while current_node is not None:
            current_node.visits += 1
            current_node.total_reward += reward
            current_node.average_reward = current_node.total_reward / current_node.visits
            current_node = current_node.parent

    def get_messages(self, include_reflections: bool = True) -> List[BaseMessage]:
        """è·å–èŠ‚ç‚¹æ¶ˆæ¯ï¼Œå¯é€‰æ‹©æ˜¯å¦åŒ…å«åæ€"""
        if include_reflections and self.reflection:
            return self.messages + [self.reflection.as_message()]
        return self.messages.copy()

    def get_trajectory(self, include_reflections: bool = True) -> List[BaseMessage]:
        """è·å–ä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹çš„å®Œæ•´è½¨è¿¹"""
        trajectory = []
        path_nodes = []
        
        # æ”¶é›†è·¯å¾„ä¸Šçš„æ‰€æœ‰èŠ‚ç‚¹
        current_node = self
        while current_node is not None:
            path_nodes.append(current_node)
            current_node = current_node.parent
        
        # ä»æ ¹å¼€å§‹æ„å»ºè½¨è¿¹
        for node in reversed(path_nodes):
            trajectory.extend(node.get_messages(include_reflections))
        
        return trajectory

    def get_all_descendants(self) -> List["LATSTreeNode"]:
        """è·å–æ‰€æœ‰åä»£èŠ‚ç‚¹"""
        descendants = []
        queue = deque(self.children)
        
        while queue:
            node = queue.popleft()
            descendants.append(node)
            queue.extend(node.children)
        
        return descendants

    def get_best_solution_node(self) -> Optional["LATSTreeNode"]:
        """åœ¨å½“å‰å­æ ‘ä¸­å¯»æ‰¾æœ€ä½³è§£å†³æ–¹æ¡ˆèŠ‚ç‚¹"""
        all_nodes = [self] + self.get_all_descendants()
        
        # ç­›é€‰å·²è§£å†³çš„ç»ˆç«¯èŠ‚ç‚¹
        solution_nodes = [
            node for node in all_nodes 
            if node.is_solved and node.is_terminal
        ]
        
        if not solution_nodes:
            return None
            
        # è¿”å›ç»¼åˆè¯„åˆ†æœ€é«˜çš„è§£å†³æ–¹æ¡ˆ
        return max(
            solution_nodes,
            key=lambda node: (
                node.reflection.overall_score * 10 +
                node.reflection.confidence * 5 +
                node.visits  # è®¿é—®æ¬¡æ•°ä½œä¸ºtie-breaker
            )
        )

    def _mark_tree_as_solved(self) -> None:
        """å°†æ•´ä¸ªè·¯å¾„æ ‡è®°ä¸ºå·²è§£å†³"""
        current_node = self.parent
        while current_node is not None:
            current_node._is_solved = True
            current_node = current_node.parent

    def prune_low_quality_children(self, threshold: float = 0.3) -> int:
        """å‰ªæä½è´¨é‡å­èŠ‚ç‚¹ï¼Œè¿”å›è¢«å‰ªæçš„èŠ‚ç‚¹æ•°"""
        if not self.children:
            return 0
            
        initial_count = len(self.children)
        self.children = [
            child for child in self.children
            if child.average_reward >= threshold or child.is_solved
        ]
        
        pruned_count = initial_count - len(self.children)
        if pruned_count > 0:
            logger.debug(f"èŠ‚ç‚¹ {self.node_id} å‰ªæäº† {pruned_count} ä¸ªä½è´¨é‡å­èŠ‚ç‚¹")
        
        return pruned_count


class LATSAgentState(TypedDict):
    """ä¸“ä¸šåŒ–LATS AgentçŠ¶æ€ç®¡ç†"""
    messages: Annotated[List[BaseMessage], add_messages]
    graph_request: LatsAgentRequest
    
    # LATSæ ‘æœç´¢çŠ¶æ€
    root: Optional[LATSTreeNode]
    current_phase: SearchPhase
    search_config: LATSConfig
    
    # æœç´¢ç»Ÿè®¡
    search_start_time: float
    total_evaluations: int
    best_score_so_far: float
    
    # ä¸­é—´ç»“æœ
    intermediate_results: List[Dict[str, Any]]
    tool_execution_needed: bool


class LatsAgentNode(ToolsNodes):
    """LATS Agent - ä¸“ä¸šåŒ–æ ‘æœç´¢æ‰§è¡ŒèŠ‚ç‚¹"""

    async def _evaluate_candidate(
        self, 
        user_input: str, 
        candidate_messages: List[BaseMessage], 
        config: RunnableConfig,
        search_config: LATSConfig
    ) -> MultiDimensionalReflection:
        """é«˜çº§å¤šç»´åº¦å€™é€‰æ–¹æ¡ˆè¯„ä¼°"""
        try:
            # æå–å€™é€‰å›ç­”å†…å®¹
            contents = []
            for msg in candidate_messages:
                if hasattr(msg, 'content') and msg.content:
                    contents.append(str(msg.content))
            candidate_content = "\n\n".join(contents) if contents else "ç©ºå›ç­”"
            
            # æ™ºèƒ½è·å–è¯„ä¼°æ ‡å‡†
            evaluation_criteria = "å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€æ¸…æ™°åº¦ã€å®ç”¨æ€§"  # é»˜è®¤æ ‡å‡†
            try:
                from pydantic import BaseModel
                
                class EvaluationCriteria(BaseModel):
                    question_type: str = Field(description="é—®é¢˜ç±»å‹ï¼šæ—¶é—´æŸ¥è¯¢ç±»ã€æ–¹æ³•æŒ‡å¯¼ç±»ã€åŸå› è§£é‡Šç±»ã€é€šç”¨é—®ç­”ç±»")
                    criteria: str = Field(description="å¯¹åº”çš„è¯„ä¼°æ ‡å‡†å…³é”®è¯")
                
                criteria_prompt = f"""
                è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜çš„ç±»å‹ï¼Œå¹¶æä¾›ç›¸åº”çš„è¯„ä¼°æ ‡å‡†ã€‚

                ç”¨æˆ·é—®é¢˜ï¼š{user_input}

                è¯·ä»ä»¥ä¸‹ç±»å‹ä¸­é€‰æ‹©æœ€ç¬¦åˆçš„ï¼š
                1. æ—¶é—´æŸ¥è¯¢ç±»ï¼šæ—¶é—´æŸ¥è¯¢å‡†ç¡®æ€§ã€å®æ—¶æ€§ã€æ ¼å¼è§„èŒƒæ€§
                2. æ–¹æ³•æŒ‡å¯¼ç±»ï¼šæ–¹æ³•å®Œæ•´æ€§ã€å¯æ“ä½œæ€§ã€æ­¥éª¤æ¸…æ™°åº¦
                3. åŸå› è§£é‡Šç±»ï¼šè§£é‡Šæ·±åº¦ã€é€»è¾‘æ€§ã€ä¾‹è¯å……åˆ†æ€§
                4. é€šç”¨é—®ç­”ç±»ï¼šå‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€æ¸…æ™°åº¦ã€å®ç”¨æ€§
                """
                
                criteria_result = await self.structured_output_parser.parse_with_structured_output(
                    user_message=criteria_prompt,
                    pydantic_class=EvaluationCriteria
                )
                evaluation_criteria = criteria_result.criteria
                
            except Exception as e:
                logger.warning(f"æ™ºèƒ½è¯„ä¼°æ ‡å‡†è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†: {e}")
            
            # æ„å»ºè¯„ä¼°æç¤º
            evaluation_prompt = TemplateLoader.render_template(
                "prompts/lats_agent/multi_dimensional_evaluation",
                {
                    "user_question": user_input,
                    "candidate_answer": candidate_content,
                    "evaluation_criteria": evaluation_criteria
                }
            )

            # æ‰§è¡Œå¤šç»´åº¦è¯„ä¼°
            result = await self.structured_output_parser.parse_with_structured_output(
                user_message=evaluation_prompt,
                pydantic_class=MultiDimensionalReflection
            )
            
            # è®¾ç½®æ ‡å¿—
            result.needs_tools = False
            if result.overall_score >= search_config.solution_threshold:
                result.found_solution = True
            
            logger.debug(f"å€™é€‰è¯„ä¼°å®Œæˆ: {result.overall_score:.2f}/10 (ç½®ä¿¡åº¦: {result.confidence:.2f})")
            return result
            
        except Exception as e:
            logger.warning(f"å¤šç»´åº¦è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„ä¼°: {e}")
            return MultiDimensionalReflection.create_default(6.0)

    def select_node_for_expansion(self, root: LATSTreeNode, config: LATSConfig) -> LATSTreeNode:
        """ä½¿ç”¨æ”¹è¿›çš„UCBç®—æ³•é€‰æ‹©æ‰©å±•èŠ‚ç‚¹"""
        if not root.children:
            return root

        current = root
        selection_path = [root]
        
        # æ²¿ç€UCBå€¼æœ€é«˜çš„è·¯å¾„å‘ä¸‹é€‰æ‹©
        while current.children:
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰©å±•å½“å‰èŠ‚ç‚¹
            should_expand = (
                not current.is_solved and 
                current.depth < config.max_tree_depth and 
                (current.visits < 3 or len(current.children) < config.max_candidates)
            )
            
            if not should_expand and current.is_fully_expanded:
                # å·²å……åˆ†æ‰©å±•ï¼Œç»§ç»­å‘ä¸‹é€‰æ‹©
                best_child = max(
                    current.children,
                    key=lambda child: child.upper_confidence_bound(config.exploration_weight)
                )
                current = best_child
                selection_path.append(current)
            else:
                break
        
        logger.debug(
            f"MCTSé€‰æ‹©è·¯å¾„: {' -> '.join(f'Node{i}' for i in range(len(selection_path)))}, "
            f"æœ€ç»ˆé€‰æ‹©æ·±åº¦: {current.depth}"
        )
        return current

    async def _process_candidates_with_evaluation(
        self,
        candidates: List[BaseMessage],
        user_message: str,
        config: RunnableConfig,
        search_config: LATSConfig
    ) -> Tuple[List[List[BaseMessage]], List[MultiDimensionalReflection]]:
        """å¤„ç†å’Œè¯„ä¼°å€™é€‰æ–¹æ¡ˆ"""
        
        candidate_message_lists = [[candidate] for candidate in candidates]
        progress_messages = config.setdefault('progress_messages', [])
        
        # æ˜¾ç¤ºè¯„ä¼°å¼€å§‹ä¿¡æ¯
        eval_start_msg = f"\n\nğŸ“Š **è¯„ä¼° {len(candidates)} ä¸ªå€™é€‰æ–¹æ¡ˆ**\n\n"
        progress_messages.append(AIMessage(content=eval_start_msg))

        # ä¸²è¡Œè¯„ä¼°æ‰€æœ‰å€™é€‰æ–¹æ¡ˆ
        valid_reflections = []
        
        for i, messages in enumerate(candidate_message_lists):
            eval_progress_msg = f"\n\nğŸ“Š **è¯„ä¼°å€™é€‰ {i+1}/{len(candidate_message_lists)}**\n\n"
            progress_messages.append(AIMessage(content=eval_progress_msg))
            
            try:
                reflection = await self._evaluate_candidate(
                    user_message, messages, config, search_config
                )
                valid_reflections.append(reflection)
                
                eval_result_msg = f"\n\nâœ… å€™é€‰ {i+1}: **{reflection.overall_score:.1f}/10**\n\n"
                progress_messages.append(AIMessage(content=eval_result_msg))
                
            except Exception as e:
                logger.warning(f"å€™é€‰ {i+1} è¯„ä¼°å¤±è´¥: {e}")
                fallback_reflection = MultiDimensionalReflection.create_default(4.0)
                valid_reflections.append(fallback_reflection)
                
                eval_result_msg = f"\n\nâš ï¸ å€™é€‰ {i+1}: **{fallback_reflection.overall_score:.1f}/10** (é™çº§è¯„ä¼°)\n\n"
                progress_messages.append(AIMessage(content=eval_result_msg))

        # è®°å½•è¯„ä¼°æ‘˜è¦
        if valid_reflections:
            scores = [r.overall_score for r in valid_reflections]
            confidences = [r.confidence for r in valid_reflections]
            solved_count = sum(1 for r in valid_reflections if r.found_solution)
            
            logger.info(
                f"ğŸ“Š å¤šç»´åº¦è¯„ä¼°å®Œæˆ | "
                f"å€™é€‰æ•°: {len(valid_reflections)} | "
                f"è´¨é‡åˆ†å¸ƒ: æœ€é«˜{max(scores):.1f} å¹³å‡{sum(scores)/len(scores):.1f} æœ€ä½{min(scores):.1f} | "
                f"å¹³å‡ç½®ä¿¡åº¦: {sum(confidences)/len(confidences):.2f} | "
                f"è§£å†³æ–¹æ¡ˆ: {solved_count}ä¸ª"
            )

        # åº”ç”¨æ—©åœç­–ç•¥
        for reflection in valid_reflections:
            if reflection.overall_score >= search_config.early_stop_threshold:
                reflection.found_solution = True
                logger.info(f"ğŸ¯ è¾¾åˆ°æ—©åœé˜ˆå€¼ {search_config.early_stop_threshold}ï¼Œæ ‡è®°ä¸ºè§£å†³æ–¹æ¡ˆ")

        return candidate_message_lists, valid_reflections

    async def _generate_candidates(self, user_message: str, messages: List[BaseMessage], config: RunnableConfig) -> List[BaseMessage]:
        """ç”Ÿæˆå€™é€‰æ–¹æ¡ˆ - ä½¿ç”¨ ReAct æ¨¡å¼"""
        
        # ä»é…ç½®è·å–å€™é€‰æ•°é‡
        search_config = config.get('configurable', {}).get('search_config', LATSConfig())
        max_candidates = getattr(search_config, 'max_candidates', 3)
        
        # ä½¿ç”¨å€™é€‰ç”Ÿæˆæ¨¡æ¿
        system_message = TemplateLoader.render_template(
            "prompts/lats_agent/candidate_generation",
            {
                "user_question": user_message,
                "context_length": len(messages)
            }
        )
        
        # ç”Ÿæˆå¤šä¸ªå€™é€‰æ–¹æ¡ˆ
        candidates = []
        progress_messages = []
        
        for i in range(max_candidates):
            progress_msg = f"\n\nğŸ” **ç”Ÿæˆå€™é€‰æ–¹æ¡ˆ {i+1}/{max_candidates}**\n\n"
            progress_messages.append(AIMessage(content=progress_msg))
            
            logger.debug(f"ä½¿ç”¨ ReAct æ¨¡å¼ç”Ÿæˆç¬¬ {i+1}/{max_candidates} ä¸ªå€™é€‰æ–¹æ¡ˆ")
            candidate = await self.invoke_react_for_candidate(user_message, messages, config, system_message)
            candidates.append(candidate)
        
        config.setdefault('progress_messages', []).extend(progress_messages)
        return candidates

    async def expand(self, state: LATSAgentState, config: RunnableConfig) -> LATSAgentState:
        """æ‰©å±•æœç´¢æ ‘"""
        logger.info("ğŸŒ³ å¼€å§‹æ‰©å±•æœç´¢æ ‘")

        search_depth = state["root"].height if state["root"] else 0
        search_start_msg = f"ğŸ” **ç¬¬ {search_depth + 1} è½®ä¼˜åŒ–æœç´¢**"
        
        root = state["root"]
        if not root:
            logger.error("æœç´¢æ ‘æ ¹èŠ‚ç‚¹æœªåˆå§‹åŒ–")
            return state

        best_candidate = self.select_node_for_expansion(root, state.get("search_config", LATSConfig()))
        messages = best_candidate.get_trajectory()

        config['progress_messages'] = [AIMessage(content=search_start_msg)]

        user_message = config["configurable"]["graph_request"].user_message
        new_candidates = await self._generate_candidates(user_message, messages, config)

        output_messages, reflections = await self._process_candidates_with_evaluation(
            new_candidates, user_message, config, state.get("search_config", LATSConfig())
        )
        
        progress_messages = config.get('progress_messages', [])
        search_config = state.get("search_config", LATSConfig())

        # æ‰©å±•æœç´¢æ ‘
        child_nodes = [
            LATSTreeNode(messages=cand, reflection=reflection, parent=best_candidate)
            for cand, reflection in zip(output_messages, reflections)
        ]
        best_candidate.children.extend(child_nodes)

        best_score = max((r.overall_score for r in reflections), default=0)
        eval_summary_msg = f"\n\nğŸ¯ **æœ€ä½³è¯„åˆ†: {best_score:.1f}/10** {'âœ¨' if best_score >= 8.0 else 'ğŸ” ç»§ç»­ä¼˜åŒ–...'}\n\n"
        progress_messages.append(AIMessage(content=eval_summary_msg))
        
        # æ£€æŸ¥è§£å†³æ–¹æ¡ˆ - ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ ‡å‡†
        solution_nodes = [node for node, r in zip(child_nodes, reflections) 
                         if r.found_solution and r.overall_score >= search_config.solution_threshold]
        
        if solution_nodes:
            best_solution = max(solution_nodes, key=lambda node: node.reflection.overall_score)
            logger.info(f"ğŸ‰ æ‰¾åˆ°é«˜è´¨é‡è§£å†³æ–¹æ¡ˆ! è¯„åˆ†: {best_solution.reflection.overall_score}/10")
            
            # åªæœ‰çœŸæ­£é«˜è´¨é‡çš„è§£å†³æ–¹æ¡ˆæ‰æ ‡è®°ä¸ºå·²è§£å†³
            root._is_solved = True
            messages_to_add = progress_messages
        else:
            # ä¸è¦åœ¨è¿™é‡Œæ·»åŠ æœ€ç»ˆç­”æ¡ˆï¼Œè®©æœç´¢ç»§ç»­è¿›è¡Œ
            messages_to_add = progress_messages
            logger.info(f"ğŸ” å½“å‰æœ€ä½³è¯„åˆ† {best_score:.1f}ï¼Œç»§ç»­æœç´¢æ›´ä¼˜æ–¹æ¡ˆ")

        return {
            **state,
            "messages": state.get("messages", []) + messages_to_add
        }

    async def generate_final_answer(self, state: LATSAgentState, config: RunnableConfig) -> dict:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹"""
        logger.info("ğŸ“ ç”Ÿæˆæœ€ç»ˆæ€»ç»“ç­”æ¡ˆ")

        root = state["root"]
        
        # æ‰¾åˆ°æœ€ä½³è§£å†³æ–¹æ¡ˆèŠ‚ç‚¹
        best_solution_node = root.get_best_solution_node()
        if not best_solution_node:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„è§£å†³æ–¹æ¡ˆï¼Œé€‰æ‹©è¯„åˆ†æœ€é«˜çš„èŠ‚ç‚¹
            all_nodes = [root] + root.get_all_descendants()
            best_solution_node = max(all_nodes, key=lambda node: node.reflection.overall_score)
            logger.info(f"ä½¿ç”¨è¯„åˆ†æœ€é«˜çš„èŠ‚ç‚¹ä½œä¸ºæœ€ç»ˆæ–¹æ¡ˆ: {best_solution_node.reflection.overall_score}/10")
        
        # è·å–æœ€ä½³è§£å†³æ–¹æ¡ˆçš„å®Œæ•´è½¨è¿¹
        solution_trajectory = best_solution_node.get_trajectory(include_reflections=False)
        
        # æå–æœ€åä¸€ä¸ªAIå›ç­”ä½œä¸ºæ ¸å¿ƒå†…å®¹
        final_solution_content = ""
        for msg in reversed(solution_trajectory):
            if isinstance(msg, AIMessage) and msg.content and not msg.content.startswith("ğŸ”") and not msg.content.startswith("ğŸ“Š"):
                final_solution_content = msg.content
                break
        
        if not final_solution_content:
            final_solution_content = "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆæ»¡æ„çš„ç­”æ¡ˆã€‚"
        
        # ç”Ÿæˆæœ€ç»ˆç»¼åˆç­”æ¡ˆ
        system_message = TemplateLoader.render_template("prompts/lats_agent/intelligent_assistant")
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="messages", optional=True),
        ])

        user_question = config['configurable']['graph_request'].user_message

        question = TemplateLoader.render_template(
            "prompts/lats_agent/final_answer_synthesis",
            {
                "user_question": user_question,
                "solution_content": final_solution_content
            }
        )

        chain = prompt_template | self.llm
        final_answer = await chain.ainvoke({"input": question})

        logger.info("âœ… æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå®Œæˆ")
        return {
            **state,
            "messages": state.get("messages", []) + [final_answer]
        }

    def should_continue(self, state: LATSAgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æœç´¢æˆ–è¿›å…¥æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ"""
        root = state.get("root")
        
        # å¦‚æœæœ‰æ ¹èŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ
        if root and root.is_solved:
            logger.info("âœ… å·²æ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return "generate_final_answer"
        
        # æ£€æŸ¥æœç´¢æ·±åº¦å’Œæ—¶é—´
        search_config = state.get('search_config', LATSConfig())
        elapsed_time = time.time() - state.get("search_start_time", time.time())
        
        if root and root.height >= search_config.max_tree_depth:
            logger.info(f"â¹ï¸ è¾¾åˆ°æœ€å¤§æœç´¢æ·±åº¦ {search_config.max_tree_depth}ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return "generate_final_answer"
        
        if elapsed_time >= search_config.max_search_time:
            logger.info(f"â° è¾¾åˆ°æœ€å¤§æœç´¢æ—¶é—´ {search_config.max_search_time}sï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return "generate_final_answer"
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰èŠ‚ç‚¹çš„è¯„åˆ†éƒ½å¤ªä½ï¼Œé¿å…æ— é™æœç´¢
        if root:
            all_nodes = [root] + root.get_all_descendants()
            best_score = max(node.reflection.overall_score for node in all_nodes)
            if best_score < 5.0 and root.height >= 2:
                logger.info(f"âš ï¸ æœç´¢è´¨é‡ä¸ä½³ (æœ€ä½³: {best_score}/10)ï¼Œæå‰ç»“æŸ")
                return "generate_final_answer"
        
        logger.info("ğŸŒ³ ç»§ç»­æ‰©å±•æœç´¢æ ‘")
        return "expand"

    async def generate_initial_response(self, state: LATSAgentState, config: RunnableConfig) -> dict:
        """ç”Ÿæˆåˆå§‹å“åº” - ä½¿ç”¨ ReAct æ¨¡å¼ç”Ÿæˆç¬¬ä¸€ä¸ªå€™é€‰å¹¶è¯„ä¼°"""
        request = config['configurable']['graph_request']
        user_message = request.user_message
        
        # ç®€åŒ–çŠ¶æ€åˆå§‹åŒ–
        state['search_config'] = LATSConfig()
        state['search_start_time'] = time.time()
        state['current_phase'] = SearchPhase.INITIALIZATION

        progress_start_msg = AIMessage(content="\n\nğŸ§  **æ™ºèƒ½åˆ†æä¸­...**\n\n")
        
        system_message = TemplateLoader.render_template("prompts/lats_agent/initial_response")
        
        initial_candidate = await self.invoke_react_for_candidate(
            user_message, 
            state.get("messages", []), 
            config, 
            system_message
        )

        eval_progress_msg = AIMessage(content="\n\nğŸ“Š **è¯„ä¼°ç­”æ¡ˆè´¨é‡**\n\n")

        search_config = state.get('search_config', LATSConfig())
        output_messages = [initial_candidate]
        reflection = await self._evaluate_candidate(user_message, output_messages, config, search_config)
        
        root = LATSTreeNode(messages=output_messages, reflection=reflection)
        state['root'] = root
        
        logger.info(f"ğŸ“Š åˆå§‹å“åº”è¯„ä¼°å®Œæˆ | è¯„åˆ†: {reflection.overall_score}/10 | è§£å†³æ–¹æ¡ˆ: {reflection.found_solution}")
        
        # ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ ‡å‡†åˆ¤æ–­æ˜¯å¦ä¸ºè§£å†³æ–¹æ¡ˆ
        is_high_quality_solution = (reflection.found_solution and 
                                   reflection.overall_score >= search_config.solution_threshold and
                                   reflection.confidence >= 0.8)
        
        if is_high_quality_solution:
            eval_result_msg = AIMessage(content=f"\n\nâœ… **åˆå§‹è¯„åˆ†: {reflection.overall_score:.1f}/10** ğŸ‰\n\n")
            messages_to_add = [progress_start_msg, eval_progress_msg, eval_result_msg, initial_candidate]
            # æ ‡è®°ä¸ºå·²è§£å†³
            root._is_solved = True
        else:
            eval_result_msg = AIMessage(content=f"\n\nâœ… **åˆå§‹è¯„åˆ†: {reflection.overall_score:.1f}/10** \n\nğŸ” å¯»æ‰¾æ›´ä¼˜æ–¹æ¡ˆ...\n\n")
            messages_to_add = [progress_start_msg, eval_progress_msg, initial_candidate, eval_result_msg]
        
        return {
            **state,
            "messages": state.get("messages", []) + messages_to_add
        }




class LatsAgentGraph(BasicGraph):
    """LATS Agent å›¾æ‰§è¡Œå™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""

    async def compile_graph(self, request: LatsAgentRequest) -> StateGraph:
        # åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆæœ¬çš„èŠ‚ç‚¹æ„å»ºå™¨
        node_builder = LatsAgentNode()
        await node_builder.setup(request)

        # åˆ›å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(LATSAgentState)

        # æ·»åŠ åŸºç¡€å›¾ç»“æ„
        last_edge = self.prepare_graph(graph_builder, node_builder)

        # æ·»åŠ  LATS ç‰¹æœ‰èŠ‚ç‚¹
        graph_builder.add_node("generate_initial_response",
                               node_builder.generate_initial_response)
        graph_builder.add_node("expand", node_builder.expand)
        graph_builder.add_node("generate_final_answer",
                               node_builder.generate_final_answer)

        # æ„å»ºæ‰§è¡Œæµç¨‹ - æ ‡å‡† LATS æµç¨‹
        graph_builder.add_edge(last_edge, 'generate_initial_response')
        
        # åˆå§‹å“åº”åæ ¹æ®è¯„ä¼°ç»“æœå†³å®š
        graph_builder.add_conditional_edges(
            "generate_initial_response",
            node_builder.should_continue,
            {
                "expand": "expand",
                "generate_final_answer": "generate_final_answer"
            }
        )
        
        # æ‰©å±•æœç´¢åçš„æ¡ä»¶åˆ†æ”¯
        graph_builder.add_conditional_edges(
            "expand", 
            node_builder.should_continue,
            {
                "expand": "expand",
                "generate_final_answer": "generate_final_answer"
            }
        )

        # æœ€ç»ˆç­”æ¡ˆç”Ÿæˆåç»“æŸ
        graph_builder.add_edge("generate_final_answer", END)

        # ç¼–è¯‘å¹¶è¿”å›å›¾
        compiled_graph = graph_builder.compile()
        logger.info("âœ… LATS Agent æ‰§è¡Œå›¾ç¼–è¯‘å®Œæˆ")

        return compiled_graph
