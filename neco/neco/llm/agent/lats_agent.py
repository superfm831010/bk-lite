import asyncio
import math
import time
from collections import deque
from dataclasses import dataclass
from enum import Enum
from typing import TypedDict, Annotated, Optional, List, Tuple, Dict, Any, Union
from concurrent.futures import ThreadPoolExecutor

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig
from langgraph.constants import END
from langgraph.graph import StateGraph, add_messages
from pydantic import BaseModel, Field, ConfigDict
from loguru import logger

from neco.core.utils.template_loader import TemplateLoader
from neco.llm.chain.entity import BasicLLMRequest, BasicLLMResponse, ToolsServer
from neco.llm.chain.graph import BasicGraph
from neco.llm.chain.node import ToolsNodes

class LatsAgentResponse(BasicLLMResponse):
    pass


class LatsAgentRequest(BasicLLMRequest):
    tools_servers: List[ToolsServer] = []
    langchain_tools: List[str] = []

# ========== LATSæ ¸å¿ƒé…ç½®å’Œæšä¸¾ ==========

class SearchStrategy(Enum):
    """æœç´¢ç­–ç•¥æšä¸¾"""
    PURE_LATS = "pure_lats"              # çº¯LATSæ ‘æœç´¢
    LATS_WITH_REACT = "lats_with_react"  # LATS + ReActå·¥å…·è°ƒç”¨
    ADAPTIVE = "adaptive"                # è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©

class SearchPhase(Enum):
    """æœç´¢é˜¶æ®µæšä¸¾"""
    INITIALIZATION = "initialization"
    TREE_SEARCH = "tree_search"
    TOOL_EXECUTION = "tool_execution"
    SYNTHESIS = "synthesis"
    COMPLETED = "completed"

@dataclass
class LATSConfig:
    """LATSæœç´¢å¼•æ“é…ç½®"""
    # æœç´¢å‚æ•°
    max_candidates: int = 5              # æ¯æ¬¡æ‰©å±•çš„å€™é€‰æ•°é‡
    max_tree_depth: int = 4              # æœ€å¤§æœç´¢æ·±åº¦
    exploration_weight: float = 1.414    # UCBæ¢ç´¢æƒé‡(âˆš2)
    
    # è´¨é‡é˜ˆå€¼
    solution_threshold: float = 8.0      # è§£å†³æ–¹æ¡ˆåˆ†æ•°é˜ˆå€¼
    early_stop_threshold: float = 9.0    # æ—©åœåˆ†æ•°é˜ˆå€¼
    
    # æ€§èƒ½é…ç½®
    parallel_evaluation: bool = True     # å¹¶è¡Œè¯„ä¼°
    max_search_time: float = 30.0       # æœ€å¤§æœç´¢æ—¶é—´(ç§’)
    enable_pruning: bool = True          # å¯ç”¨æœç´¢å‰ªæ
    
    # ç­–ç•¥é€‰æ‹©
    strategy: SearchStrategy = SearchStrategy.ADAPTIVE
    use_react_fallback: bool = True      # å¤æ‚æŸ¥è¯¢ä½¿ç”¨ReAct

class MultiDimensionalReflection(BaseModel):
    """å¤šç»´åº¦åæ€è¯„ä¼°æ¨¡å‹"""
    model_config = ConfigDict(arbitrary_types_allowed=True)
    
    # æ ¸å¿ƒè¯„ä¼°ç»´åº¦
    accuracy: float = Field(ge=0, le=10, description="ç­”æ¡ˆå‡†ç¡®æ€§è¯„åˆ†")
    completeness: float = Field(ge=0, le=10, description="ç­”æ¡ˆå®Œæ•´æ€§è¯„åˆ†")
    relevance: float = Field(ge=0, le=10, description="ç­”æ¡ˆç›¸å…³æ€§è¯„åˆ†")
    clarity: float = Field(ge=0, le=10, description="è¡¨è¾¾æ¸…æ™°åº¦è¯„åˆ†")
    
    # é«˜çº§è¯„ä¼°ç»´åº¦
    creativity: float = Field(ge=0, le=10, description="åˆ›æ–°æ€§å’Œç‹¬ç‰¹è§è§£")
    actionability: float = Field(ge=0, le=10, description="å¯æ‰§è¡Œæ€§å’Œå®ç”¨æ€§")
    
    # ç»¼åˆè¯„ä¼°
    overall_score: float = Field(ge=0, le=10, description="åŠ æƒç»¼åˆè¯„åˆ†")
    confidence: float = Field(ge=0, le=1, description="è¯„ä¼°ç½®ä¿¡åº¦")
    
    # åæ€å†…å®¹
    strengths: List[str] = Field(description="å›ç­”çš„ä¼˜ç‚¹")
    weaknesses: List[str] = Field(description="å›ç­”çš„ä¸è¶³")
    suggestions: List[str] = Field(description="æ”¹è¿›å»ºè®®")
    
    # å†³ç­–æ ‡å¿—
    found_solution: bool = Field(description="æ˜¯å¦æ‰¾åˆ°æ»¡æ„è§£å†³æ–¹æ¡ˆ")
    needs_tools: bool = Field(description="æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨")
    
    def as_message(self) -> HumanMessage:
        """è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼ç”¨äºä¸Šä¸‹æ–‡ä¼ é€’"""
        reflection_text = f"""
        **è¯„ä¼°ç»“æœ** (ç½®ä¿¡åº¦: {self.confidence:.2f})
        - å‡†ç¡®æ€§: {self.accuracy}/10 | å®Œæ•´æ€§: {self.completeness}/10
        - ç›¸å…³æ€§: {self.relevance}/10 | æ¸…æ™°åº¦: {self.clarity}/10
        - åˆ›æ–°æ€§: {self.creativity}/10 | å®ç”¨æ€§: {self.actionability}/10
        
        **ç»¼åˆè¯„åˆ†**: {self.overall_score}/10
        
        **ä¼˜ç‚¹**: {'; '.join(self.strengths)}
        **ä¸è¶³**: {'; '.join(self.weaknesses)}
        **å»ºè®®**: {'; '.join(self.suggestions)}
        """
        return HumanMessage(content=reflection_text.strip())
    
    @property
    def normalized_score(self) -> float:
        return self.overall_score / 10.0
    
    @classmethod
    def create_default(cls, basic_score: float = 5.0) -> "MultiDimensionalReflection":
        """åˆ›å»ºé»˜è®¤è¯„ä¼°ç»“æœ"""
        return cls(
            accuracy=basic_score,
            completeness=basic_score, 
            relevance=basic_score,
            clarity=basic_score,
            creativity=basic_score * 0.8,
            actionability=basic_score * 0.9,
            overall_score=basic_score,
            confidence=0.6,
            strengths=["åŸºç¡€å›ç­”ç»“æ„åˆç†"],
            weaknesses=["éœ€è¦æ›´æ·±å…¥åˆ†æ"],
            suggestions=["å¢åŠ å…·ä½“ç»†èŠ‚å’Œä¾‹è¯"],
            found_solution=basic_score >= 7.0,
            needs_tools=False
        )


class LATSTreeNode:
    """LATSæ ‘æœç´¢èŠ‚ç‚¹ - ä¸“ä¸šåŒ–å®ç°"""
    
    def __init__(
            self,
            messages: List[BaseMessage],
            reflection: MultiDimensionalReflection,
            parent: Optional["LATSTreeNode"] = None,
            node_id: str = None,
    ):
        self.messages = messages
        self.parent = parent
        self.children: List["LATSTreeNode"] = []
        self.reflection = reflection
        
        # èŠ‚ç‚¹æ ‡è¯†å’Œå±‚çº§
        self.node_id = node_id or f"node_{id(self)}"
        self.depth = parent.depth + 1 if parent is not None else 1
        
        # MCTSç»Ÿè®¡ä¿¡æ¯
        self.visits = 0
        self.total_reward = 0.0
        self.average_reward = 0.0
        
        # çŠ¶æ€æ ‡å¿—
        self._is_solved = reflection.found_solution if reflection else False
        self._creation_time = time.time()
        
        # åˆå§‹åŒ–æ—¶è¿›è¡Œåå‘ä¼ æ’­
        if self._is_solved:
            self._mark_tree_as_solved()
        self.backpropagate(reflection.normalized_score)

    def __repr__(self) -> str:
        return (
            f"<LATSTreeNode id={self.node_id}, depth={self.depth}, "
            f"visits={self.visits}, avg_reward={self.average_reward:.3f}, "
            f"solved={self.is_solved}>"
        )

    @property
    def is_solved(self) -> bool:
        """èŠ‚ç‚¹æ˜¯å¦å·²æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ"""
        return self._is_solved

    @property
    def is_terminal(self) -> bool:
        """èŠ‚ç‚¹æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹"""
        return not self.children

    @property
    def is_fully_expanded(self) -> bool:
        """èŠ‚ç‚¹æ˜¯å¦å·²å®Œå…¨æ‰©å±•(æœ‰å…·ä½“çš„å®ç°ä¾æ®)"""
        # ç®€å•å¯å‘å¼ï¼šå¦‚æœæœ‰5ä¸ªæˆ–æ›´å¤šå­èŠ‚ç‚¹ï¼Œè®¤ä¸ºå·²å……åˆ†æ‰©å±•
        return len(self.children) >= 5

    @property
    def best_child(self) -> Optional["LATSTreeNode"]:
        """è¿”å›æœ€ä½³å­èŠ‚ç‚¹"""
        if not self.children:
            return None
        return max(
            self.children,
            key=lambda child: (
                int(child.is_solved) * 100 +  # ä¼˜å…ˆè€ƒè™‘è§£å†³æ–¹æ¡ˆ
                child.average_reward * 10 +    # ç„¶åè€ƒè™‘è´¨é‡
                child.reflection.confidence    # æœ€åè€ƒè™‘ç½®ä¿¡åº¦
            )
        )

    @property
    def height(self) -> int:
        """è¿”å›ä»¥æ­¤èŠ‚ç‚¹ä¸ºæ ¹çš„å­æ ‘é«˜åº¦"""
        if not self.children:
            return 1
        return 1 + max(child.height for child in self.children)

    @property
    def tree_size(self) -> int:
        """è¿”å›ä»¥æ­¤èŠ‚ç‚¹ä¸ºæ ¹çš„å­æ ‘å¤§å°"""
        if not self.children:
            return 1
        return 1 + sum(child.tree_size for child in self.children)

    def upper_confidence_bound(self, exploration_weight: float = 1.414) -> float:
        """è®¡ç®—UCBå€¼ï¼Œå¹³è¡¡æ¢ç´¢ä¸å¼€å‘"""
        if self.parent is None:
            raise ValueError("æ ¹èŠ‚ç‚¹æ— æ³•è®¡ç®—UCBå€¼")
        
        if self.visits == 0:
            return float('inf')  # æœªè®¿é—®èŠ‚ç‚¹ä¼˜å…ˆçº§æœ€é«˜
        
        # UCB1å…¬å¼: avg_reward + c * sqrt(ln(parent_visits) / visits)
        exploitation_term = self.average_reward
        exploration_term = exploration_weight * math.sqrt(
            math.log(self.parent.visits) / self.visits
        )
        
        # åŠ å…¥å¤šç»´åº¦å¥–åŠ±
        quality_bonus = self.reflection.confidence * 0.1
        
        return exploitation_term + exploration_term + quality_bonus

    def backpropagate(self, reward: float) -> None:
        """åå‘ä¼ æ’­å¥–åŠ±å€¼åˆ°æ‰€æœ‰ç¥–å…ˆèŠ‚ç‚¹"""
        current_node = self
        
        while current_node is not None:
            current_node.visits += 1
            current_node.total_reward += reward
            current_node.average_reward = current_node.total_reward / current_node.visits
            current_node = current_node.parent

    def get_messages(self, include_reflections: bool = True) -> List[BaseMessage]:
        """è·å–èŠ‚ç‚¹æ¶ˆæ¯ï¼Œå¯é€‰æ‹©æ˜¯å¦åŒ…å«åæ€"""
        if include_reflections and self.reflection:
            return self.messages + [self.reflection.as_message()]
        return self.messages.copy()

    def get_trajectory(self, include_reflections: bool = True) -> List[BaseMessage]:
        """è·å–ä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹çš„å®Œæ•´è½¨è¿¹"""
        trajectory = []
        path_nodes = []
        
        # æ”¶é›†è·¯å¾„ä¸Šçš„æ‰€æœ‰èŠ‚ç‚¹
        current_node = self
        while current_node is not None:
            path_nodes.append(current_node)
            current_node = current_node.parent
        
        # ä»æ ¹å¼€å§‹æ„å»ºè½¨è¿¹
        for node in reversed(path_nodes):
            trajectory.extend(node.get_messages(include_reflections))
        
        return trajectory

    def get_all_descendants(self) -> List["LATSTreeNode"]:
        """è·å–æ‰€æœ‰åä»£èŠ‚ç‚¹"""
        descendants = []
        queue = deque(self.children)
        
        while queue:
            node = queue.popleft()
            descendants.append(node)
            queue.extend(node.children)
        
        return descendants

    def get_best_solution_node(self) -> Optional["LATSTreeNode"]:
        """åœ¨å½“å‰å­æ ‘ä¸­å¯»æ‰¾æœ€ä½³è§£å†³æ–¹æ¡ˆèŠ‚ç‚¹"""
        all_nodes = [self] + self.get_all_descendants()
        
        # ç­›é€‰å·²è§£å†³çš„ç»ˆç«¯èŠ‚ç‚¹
        solution_nodes = [
            node for node in all_nodes 
            if node.is_solved and node.is_terminal
        ]
        
        if not solution_nodes:
            return None
            
        # è¿”å›ç»¼åˆè¯„åˆ†æœ€é«˜çš„è§£å†³æ–¹æ¡ˆ
        return max(
            solution_nodes,
            key=lambda node: (
                node.reflection.overall_score * 10 +
                node.reflection.confidence * 5 +
                node.visits  # è®¿é—®æ¬¡æ•°ä½œä¸ºtie-breaker
            )
        )

    def _mark_tree_as_solved(self) -> None:
        """å°†æ•´ä¸ªè·¯å¾„æ ‡è®°ä¸ºå·²è§£å†³"""
        current_node = self.parent
        while current_node is not None:
            current_node._is_solved = True
            current_node = current_node.parent

    def prune_low_quality_children(self, threshold: float = 0.3) -> int:
        """å‰ªæä½è´¨é‡å­èŠ‚ç‚¹ï¼Œè¿”å›è¢«å‰ªæçš„èŠ‚ç‚¹æ•°"""
        if not self.children:
            return 0
            
        initial_count = len(self.children)
        self.children = [
            child for child in self.children
            if child.average_reward >= threshold or child.is_solved
        ]
        
        pruned_count = initial_count - len(self.children)
        if pruned_count > 0:
            logger.debug(f"èŠ‚ç‚¹ {self.node_id} å‰ªæäº† {pruned_count} ä¸ªä½è´¨é‡å­èŠ‚ç‚¹")
        
        return pruned_count


class LATSAgentState(TypedDict):
    """ä¸“ä¸šåŒ–LATS AgentçŠ¶æ€ç®¡ç†"""
    messages: Annotated[List[BaseMessage], add_messages]
    graph_request: LatsAgentRequest
    
    # LATSæ ‘æœç´¢çŠ¶æ€
    root: Optional[LATSTreeNode]
    current_phase: SearchPhase
    search_config: LATSConfig
    
    # æœç´¢ç»Ÿè®¡
    search_start_time: float
    total_evaluations: int
    best_score_so_far: float
    
    # ä¸­é—´ç»“æœ
    intermediate_results: List[Dict[str, Any]]
    tool_execution_needed: bool


class LatsAgentNode(ToolsNodes):
    """LATS Agent - ä¸“ä¸šåŒ–æ ‘æœç´¢æ‰§è¡ŒèŠ‚ç‚¹
    
    ä½¿ç”¨é…ç½®åŒ–å‚æ•°æ›¿ä»£ç¡¬ç¼–ç å¸¸é‡ï¼Œæ”¯æŒè¿è¡Œæ—¶è°ƒæ•´æœç´¢ç­–ç•¥ã€‚
    """

    
    async def _evaluate_candidate(
        self, 
        user_input: str, 
        candidate_messages: List[BaseMessage], 
        config: RunnableConfig,
        search_config: LATSConfig
    ) -> MultiDimensionalReflection:
        """é«˜çº§å¤šç»´åº¦å€™é€‰æ–¹æ¡ˆè¯„ä¼°"""
        try:
            # æ„å»ºå€™é€‰å›ç­”å†…å®¹
            candidate_content = self._extract_candidate_content(candidate_messages)
            
            # è®©ReAct Agentè‡ªä¸»åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·ï¼Œä¸åšé¢„åˆ¤
            needs_tools = False
            
            # è·å–æ™ºèƒ½è¯„ä¼°æ ‡å‡†
            evaluation_criteria = await self._get_evaluation_criteria(user_input)
            
            evaluation_prompt = TemplateLoader.render_template(
                "prompts/lats_agent/multi_dimensional_evaluation",
                {
                    "user_question": user_input,
                    "candidate_answer": candidate_content,
                    "evaluation_criteria": evaluation_criteria
                }
            )

            # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè§£æå™¨è¿›è¡Œå¤šç»´åº¦è¯„ä¼°
            result = await self.structured_output_parser.parse_with_structured_output(
                user_message=evaluation_prompt,
                pydantic_class=MultiDimensionalReflection
            )
            
            # è®¾ç½®å·¥å…·éœ€æ±‚æ ‡å¿—
            result.needs_tools = needs_tools
            
            # æ ¹æ®é…ç½®è°ƒæ•´è§£å†³æ–¹æ¡ˆé˜ˆå€¼
            if result.overall_score >= search_config.solution_threshold:
                result.found_solution = True
            
            logger.debug(f"å€™é€‰è¯„ä¼°å®Œæˆ: {result.overall_score:.2f}/10 (ç½®ä¿¡åº¦: {result.confidence:.2f})")
            return result
            
        except Exception as e:
            logger.warning(f"å¤šç»´åº¦è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„ä¼°: {e}")
            return MultiDimensionalReflection.create_default(6.0)

    def _extract_candidate_content(self, messages: List[BaseMessage]) -> str:
        """æå–å€™é€‰æ¶ˆæ¯çš„æ ¸å¿ƒå†…å®¹"""
        contents = []
        for msg in messages:
            if hasattr(msg, 'content') and msg.content:
                contents.append(str(msg.content))
        return "\n".join(contents) if contents else "ç©ºå›ç­”"



    async def _get_evaluation_criteria(self, user_input: str) -> str:
        """æ™ºèƒ½è·å–è¯„ä¼°æ ‡å‡† - ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º"""
        try:
            # å®šä¹‰è¯„ä¼°æ ‡å‡†ç»“æ„åŒ–æ¨¡å‹
            from pydantic import BaseModel
            
            class EvaluationCriteria(BaseModel):
                question_type: str = Field(description="é—®é¢˜ç±»å‹ï¼šæ—¶é—´æŸ¥è¯¢ç±»ã€æ–¹æ³•æŒ‡å¯¼ç±»ã€åŸå› è§£é‡Šç±»ã€é€šç”¨é—®ç­”ç±»")
                criteria: str = Field(description="å¯¹åº”çš„è¯„ä¼°æ ‡å‡†å…³é”®è¯")
            
            criteria_prompt = f"""
            è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜çš„ç±»å‹ï¼Œå¹¶æä¾›ç›¸åº”çš„è¯„ä¼°æ ‡å‡†ã€‚

            ç”¨æˆ·é—®é¢˜ï¼š{user_input}

            è¯·ä»ä»¥ä¸‹ç±»å‹ä¸­é€‰æ‹©æœ€ç¬¦åˆçš„ï¼š
            1. æ—¶é—´æŸ¥è¯¢ç±»ï¼šæ—¶é—´æŸ¥è¯¢å‡†ç¡®æ€§ã€å®æ—¶æ€§ã€æ ¼å¼è§„èŒƒæ€§
            2. æ–¹æ³•æŒ‡å¯¼ç±»ï¼šæ–¹æ³•å®Œæ•´æ€§ã€å¯æ“ä½œæ€§ã€æ­¥éª¤æ¸…æ™°åº¦
            3. åŸå› è§£é‡Šç±»ï¼šè§£é‡Šæ·±åº¦ã€é€»è¾‘æ€§ã€ä¾‹è¯å……åˆ†æ€§
            4. é€šç”¨é—®ç­”ç±»ï¼šå‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€æ¸…æ™°åº¦ã€å®ç”¨æ€§
            """
            
            result = await self.structured_output_parser.parse_with_structured_output(
                user_message=criteria_prompt,
                pydantic_class=EvaluationCriteria
            )
            
            return result.criteria
                
        except Exception as e:
            logger.warning(f"æ™ºèƒ½è¯„ä¼°æ ‡å‡†è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†: {e}")
            return "å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€æ¸…æ™°åº¦ã€å®ç”¨æ€§"



    def select_node_for_expansion(
        self, 
        root: LATSTreeNode, 
        config: LATSConfig
    ) -> LATSTreeNode:
        """ä½¿ç”¨æ”¹è¿›çš„UCBç®—æ³•é€‰æ‹©æ‰©å±•èŠ‚ç‚¹"""
        if not root.children:
            return root

        current = root
        selection_path = [root]
        
        # æ²¿ç€UCBå€¼æœ€é«˜çš„è·¯å¾„å‘ä¸‹é€‰æ‹©ï¼Œç›´åˆ°æ‰¾åˆ°å¯æ‰©å±•çš„èŠ‚ç‚¹
        while current.children and not self._should_expand_node(current, config):
            if current.is_fully_expanded:
                # å·²å……åˆ†æ‰©å±•ï¼Œç»§ç»­å‘ä¸‹é€‰æ‹©
                best_child = max(
                    current.children,
                    key=lambda child: child.upper_confidence_bound(config.exploration_weight)
                )
                current = best_child
                selection_path.append(current)
            else:
                # å¯ä»¥åœ¨å½“å‰èŠ‚ç‚¹æ‰©å±•
                break
        
        logger.debug(
            f"MCTSé€‰æ‹©è·¯å¾„: {' -> '.join(f'Node{i}' for i in range(len(selection_path)))}, "
            f"æœ€ç»ˆé€‰æ‹©æ·±åº¦: {current.depth}"
        )
        return current

    def _should_expand_node(self, node: LATSTreeNode, config: LATSConfig) -> bool:
        """åˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦åº”è¯¥è¢«æ‰©å±•"""
        # å¦‚æœå·²ç»æ˜¯è§£å†³æ–¹æ¡ˆï¼Œä¸éœ€è¦æ‰©å±•
        if node.is_solved:
            return False
            
        # å¦‚æœè¾¾åˆ°æœ€å¤§æ·±åº¦ï¼Œä¸æ‰©å±•
        if node.depth >= config.max_tree_depth:
            return False
            
        # å¦‚æœè®¿é—®æ¬¡æ•°å¤ªå°‘ï¼Œç»§ç»­æ‰©å±•å½“å‰èŠ‚ç‚¹
        if node.visits < 3:
            return True
            
        # å¦‚æœå­èŠ‚ç‚¹æ•°é‡è¿˜æ²¡è¾¾åˆ°é…ç½®çš„å€™é€‰æ•°é‡ï¼Œå¯ä»¥æ‰©å±•
        return len(node.children) < config.max_candidates

    async def _process_candidates_with_evaluation(
        self,
        candidates: List[BaseMessage],
        user_message: str,
        config: RunnableConfig,
        search_config: LATSConfig
    ) -> Tuple[List[List[BaseMessage]], List[MultiDimensionalReflection]]:
        """å¤„ç†å’Œè¯„ä¼°å€™é€‰æ–¹æ¡ˆ - æ”¯æŒå¹¶è¡Œè¯„ä¼°"""
        
        # å‡†å¤‡å€™é€‰æ¶ˆæ¯åˆ—è¡¨
        candidate_message_lists = [[candidate] for candidate in candidates]

        # æ˜¾ç¤ºè¯„ä¼°å¼€å§‹ä¿¡æ¯
        eval_start_msg = f"ğŸ“Š **è¯„ä¼° {len(candidates)} ä¸ªå€™é€‰æ–¹æ¡ˆ**"
        progress_messages = config.setdefault('progress_messages', [])
        progress_messages.append(AIMessage(content=eval_start_msg))

        # å¹¶è¡Œè¯„ä¼°æ‰€æœ‰å€™é€‰æ–¹æ¡ˆ
        if search_config.parallel_evaluation:
            evaluation_tasks = [
                self._evaluate_candidate(user_message, messages, config, search_config)
                for messages in candidate_message_lists
            ]
            reflections = await asyncio.gather(*evaluation_tasks, return_exceptions=True)
            
            # å¤„ç†è¯„ä¼°å¼‚å¸¸
            valid_reflections = []
            valid_candidates = []
            for i, reflection in enumerate(reflections):
                if isinstance(reflection, Exception):
                    logger.warning(f"å€™é€‰ {i} è¯„ä¼°å¤±è´¥: {reflection}")
                    valid_reflections.append(MultiDimensionalReflection.create_default(4.0))
                else:
                    valid_reflections.append(reflection)
                    # æ˜¾ç¤ºæ¯ä¸ªå€™é€‰çš„è¯„ä¼°ç»“æœ
                    eval_result_msg = f"âœ… å€™é€‰ {i+1}: **{reflection.overall_score:.1f}/10**"
                    progress_messages.append(AIMessage(content=eval_result_msg))
                
                valid_candidates.append(candidate_message_lists[i])
                
        else:
            # ä¸²è¡Œè¯„ä¼°
            valid_reflections = []
            valid_candidates = candidate_message_lists
            for i, messages in enumerate(candidate_message_lists):
                # æ˜¾ç¤ºä¸²è¡Œè¯„ä¼°è¿›åº¦
                eval_progress_msg = f"ğŸ“Š **è¯„ä¼°å€™é€‰ {i+1}/{len(candidate_message_lists)}**"
                progress_messages.append(AIMessage(content=eval_progress_msg))
                
                reflection = await self._evaluate_candidate(
                    user_message, messages, config, search_config
                )
                valid_reflections.append(reflection)
                
                # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                eval_result_msg = f"âœ… å€™é€‰ {i+1}: **{reflection.overall_score:.1f}/10**"
                progress_messages.append(AIMessage(content=eval_result_msg))

        # è®°å½•è¯„ä¼°æ‘˜è¦
        self._log_comprehensive_evaluation_summary(valid_reflections)

        # åº”ç”¨æ—©åœç­–ç•¥
        for reflection in valid_reflections:
            if reflection.overall_score >= search_config.early_stop_threshold:
                reflection.found_solution = True
                logger.info(f"ğŸ¯ è¾¾åˆ°æ—©åœé˜ˆå€¼ {search_config.early_stop_threshold}ï¼Œæ ‡è®°ä¸ºè§£å†³æ–¹æ¡ˆ")

        return valid_candidates, valid_reflections

    def _log_comprehensive_evaluation_summary(
        self, 
        reflections: List[MultiDimensionalReflection]
    ) -> None:
        """è®°å½•è¯¦ç»†çš„è¯„ä¼°æ‘˜è¦"""
        if not reflections:
            return

        # ç»Ÿè®¡ä¿¡æ¯
        scores = [r.overall_score for r in reflections]
        confidences = [r.confidence for r in reflections]
        solved_count = sum(1 for r in reflections if r.found_solution)
        tool_needed_count = sum(1 for r in reflections if r.needs_tools)

        logger.info(
            f"ğŸ“Š å¤šç»´åº¦è¯„ä¼°å®Œæˆ | "
            f"å€™é€‰æ•°: {len(reflections)} | "
            f"è´¨é‡åˆ†å¸ƒ: æœ€é«˜{max(scores):.1f} å¹³å‡{sum(scores)/len(scores):.1f} æœ€ä½{min(scores):.1f} | "
            f"å¹³å‡ç½®ä¿¡åº¦: {sum(confidences)/len(confidences):.2f} | "
            f"è§£å†³æ–¹æ¡ˆ: {solved_count}ä¸ª | "
            f"éœ€è¦å·¥å…·: {tool_needed_count}ä¸ª"
        )

    async def _invoke_react_for_candidate(self, user_message: str, messages: List[BaseMessage], config: RunnableConfig, system_prompt: str) -> AIMessage:
        """å¤ç”¨ ReAct é€»è¾‘ç”Ÿæˆå•ä¸ªå€™é€‰ - ä½¿ç”¨å¯å¤ç”¨çš„ ReAct èŠ‚ç‚¹ç»„åˆ"""
        
        try:
            # åˆ›å»ºä¸´æ—¶çŠ¶æ€å›¾æ¥ä½¿ç”¨å¯å¤ç”¨çš„ ReAct èŠ‚ç‚¹ç»„åˆ
            from langgraph.graph import StateGraph
            temp_graph_builder = StateGraph(dict)
            
            # ä½¿ç”¨å¯å¤ç”¨çš„ ReAct èŠ‚ç‚¹ç»„åˆæ„å»ºå›¾
            react_entry_node = await self.build_react_nodes(
                graph_builder=temp_graph_builder,
                composite_node_name="temp_react_candidate",
                additional_system_prompt=system_prompt,
                next_node=END
            )
            
            # è®¾ç½®èµ·å§‹èŠ‚ç‚¹
            temp_graph_builder.set_entry_point(react_entry_node)
            temp_graph_builder.add_edge(react_entry_node, END)
            
            # ç¼–è¯‘ä¸´æ—¶å›¾
            temp_graph = temp_graph_builder.compile()
            
            # è°ƒç”¨ ReAct èŠ‚ç‚¹
            result = await temp_graph.ainvoke(
                {"messages": messages[-3:] if len(messages) > 3 else messages},
                config=config
            )
            
            # æå–æœ€åçš„ AI æ¶ˆæ¯
            result_messages = result.get("messages", [])
            if isinstance(result_messages, list):
                for msg in reversed(result_messages):
                    if isinstance(msg, AIMessage):
                        return msg
            elif isinstance(result_messages, AIMessage):
                return result_messages
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° AI æ¶ˆæ¯ï¼Œè¿”å›é»˜è®¤å“åº”
            return AIMessage(content=f"æ­£åœ¨åˆ†æé—®é¢˜: {user_message}")
            
        except Exception as e:
            logger.warning(f"ReAct è°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
            return await self._generate_fallback_candidate(user_message, messages, system_prompt)
    
    async def _generate_fallback_candidate(self, user_message: str, messages: List[BaseMessage], system_message: str) -> AIMessage:
        """é™çº§æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨ LLM ç”Ÿæˆå€™é€‰"""
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="messages", optional=True),
        ])
        
        chain = prompt_template | self.llm
        try:
            candidate = await chain.ainvoke({
                "input": user_message,
                "messages": messages[-3:] if len(messages) > 3 else messages
            })
            return candidate
        except Exception as e:
            logger.error(f"é™çº§æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e}")
            return AIMessage(
                content=f"æ­£åœ¨é‡æ–°åˆ†æè¿™ä¸ªé—®é¢˜: {user_message}ï¼Œå¯»æ‰¾æ›´å¥½çš„è§£å†³æ–¹æ¡ˆ...",
                tool_calls=[]
            )

    async def _generate_candidates(self, user_message: str, messages: List[BaseMessage], config: RunnableConfig) -> List[BaseMessage]:
        """ç”Ÿæˆå€™é€‰æ–¹æ¡ˆ - ä½¿ç”¨ ReAct æ¨¡å¼ï¼ˆå¤ç”¨ build_react_nodes çš„é€»è¾‘ï¼‰"""
        
        # ä»é…ç½®è·å–å€™é€‰æ•°é‡
        search_config = config.get('configurable', {}).get('search_config', LATSConfig())
        max_candidates = getattr(search_config, 'max_candidates', 3)
        
        # ä½¿ç”¨å€™é€‰ç”Ÿæˆæ¨¡æ¿
        system_message = TemplateLoader.render_template(
            "prompts/lats_agent/candidate_generation",
            {
                "user_question": user_message,
                "context_length": len(messages)
            }
        )
        
        # ç”Ÿæˆå¤šä¸ªå€™é€‰æ–¹æ¡ˆï¼ˆæ¯ä¸ªå€™é€‰éƒ½é€šè¿‡ ReAct ç”Ÿæˆï¼‰
        candidates = []
        progress_messages = []
        
        for i in range(max_candidates):
            # æ˜¾ç¤ºå€™é€‰ç”Ÿæˆè¿›åº¦
            progress_msg = f"ğŸ” **ç”Ÿæˆå€™é€‰æ–¹æ¡ˆ {i+1}/{max_candidates}**"
            progress_messages.append(AIMessage(content=progress_msg))
            
            logger.debug(f"ä½¿ç”¨ ReAct æ¨¡å¼ç”Ÿæˆç¬¬ {i+1}/{max_candidates} ä¸ªå€™é€‰æ–¹æ¡ˆ")
            candidate = await self._invoke_react_for_candidate(user_message, messages, config, system_message)
            candidates.append(candidate)
        
        # å°†è¿›åº¦ä¿¡æ¯å­˜å‚¨åˆ°é…ç½®ä¸­ï¼Œä¾›åç»­ä½¿ç”¨
        config.setdefault('progress_messages', []).extend(progress_messages)
        return candidates

    async def _generate_diverse_candidates(
        self, 
        user_message: str, 
        messages: List[BaseMessage], 
        config: RunnableConfig,
        search_config: LATSConfig
    ) -> List[BaseMessage]:
        """ç”Ÿæˆå¤šæ ·åŒ–çš„å€™é€‰æ–¹æ¡ˆ - ä½¿ç”¨ä¸åŒçš„æç¤ºç­–ç•¥"""
        
        # åŸºç¡€å€™é€‰ç”Ÿæˆï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
        base_candidates = await self._generate_candidates(user_message, messages, config)
        
        # å¦‚æœéœ€è¦æ›´å¤šå€™é€‰ï¼Œå¯ä»¥æ·»åŠ å˜ä½“ç­–ç•¥
        if len(base_candidates) < search_config.max_candidates:
            additional_needed = search_config.max_candidates - len(base_candidates)
            
            # ç”Ÿæˆåˆ›æ–°æ€§å€™é€‰
            creative_prompt = f"è¯·ä»åˆ›æ–°çš„è§’åº¦é‡æ–°æ€è€ƒè¿™ä¸ªé—®é¢˜ï¼š{user_message}"
            creative_candidates = await self._generate_candidates(creative_prompt, messages[-2:], config)
            base_candidates.extend(creative_candidates[:additional_needed])
        
        return base_candidates[:search_config.max_candidates]

    def _build_search_progress_info(
        self, 
        state: LATSAgentState, 
        selected_node: LATSTreeNode, 
        config: RunnableConfig
    ) -> str:
        """æ„å»ºæœç´¢è¿›åº¦ä¿¡æ¯"""
        elapsed_time = time.time() - state["search_start_time"]
        search_config = state["search_config"]
        
        return f"""ğŸŒ³ **LATSæ™ºèƒ½æ ‘æœç´¢ - ç¬¬ {selected_node.depth} å±‚**

ğŸ¯ **ç›®æ ‡**: {config["configurable"]["graph_request"].user_message}
â±ï¸ **æœç´¢æ—¶é—´**: {elapsed_time:.1f}s / {search_config.max_search_time:.0f}s
ğŸ“Š **å½“å‰ç»Ÿè®¡**: å·²è¯„ä¼°{state["total_evaluations"]}ä¸ªå€™é€‰ï¼Œæœ€é«˜åˆ†{state["best_score_so_far"]:.1f}
ğŸ” **æœç´¢ç­–ç•¥**: {search_config.strategy.value} | å¹¶è¡Œè¯„ä¼°: {'å¯ç”¨' if search_config.parallel_evaluation else 'å…³é—­'}

ğŸ’¡ **æ­£åœ¨ç¬¬ {selected_node.depth} å±‚ç”Ÿæˆ {search_config.max_candidates} ä¸ªè§£å†³æ–¹æ¡ˆå€™é€‰...**"""

    def _build_solution_found_message(self, solution_node: LATSTreeNode) -> str:
        """æ„å»ºæ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„æ¶ˆæ¯"""
        reflection = solution_node.reflection
        return f"""ğŸ‰ **æ‰¾åˆ°é«˜è´¨é‡è§£å†³æ–¹æ¡ˆï¼**

âœ¨ **ç»¼åˆè¯„åˆ†**: {reflection.overall_score:.1f}/10 (ç½®ä¿¡åº¦: {reflection.confidence:.2f})
ğŸ† **è¯„ä¼°äº®ç‚¹**: {' | '.join(reflection.strengths[:2])}
ğŸ“‹ **è´¨é‡ç»´åº¦**: å‡†ç¡®æ€§{reflection.accuracy:.1f} å®Œæ•´æ€§{reflection.completeness:.1f} åˆ›æ–°æ€§{reflection.creativity:.1f}

ğŸš€ **æ­£åœ¨ä¸ºæ‚¨æ•´ç†æœ€ç»ˆç­”æ¡ˆ...**"""

    def _build_intermediate_result_message(self, node: LATSTreeNode) -> str:
        """æ„å»ºä¸­é—´ç»“æœæ¶ˆæ¯"""
        reflection = node.reflection
        return f"""â­ **å‘ç°ä¼˜è´¨å€™é€‰ç­”æ¡ˆ**

ğŸ“Š **è´¨é‡è¯„åˆ†**: {reflection.overall_score:.1f}/10 (ç½®ä¿¡åº¦: {reflection.confidence:.2f})
ğŸ” **ä¼˜åŠ¿**: {reflection.strengths[0] if reflection.strengths else 'ç»“æ„åˆç†'}
ğŸ’¡ **æ”¹è¿›æ–¹å‘**: {reflection.suggestions[0] if reflection.suggestions else 'ç»§ç»­ä¼˜åŒ–'}

ğŸŒ³ **ç»§ç»­æ·±åº¦æœç´¢æ›´ä¼˜è§£å†³æ–¹æ¡ˆ...**"""

    def _prepare_timeout_response(self, state: LATSAgentState) -> LATSAgentState:
        """å‡†å¤‡è¶…æ—¶å“åº” - é™é»˜å¤„ç†"""
        return {
            **state,
            "current_phase": SearchPhase.SYNTHESIS
        }

    async def expand(self, state: LATSAgentState, config: RunnableConfig) -> LATSAgentState:
        """æ‰©å±•æœç´¢æ ‘"""
        logger.info("ğŸŒ³ å¼€å§‹æ‰©å±•æœç´¢æ ‘")

        # æ˜¾ç¤ºæœç´¢å¼€å§‹ä¿¡æ¯
        search_depth = state["root"].height if state["root"] else 0
        search_start_msg = f"ğŸ” **ç¬¬ {search_depth + 1} è½®ä¼˜åŒ–æœç´¢**"
        
        root = state["root"]
        if not root:
            logger.error("æœç´¢æ ‘æ ¹èŠ‚ç‚¹æœªåˆå§‹åŒ–")
            return state

        # é€‰æ‹©æœ€ä½³å€™é€‰èŠ‚ç‚¹
        best_candidate = self.select_node_for_expansion(root, state.get("search_config", LATSConfig()))
        messages = best_candidate.get_trajectory()

        # åˆå§‹åŒ–è¿›åº¦æ¶ˆæ¯å®¹å™¨
        config['progress_messages'] = [AIMessage(content=search_start_msg)]

        # ç”Ÿæˆæ–°å€™é€‰
        user_message = config["configurable"]["graph_request"].user_message
        new_candidates = await self._generate_candidates(user_message, messages, config)

        # å¤„ç†å€™é€‰å¹¶è¯„ä¼°
        output_messages, reflections = await self._process_candidates_with_evaluation(
            new_candidates, user_message, config, state.get("search_config", LATSConfig())
        )
        
        # è·å–æ‰€æœ‰è¿›åº¦æ¶ˆæ¯
        progress_messages = config.get('progress_messages', [])

        # æ·»åŠ è¯„ä¼°ç»“æœåˆ°çŠ¶æ€
        state['evaluation_results'] = [
            {
                'index': i + 1,
                'score': r.overall_score,
                'found_solution': r.found_solution,
                'reflections': '; '.join(r.strengths + r.weaknesses),
                'message_content': output_messages[i][-1].content if output_messages[i] else ""
            }
            for i, r in enumerate(reflections)
        ]

        # æ‰©å±•æœç´¢æ ‘
        child_nodes = [
            LATSTreeNode(messages=cand, reflection=reflection, parent=best_candidate)
            for cand, reflection in zip(output_messages, reflections)
        ]
        best_candidate.children.extend(child_nodes)

        # æ·»åŠ è¯„ä¼°å®Œæˆæ€»ç»“
        best_score = max((r.overall_score for r in reflections), default=0)
        eval_summary_msg = f"ğŸ¯ **æœ€ä½³è¯„åˆ†: {best_score:.1f}/10** {'âœ¨' if best_score >= 8.0 else 'ğŸ” ç»§ç»­ä¼˜åŒ–...'}"
        progress_messages.append(AIMessage(content=eval_summary_msg))
        
        # æ£€æŸ¥è§£å†³æ–¹æ¡ˆ
        solution_nodes = [node for node, r in zip(
            child_nodes, reflections) if r.found_solution]
        if solution_nodes:
            best_solution = max(
                solution_nodes, key=lambda node: node.reflection.overall_score)

            logger.info(f"ğŸ‰ æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ! è¯„åˆ†: {best_solution.reflection.overall_score}/10")

            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            final_answer = await self._generate_final_answer(best_solution, config)
            
            # æ·»åŠ è¿›åº¦ä¿¡æ¯å’Œæœ€ç»ˆç­”æ¡ˆ
            messages_to_add = progress_messages + [final_answer]
            root._is_solved = True
        else:
            # æ·»åŠ æœ€ä½³ä¸­é—´ç»“æœ
            if child_nodes:
                best_node = max(
                    child_nodes, key=lambda node: node.reflection.overall_score)
                if best_node.reflection.overall_score >= 7:
                    best_message = best_node.get_trajectory(
                        include_reflections=False)[-1]
                    
                    # è¿”å›è¿›åº¦ä¿¡æ¯å’Œæœ€ä½³ä¸­é—´ç»“æœ
                    messages_to_add = progress_messages + [best_message]
                    logger.info(
                        f"â­ æ·»åŠ é«˜è´¨é‡ä¸­é—´ç»“æœ (è¯„åˆ†: {best_node.reflection.overall_score}/10)")
                else:
                    # åªæ˜¾ç¤ºè¿›åº¦ä¿¡æ¯ï¼Œç»§ç»­æœç´¢
                    messages_to_add = progress_messages
            else:
                # åªæ˜¾ç¤ºè¿›åº¦ä¿¡æ¯ï¼Œç»§ç»­æœç´¢
                messages_to_add = progress_messages

        return {
            **state,
            "messages": state.get("messages", []) + messages_to_add
        }

    async def generate_final_answer(self, state: LATSAgentState, config: RunnableConfig) -> dict:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹"""
        logger.info("ğŸ“ ç”Ÿæˆæœ€ç»ˆæ€»ç»“ç­”æ¡ˆ")

        root = state["root"]

        # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œä¸æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        final_answer = await self._generate_final_answer(root, config)

        logger.info("âœ… æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå®Œæˆ")

        # åªè¿”å›æœ€ç»ˆç­”æ¡ˆ
        return {
            **state,
            "messages": state.get("messages", []) + [final_answer]
        }

    async def _generate_final_answer(self, solution_node: LATSTreeNode, config: RunnableConfig) -> BaseMessage:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ - ä½¿ç”¨ç»Ÿä¸€çš„LLMå®ä¾‹"""
        
        system_message = TemplateLoader.render_template(
            "prompts/lats_agent/intelligent_assistant")
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="messages", optional=True),
        ])

        final_solution = solution_node.get_trajectory(
            include_reflections=False)[-1]

        # å®‰å…¨åœ°æå–ç”¨æˆ·æ ¸å¿ƒé—®é¢˜ï¼Œè¿‡æ»¤æ•æ„Ÿç³»ç»ŸæŒ‡ä»¤
        user_question = config['configurable']['graph_request'].user_message

        question = TemplateLoader.render_template(
            "prompts/lats_agent/final_answer_synthesis",
            {
                "user_question": user_question,
                "solution_content": final_solution.content
            }
        )

        chain = prompt_template | self.llm  # ä½¿ç”¨ç»§æ‰¿çš„ç»Ÿä¸€LLMå®ä¾‹
        return await chain.ainvoke({"input": question})

    def should_continue(self, state: LATSAgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æœç´¢æˆ–è¿›å…¥æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ"""
        root = state.get("root")
        
        # å¦‚æœæœ‰æ ¹èŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ
        if root and root.is_solved:
            logger.info("âœ… å·²æ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return "generate_final_answer"
        
        # æ£€æŸ¥æœç´¢æ·±åº¦
        search_config = state.get('search_config', LATSConfig())
        if root and root.height >= search_config.max_tree_depth:
            logger.info(f"â¹ï¸ è¾¾åˆ°æœ€å¤§æœç´¢æ·±åº¦ {search_config.max_tree_depth}ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return "generate_final_answer"
        
        # æ£€æŸ¥æœç´¢æ—¶é—´
        elapsed_time = time.time() - state.get("search_start_time", time.time())
        if elapsed_time >= search_config.max_search_time:
            logger.info(f"â° è¾¾åˆ°æœ€å¤§æœç´¢æ—¶é—´ {search_config.max_search_time}sï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return "generate_final_answer"
        
        # å¦åˆ™ç»§ç»­æ‰©å±•æœç´¢æ ‘
        logger.info("ğŸŒ³ ç»§ç»­æ‰©å±•æœç´¢æ ‘")
        return "expand"

    async def generate_initial_response(self, state: LATSAgentState, config: RunnableConfig) -> dict:
        """ç”Ÿæˆåˆå§‹å“åº” - ä½¿ç”¨ ReAct æ¨¡å¼ç”Ÿæˆç¬¬ä¸€ä¸ªå€™é€‰å¹¶è¯„ä¼°"""
        logger.info("ğŸŒ± ç”Ÿæˆåˆå§‹å“åº” (ä½¿ç”¨ ReAct æ¨¡å¼)")
        
        request = config['configurable']['graph_request']
        user_message = request.user_message
        
        # åˆå§‹åŒ–å®Œæ•´çš„æœç´¢çŠ¶æ€
        if 'search_config' not in state:
            state['search_config'] = LATSConfig()
        if 'search_start_time' not in state:
            state['search_start_time'] = time.time()
        if 'total_evaluations' not in state:
            state['total_evaluations'] = 0
        if 'best_score_so_far' not in state:
            state['best_score_so_far'] = 0.0
        if 'intermediate_results' not in state:
            state['intermediate_results'] = []
        if 'tool_execution_needed' not in state:
            state['tool_execution_needed'] = False
        
        state['current_phase'] = SearchPhase.INITIALIZATION

        # æ˜¾ç¤ºåˆå§‹åˆ†æè¿›åº¦
        progress_start_msg = AIMessage(content="ğŸ§  **æ™ºèƒ½åˆ†æä¸­...**")
        
        # ä½¿ç”¨ ReAct æ¨¡å¼ç”Ÿæˆåˆå§‹å€™é€‰ç­”æ¡ˆ
        system_message = TemplateLoader.render_template(
            "prompts/lats_agent/initial_response"
        )
        
        logger.info("ğŸ”§ ä½¿ç”¨ ReAct ç”Ÿæˆåˆå§‹å€™é€‰ç­”æ¡ˆ")
        initial_candidate = await self._invoke_react_for_candidate(
            user_message, 
            state.get("messages", []), 
            config, 
            system_message
        )
        
        # æ˜¾ç¤ºè¯„ä¼°è¿›åº¦
        eval_progress_msg = AIMessage(content="ğŸ“Š **è¯„ä¼°ç­”æ¡ˆè´¨é‡**")
        
        # è¯„ä¼°åˆå§‹å“åº”
        search_config = state.get('search_config', LATSConfig())
        output_messages = [initial_candidate]
        reflection = await self._evaluate_candidate(user_message, output_messages, config, search_config)
        
        # åˆ›å»ºæ ¹èŠ‚ç‚¹
        root = LATSTreeNode(messages=output_messages, reflection=reflection)
        state['root'] = root
        state['total_evaluations'] = 1
        state['best_score_so_far'] = reflection.overall_score
        
        logger.info(f"ğŸ“Š åˆå§‹å“åº”è¯„ä¼°å®Œæˆ | è¯„åˆ†: {reflection.overall_score}/10 | è§£å†³æ–¹æ¡ˆ: {reflection.found_solution}")
        
        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
        eval_result_msg = AIMessage(content=f"âœ… **åˆå§‹è¯„åˆ†: {reflection.overall_score:.1f}/10** {('ğŸ‰' if reflection.found_solution else 'ğŸ” å¯»æ‰¾æ›´ä¼˜æ–¹æ¡ˆ...')}")
        
        # è¿”å›è¿›åº¦ä¿¡æ¯å’Œåˆå§‹å€™é€‰ç­”æ¡ˆ
        messages_to_add = [progress_start_msg, eval_progress_msg, initial_candidate, eval_result_msg]
        
        return {
            **state,
            "messages": state.get("messages", []) + messages_to_add
        }




class LatsAgentGraph(BasicGraph):
    """LATS Agent å›¾æ‰§è¡Œå™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""

    async def compile_graph(self, request: LatsAgentRequest) -> StateGraph:
        """ç¼–è¯‘ LATS Agent æ‰§è¡Œå›¾"""
        logger.info("ğŸ”§ ç¼–è¯‘ LATS Agent æ‰§è¡Œå›¾")

        # åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆæœ¬çš„èŠ‚ç‚¹æ„å»ºå™¨
        node_builder = LatsAgentNode()
        await node_builder.setup(request)

        # åˆ›å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(LATSAgentState)

        # æ·»åŠ åŸºç¡€å›¾ç»“æ„
        last_edge = self.prepare_graph(graph_builder, node_builder)
        logger.debug(f"åŸºç¡€å›¾æ„å»ºå®Œæˆï¼Œè¿æ¥ç‚¹: {last_edge}")

        # æ·»åŠ  LATS ç‰¹æœ‰èŠ‚ç‚¹
        graph_builder.add_node("generate_initial_response",
                               node_builder.generate_initial_response)
        graph_builder.add_node("expand", node_builder.expand)
        graph_builder.add_node("generate_final_answer",
                               node_builder.generate_final_answer)

        # æ„å»ºæ‰§è¡Œæµç¨‹ - æ ‡å‡† LATS æµç¨‹
        graph_builder.add_edge(last_edge, 'generate_initial_response')
        
        # åˆå§‹å“åº”åæ ¹æ®è¯„ä¼°ç»“æœå†³å®š
        graph_builder.add_conditional_edges(
            "generate_initial_response",
            node_builder.should_continue,
            {
                "expand": "expand",
                "generate_final_answer": "generate_final_answer"
            }
        )
        
        # æ‰©å±•æœç´¢åçš„æ¡ä»¶åˆ†æ”¯
        graph_builder.add_conditional_edges(
            "expand", 
            node_builder.should_continue,
            {
                "expand": "expand",
                "generate_final_answer": "generate_final_answer"
            }
        )

        # æœ€ç»ˆç­”æ¡ˆç”Ÿæˆåç»“æŸ
        graph_builder.add_edge("generate_final_answer", END)

        # ç¼–è¯‘å¹¶è¿”å›å›¾
        compiled_graph = graph_builder.compile()
        logger.info("âœ… LATS Agent æ‰§è¡Œå›¾ç¼–è¯‘å®Œæˆ")

        return compiled_graph
