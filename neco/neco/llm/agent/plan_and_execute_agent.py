import time
from typing import TypedDict, Annotated, List, Optional

from langchain_core.messages import BaseMessage, AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.constants import END
from langgraph.graph import StateGraph, add_messages
from pydantic import BaseModel, Field
from loguru import logger

from neco.llm.chain.entity import BasicLLMRequest, BasicLLMResponse, ToolsServer
from neco.llm.chain.graph import BasicGraph
from neco.llm.chain.node import ToolsNodes

class PlanAndExecuteAgentResponse(BasicLLMResponse):
    pass

class PlanAndExecuteAgentRequest(BasicLLMRequest):
    tools_servers: List[ToolsServer] = []
    langchain_tools: List[str] = []

class PlanAndExecuteAgentState(TypedDict):
    """çœŸæ­£çš„Plan and Execute AgentçŠ¶æ€ç®¡ç†"""
    messages: Annotated[List[BaseMessage], add_messages]
    graph_request: PlanAndExecuteAgentRequest
    
    # è®¡åˆ’ç›¸å…³
    original_plan: List[str]      # åŸå§‹è®¡åˆ’
    current_plan: List[str]       # å½“å‰å‰©ä½™æ­¥éª¤
    
    # æ‰§è¡Œç›¸å…³
    execution_prompt: Optional[str]  # å½“å‰æ­¥éª¤çš„æ‰§è¡Œæç¤º
    
    # æœ€ç»ˆç»“æœ
    final_response: Optional[str]

class Plan(BaseModel):
    """åŠ¨æ€è®¡åˆ’æ¨¡å‹"""
    steps: List[str] = Field(description="å½“å‰å‰©ä½™çš„æ‰§è¡Œæ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åº”è¯¥å…·ä½“æ˜ç¡®ä¸”å¯æ‰§è¡Œ")

class PlanResponse(BaseModel):
    """è®¡åˆ’å“åº”æ¨¡å‹"""
    plan: Plan = Field(description="ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’")
    reasoning: str = Field(description="è®¡åˆ’åˆ¶å®šçš„æ¨ç†è¿‡ç¨‹")

class ReplanResponse(BaseModel):
    """é‡æ–°è§„åˆ’å“åº”æ¨¡å‹"""
    updated_plan: Plan = Field(description="æ›´æ–°åçš„å‰©ä½™æ­¥éª¤")
    reasoning: str = Field(description="é‡æ–°è§„åˆ’çš„æ¨ç†è¿‡ç¨‹")
    is_complete: bool = Field(description="ä»»åŠ¡æ˜¯å¦å·²ç»å®Œæˆï¼Œæ— éœ€ç»§ç»­æ‰§è¡Œ")

class PlanAndExecuteAgentNode(ToolsNodes):
    """Plan and Execute Agent - æ™ºèƒ½è®¡åˆ’ç”Ÿæˆä¸æ‰§è¡Œ"""

    async def planner_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """åŠ¨æ€è®¡åˆ’ç”ŸæˆèŠ‚ç‚¹ - çœŸæ­£çš„Plan and Execute Agent"""
        
        user_message = config["configurable"]["graph_request"].user_message
        
        # è·å–å¯ç”¨å·¥å…·ä¿¡æ¯
        tools_info = ""
        if hasattr(self, 'tools') and self.tools:
            tools_list = []
            for tool in self.tools:
                tool_name = getattr(tool, 'name', str(tool))
                tool_desc = getattr(tool, 'description', 'å·¥å…·åŠŸèƒ½')
                tools_list.append(f"  â€¢ {tool_name}: {tool_desc}")
            
            tools_info = f"""

ğŸ”§ **å¯ç”¨å·¥å…·**:
{chr(10).join(tools_list)}"""
        
        # åŠ¨æ€è®¡åˆ’ç”Ÿæˆæç¤º
        planning_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡è§„åˆ’å¸ˆã€‚è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ã€‚

ğŸ“‹ **ç”¨æˆ·ä»»åŠ¡**: {user_message}{tools_info}

ğŸ¯ **è§„åˆ’æŒ‡å—**:
1. åˆ†æä»»åŠ¡çš„å…·ä½“éœ€æ±‚å’Œç›®æ ‡
2. è¯†åˆ«éœ€è¦ä½¿ç”¨çš„å·¥å…·å’Œèµ„æº  
3. åˆ¶å®šæ¸…æ™°ã€å¯æ‰§è¡Œçš„æ­¥éª¤åºåˆ—
4. æ¯ä¸ªæ­¥éª¤éƒ½åº”è¯¥æ˜¯å…·ä½“çš„è¡ŒåŠ¨é¡¹
5. å……åˆ†åˆ©ç”¨å¯ç”¨å·¥å…·çš„èƒ½åŠ›

è¯·æä¾›ä½ çš„æ¨ç†è¿‡ç¨‹å’Œå…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚"""

        try:
            # ä½¿ç”¨LLMåŠ¨æ€ç”Ÿæˆè®¡åˆ’
            plan_response = await self.structured_output_parser.parse_with_structured_output(
                user_message=planning_prompt,
                pydantic_class=PlanResponse
            )
            
            plan_steps = plan_response.plan.steps
            reasoning = plan_response.reasoning
            
        except Exception as e:
            logger.warning(f"åŠ¨æ€è®¡åˆ’ç”Ÿæˆå¤±è´¥: {e}")
            # ç´§æ€¥å¤‡ç”¨è®¡åˆ’
            plan_steps = ["åˆ†æç”¨æˆ·éœ€æ±‚", "æ‰§è¡Œå¿…è¦çš„æ“ä½œ", "æä¾›ç»“æœ"]
            reasoning = "ä½¿ç”¨å¤‡ç”¨è®¡åˆ’"
        
        # æ”¹è¿›è§„åˆ’æ˜¾ç¤ºï¼Œè®©ç»“æ„æ›´æ¸…æ™°ï¼Œæ˜¾ç¤ºè¯¦ç»†è®¡åˆ’
        plan_display = f"ğŸ¯ **æ‰§è¡Œè®¡åˆ’å·²åˆ¶å®š** ({len(plan_steps)} ä¸ªæ­¥éª¤)\n\n"
        plan_display += f"ğŸ“ **è®¡åˆ’æ¨ç†**: {reasoning}\n\n"
        plan_display += "ğŸ“‹ **æ‰§è¡Œæ­¥éª¤**:\n"
        for i, step in enumerate(plan_steps, 1):
            plan_display += f"   **{i}.** {step}\n"
        plan_display += f"\nğŸš€ å¼€å§‹æ‰§è¡Œè®¡åˆ’...\n\n---\n"
        
        self.log(config, plan_display)
        
        return {
            "messages": [AIMessage(content=plan_display)],
            "original_plan": plan_steps,
            "current_plan": plan_steps,
            "final_response": None
        }

    async def executor_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """å•æ­¥æ‰§è¡ŒèŠ‚ç‚¹ - æ‰§è¡Œå½“å‰è®¡åˆ’çš„ç¬¬ä¸€æ­¥"""
        
        current_plan = state.get("current_plan", [])
        if not current_plan:
            # æ²¡æœ‰å¾…æ‰§è¡Œæ­¥éª¤ï¼Œç›´æ¥è¿›å…¥æ€»ç»“ - ä¸è®¾ç½®final_responseï¼Œè®©should_continueå†³å®š
            return {**state}
        
        current_step = current_plan[0]  # å–ç¬¬ä¸€ä¸ªå¾…æ‰§è¡Œæ­¥éª¤
        
        # ç§»é™¤å¹²æ‰°æ€§è¾“å‡ºï¼Œè®©æ‰§è¡Œè¿‡ç¨‹æ›´ç®€æ´
        # self.log(config, f"âš¡ æ‰§è¡Œæ­¥éª¤ {len(original_plan) - len(current_plan) + 1}")  # å¯é€‰ï¼šæ˜¾ç¤ºæ­¥éª¤ç¼–å·
        
        # ä½¿ç”¨ReActæ¨¡å¼æ‰§è¡Œå½“å‰æ­¥éª¤
        execution_prompt = f"""è¯·æ‰§è¡Œä»¥ä¸‹å…·ä½“æ­¥éª¤ï¼š

ğŸ¯ **å½“å‰æ­¥éª¤**: {current_step}

ğŸ“‹ **åŸå§‹ä»»åŠ¡**: {config["configurable"]["graph_request"].user_message}

è¯·ä¸“æ³¨äºå®Œæˆè¿™ä¸€ä¸ªæ­¥éª¤ï¼Œä½¿ç”¨å¿…è¦çš„å·¥å…·ï¼Œå¹¶æä¾›æ‰§è¡Œç»“æœã€‚"""
        
        # ä¼ é€’æ‰§è¡Œæç¤ºç»™ReactèŠ‚ç‚¹ä½¿ç”¨ï¼Œä¸æ·»åŠ é¢å¤–çš„æ˜¾ç¤ºæ¶ˆæ¯
        return {
            **state,
            "execution_prompt": execution_prompt
        }

    async def replanner_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """æ™ºèƒ½é‡æ–°è§„åˆ’èŠ‚ç‚¹ - åŸºäºæ‰§è¡Œç»“æœåæ€å¹¶è°ƒæ•´å‰©ä½™è®¡åˆ’"""
        
        current_plan = state.get("current_plan", [])
        original_plan = state.get("original_plan", [])
        
        if not current_plan:
            # è®¡åˆ’ä¸ºç©ºï¼Œä¸è®¾ç½®final_responseï¼Œè®©should_continueç»Ÿä¸€åˆ¤æ–­
            return {**state}
        
        # è®¡ç®—æ‰§è¡Œè¿›åº¦ - æ­£ç¡®è®¡ç®—å·²å®Œæˆæ­¥éª¤æ•°
        total_steps = len(original_plan) if original_plan else 1
        completed_count = total_steps - len(current_plan) + 1  # +1 è¡¨ç¤ºåˆšå®Œæˆäº†ä¸€æ­¥
        
        # æ„å»ºæ™ºèƒ½é‡æ–°è§„åˆ’æç¤º
        replan_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡é‡æ–°è§„åˆ’åŠ©æ‰‹ã€‚è¯·åŸºäºå½“å‰æ‰§è¡Œæƒ…å†µï¼Œåæ€å¹¶é‡æ–°è§„åˆ’å‰©ä½™ä»»åŠ¡æ­¥éª¤ã€‚

ğŸ“‹ **åŸå§‹ç”¨æˆ·ä»»åŠ¡**: {config["configurable"]["graph_request"].user_message}

ğŸ“ **åŸå§‹å®Œæ•´è®¡åˆ’**:
{chr(10).join([f"   {i+1}. {step}" for i, step in enumerate(original_plan)])}

ğŸ“Š **å½“å‰å‰©ä½™æ­¥éª¤**:
{chr(10).join([f"   {i+1}. {step}" for i, step in enumerate(current_plan)])}

ğŸ” **æœ€è¿‘æ‰§è¡Œå†å²**:
{chr(10).join([f"- {msg.content}" for msg in state.get("messages", [])[-3:] if hasattr(msg, 'content') and msg.content])}

ğŸ¯ **é‡æ–°è§„åˆ’è¦æ±‚**:
1. åˆ†æå½“å‰æ‰§è¡Œæƒ…å†µå’Œå·²è·å¾—çš„ç»“æœ
2. åˆ¤æ–­å½“å‰ç¬¬ä¸€ä¸ªæ­¥éª¤æ˜¯å¦å·²ç»å®Œæˆæˆ–éœ€è¦è°ƒæ•´
3. åŸºäºæ‰§è¡Œç»“æœï¼Œé‡æ–°è¯„ä¼°å‰©ä½™æ­¥éª¤çš„å¿…è¦æ€§å’Œé¡ºåº
4. å¦‚æœå‘ç°æ–°çš„éœ€æ±‚æˆ–é—®é¢˜ï¼Œå¯ä»¥æ·»åŠ æ–°æ­¥éª¤
5. å¦‚æœæŸäº›æ­¥éª¤å·²ç»ä¸å†å¿…è¦ï¼Œå¯ä»¥ç§»é™¤
6. å¦‚æœä»»åŠ¡å·²ç»å®Œæˆï¼Œæ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€

è¯·æä¾›ä½ çš„é‡æ–°è§„åˆ’ç»“æœã€‚"""

        try:
            # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½é‡æ–°è§„åˆ’
            replan_response = await self.structured_output_parser.parse_with_structured_output(
                user_message=replan_prompt,
                pydantic_class=ReplanResponse
            )
            
            updated_steps = replan_response.updated_plan.steps
            reasoning = replan_response.reasoning
            is_complete = replan_response.is_complete
            
        except Exception as e:
            logger.warning(f"æ™ºèƒ½é‡æ–°è§„åˆ’å¤±è´¥: {e}")
            # ç®€å•é™çº§ï¼šç§»é™¤ç¬¬ä¸€ä¸ªæ­¥éª¤
            updated_steps = current_plan[1:] if len(current_plan) > 1 else []
            reasoning = "ä½¿ç”¨ç®€å•è§„åˆ™ï¼šç§»é™¤å·²å®Œæˆæ­¥éª¤"
            is_complete = len(updated_steps) == 0

        if is_complete or not updated_steps:
            # ä»»åŠ¡å®Œæˆ - æ¸…ç©ºcurrent_planï¼Œè®©should_continueç»Ÿä¸€åˆ¤æ–­è¿›å…¥summary
            return {
                **state,
                "current_plan": []
                # ä¸è®¾ç½®final_responseï¼Œé¿å…é‡å¤
            }
        else:
            # è¿˜æœ‰å‰©ä½™æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œ
            # æ”¹è¿›è¿›åº¦æ˜¾ç¤ºï¼Œè®©æ­¥éª¤æ›´æ¸…æ™°ï¼ŒåŒ…å«é‡æ–°è§„åˆ’ä¿¡æ¯
            progress_display = f"\n---\n\nğŸ“Š **æ­¥éª¤ {completed_count}/{total_steps} å®Œæˆ**\n"
            
            # å¦‚æœæ­¥éª¤æœ‰å˜åŒ–ï¼Œæ˜¾ç¤ºé‡æ–°è§„åˆ’ä¿¡æ¯
            if updated_steps != current_plan[1:]:
                progress_display += f"\nğŸ”„ **è®¡åˆ’å·²è°ƒæ•´**: {reasoning}\n"
                progress_display += f"\nğŸ“‹ **å‰©ä½™æ­¥éª¤**:\n"
                for i, step in enumerate(updated_steps, 1):
                    progress_display += f"   **{i}.** {step}\n"
                progress_display += f"\n"  # ç¡®ä¿æœ«å°¾æœ‰æ¢è¡Œ
            
            logger.debug(f"[replanner_node] æ˜¾ç¤ºè¿›åº¦: {progress_display.strip()}, current_plané•¿åº¦: {len(current_plan)}, updated_stepsé•¿åº¦: {len(updated_steps)}")
            self.log(config, progress_display)
            
            return {
                **state,
                "current_plan": updated_steps
            }

    async def should_continue(self, state: PlanAndExecuteAgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–ç»“æŸ - ç»Ÿä¸€åˆ¤æ–­é€»è¾‘ï¼Œé¿å…é‡å¤è¿›å…¥summary"""
        current_plan = state.get("current_plan", [])
        
        logger.debug(f"[should_continue] current_plané•¿åº¦: {len(current_plan)}")
        
        # åªåŸºäºcurrent_planåˆ¤æ–­ï¼šæ²¡æœ‰å‰©ä½™æ­¥éª¤å°±ç»“æŸæ‰§è¡Œ
        if not current_plan:
            logger.debug("[should_continue] æ²¡æœ‰å‰©ä½™æ­¥éª¤ï¼Œè¿”å› summary")
            return "summary"
        
        # å¦åˆ™ç»§ç»­æ‰§è¡Œ
        logger.debug("[should_continue] è¿˜æœ‰å‰©ä½™æ­¥éª¤ï¼Œè¿”å› executor") 
        return "executor"

    async def summary_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """æœ€ç»ˆæ€»ç»“èŠ‚ç‚¹ - ä½¿ç”¨LLMæ™ºèƒ½æ€»ç»“æ‰§è¡Œè¿‡ç¨‹å’Œç»“æœ"""
        logger.debug("[summary_node] è¿›å…¥æ€»ç»“èŠ‚ç‚¹")
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æœ€ç»ˆå“åº”ï¼Œé¿å…é‡å¤ç”Ÿæˆ
        existing_final_response = state.get("final_response")
        if existing_final_response:
            logger.debug("[summary_node] å·²å­˜åœ¨final_responseï¼Œè·³è¿‡é‡å¤ç”Ÿæˆ")
            return state
        
        # è·å–åŸå§‹ç”¨æˆ·é—®é¢˜å’Œæ‰§è¡Œè®¡åˆ’
        user_message = config["configurable"]["graph_request"].user_message
        original_plan = state.get("original_plan", [])
        total_steps = len(original_plan)
        
        # æ”¶é›†æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹çš„æ¶ˆæ¯å†å²
        messages = state.get("messages", [])
        execution_history = []
        
        # æ•´ç†æ‰§è¡Œå†å²ï¼ŒåŒ…æ‹¬è®¡åˆ’ã€æ‰§è¡Œæ­¥éª¤å’Œç»“æœ
        for message in messages:
            if hasattr(message, 'content') and message.content:
                content = message.content.strip()
                if content:  # åªæ”¶é›†éç©ºå†…å®¹
                    execution_history.append(f"- {content}")
        
        # æ„å»ºç»™LLMçš„æ€»ç»“æç¤º
        history_text = "\n".join(execution_history)  
        plan_text = "\n".join([f"   {i+1}. {step}" for i, step in enumerate(original_plan)])
        
        summary_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡æ€»ç»“åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹å®Œæ•´çš„æ‰§è¡Œå†å²ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä¸ªæ¸…æ™°ã€æœ‰ç”¨çš„ä»»åŠ¡å®Œæˆæ€»ç»“ã€‚

ğŸ“‹ **åŸå§‹ç”¨æˆ·é—®é¢˜**: {user_message}

ğŸ“ **æ‰§è¡Œè®¡åˆ’** ({total_steps} ä¸ªæ­¥éª¤):
{plan_text}

ğŸ“Š **å®Œæ•´æ‰§è¡Œå†å²**:
{history_text}

ğŸ¯ **æ€»ç»“è¦æ±‚**:
1. ç®€è¦æ¦‚è¿°ä»»åŠ¡å®Œæˆæƒ…å†µ
2. çªå‡ºæ˜¾ç¤ºå…³é”®çš„æ‰§è¡Œç»“æœå’Œæ•°æ®
3. å¦‚æœæœ‰å…·ä½“æ•°æ®ï¼ˆå¦‚æäº¤è®°å½•ã€ç»Ÿè®¡ä¿¡æ¯ç­‰ï¼‰ï¼Œè¯·æ¸…æ™°åœ°æ•´ç†å’Œå±•ç¤º
4. ä¿æŒä¸“ä¸šã€å‹å¥½çš„è¯­è°ƒ
5. å¦‚æœç”¨æˆ·å¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ“ä½œï¼Œæä¾›ç®€è¦å»ºè®®

è¯·ç”Ÿæˆä¸€ä¸ªç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„æœ€ç»ˆæ€»ç»“ã€‚"""

        try:
            # ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æ€»ç»“
            summary_response = await self.llm.ainvoke([
                HumanMessage(content=summary_prompt)
            ])
            
            if hasattr(summary_response, 'content') and summary_response.content:
                intelligent_summary = summary_response.content.strip()
                logger.debug(f"[summary_node] LLMç”Ÿæˆæ€»ç»“ï¼Œé•¿åº¦: {len(intelligent_summary)}")
            else:
                intelligent_summary = "ä»»åŠ¡å·²æˆåŠŸå®Œæˆï¼Œæ‰€æœ‰æ­¥éª¤éƒ½å·²æŒ‰è®¡åˆ’æ‰§è¡Œã€‚"
                logger.warning("[summary_node] LLMè¿”å›ç©ºå†…å®¹ï¼Œä½¿ç”¨é»˜è®¤æ€»ç»“")
                
        except Exception as e:
            logger.error(f"[summary_node] LLMæ€»ç»“å¤±è´¥: {e}")
            intelligent_summary = f"""ğŸ‰ **ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼**

âœ… æˆåŠŸå®Œæˆ {total_steps} ä¸ªè®¡åˆ’æ­¥éª¤ï¼Œæ‰€æœ‰é¢„å®šç›®æ ‡å‡å·²è¾¾æˆã€‚

ğŸ“‹ **æ‰§è¡Œæ¦‚å†µ**: æŒ‰ç…§æ—¢å®šè®¡åˆ’é€æ­¥æ‰§è¡Œï¼Œæ‰€æœ‰å·¥å…·è°ƒç”¨å’Œæ•°æ®å¤„ç†éƒ½å·²é¡ºåˆ©å®Œæˆã€‚

ğŸ’¡ å¦‚éœ€è¿›ä¸€æ­¥åˆ†ææˆ–æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘ŠçŸ¥ï¼"""

        # æ ¼å¼åŒ–æœ€ç»ˆæ€»ç»“æ˜¾ç¤º - ç¡®ä¿å‰åéƒ½æœ‰é€‚å½“çš„æ¢è¡Œ
        formatted_summary = f"\n\n---\n\nğŸ¯ **æœ€ç»ˆç»“æœ**\n\n{intelligent_summary}\n"
        self.log(config, formatted_summary)
        
        return {
            **state,
            "messages": state.get("messages", []) + [AIMessage(content=formatted_summary)],
            "final_response": formatted_summary
        }

class PlanAndExecuteAgentGraph(BasicGraph):
    """Plan and Execute Agent - æ™ºèƒ½è®¡åˆ’ç”Ÿæˆä¸æ‰§è¡Œç³»ç»Ÿ"""

    async def compile_graph(self, request: PlanAndExecuteAgentRequest):
        """ç¼–è¯‘å·¥ä½œæµå›¾"""
        node_builder = PlanAndExecuteAgentNode()
        logger.debug("ğŸš€ åˆå§‹åŒ–Plan and Execute Agent")
        await node_builder.setup(request)
        logger.debug(f"ğŸ”§ å·²åŠ è½½ {len(node_builder.tools)} ä¸ªå·¥å…·")

        graph_builder = StateGraph(PlanAndExecuteAgentState)
        last_edge = self.prepare_graph(graph_builder, node_builder)

        # æ·»åŠ æ ¸å¿ƒèŠ‚ç‚¹
        graph_builder.add_node("planner", node_builder.planner_node)
        graph_builder.add_node("executor", node_builder.executor_node)  
        graph_builder.add_node("replanner", node_builder.replanner_node)
        graph_builder.add_node("summary", node_builder.summary_node)
        
        # æ·»åŠ åŠ¨æ€æ­¥éª¤æ‰§è¡ŒåŒ…è£…èŠ‚ç‚¹
        async def step_executor_wrapper(state: PlanAndExecuteAgentState, config: RunnableConfig):
            """åŒ…è£…èŠ‚ç‚¹ï¼šåŠ¨æ€è®¾ç½®æ‰§è¡Œæ­¥éª¤æç¤º"""
            execution_prompt = state.get("execution_prompt", "è¯·å®Œæˆå½“å‰ä»»åŠ¡")
            
            # ç›´æ¥ä¼ é€’æ‰§è¡Œæç¤ºç»™ReactèŠ‚ç‚¹ï¼Œä¸æ˜¾ç¤ºé¢å¤–çš„çŠ¶æ€ä¿¡æ¯
            current_step_msg = HumanMessage(content=execution_prompt)
            
            return {
                **state,
                "messages": state.get("messages", []) + [current_step_msg]
            }
        
        graph_builder.add_node("step_executor_wrapper", step_executor_wrapper)
        
        # ä½¿ç”¨ç°æœ‰çš„ReActèŠ‚ç‚¹æ„å»ºæ–¹æ³•
        react_entry_node = await node_builder.build_react_nodes(
            graph_builder=graph_builder,
            composite_node_name="react_step_executor", 
            additional_system_prompt="ä½ æ˜¯ä»»åŠ¡æ‰§è¡ŒåŠ©æ‰‹ï¼Œä¸“æ³¨å®Œæˆç”¨æˆ·æœ€æ–°æ¶ˆæ¯ä¸­çš„å…·ä½“æ­¥éª¤ã€‚è¯·ä½¿ç”¨åˆé€‚çš„å·¥å…·å®Œæˆä»»åŠ¡ï¼Œå¹¶ç®€æ´åœ°æä¾›ç»“æœã€‚",
            next_node="replanner"
        )

        # è®¾ç½®å›¾è¾¹ç¼˜ - å®ç° Plan -> Execute -> Replan -> Execute å¾ªç¯
        graph_builder.add_edge(last_edge, "planner")                    # å¼€å§‹ -> è®¡åˆ’
        graph_builder.add_edge("planner", "executor")                   # è®¡åˆ’ -> å‡†å¤‡æ‰§è¡Œ
        graph_builder.add_edge("executor", "step_executor_wrapper")     # å‡†å¤‡æ‰§è¡Œ -> æ­¥éª¤åŒ…è£…
        graph_builder.add_edge("step_executor_wrapper", react_entry_node)  # æ­¥éª¤åŒ…è£… -> Reactæ‰§è¡Œ
        
        # æ‰‹åŠ¨æ·»åŠ ReactèŠ‚ç‚¹åˆ°replannerçš„è¿æ¥ï¼ˆå› ä¸ºbuild_react_nodesæ²¡æœ‰è‡ªåŠ¨å¤„ç†next_nodeå‚æ•°ï¼‰
        graph_builder.add_edge(react_entry_node, "replanner")          # Reactæ‰§è¡Œå®Œæˆ -> é‡æ–°è§„åˆ’
        
        # æ¡ä»¶è¾¹ï¼šé‡æ–°è§„åˆ’åå†³å®šç»§ç»­æ‰§è¡Œè¿˜æ˜¯ç»“æŸ
        async def debug_should_continue(state):
            result = await node_builder.should_continue(state)
            logger.debug(f"[debug_should_continue] è¿”å›: {result}")
            return result
        
        graph_builder.add_conditional_edges(
            "replanner",
            debug_should_continue,
            {
                "executor": "executor",   # ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
                "summary": "summary"      # ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæ€»ç»“
            }
        )
        
        graph_builder.add_edge("summary", END)

        logger.debug("âœ… Plan and Execute Agentç¼–è¯‘å®Œæˆ")
        
        graph = graph_builder.compile()
        return graph