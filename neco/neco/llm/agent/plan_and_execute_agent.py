import time
from typing import TypedDict, Annotated, List, Optional

from langchain_core.messages import BaseMessage, AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.constants import END
from langgraph.graph import StateGraph, add_messages
from neco.core.utils.template_loader import TemplateLoader
from pydantic import BaseModel, Field
from loguru import logger

from neco.llm.chain.entity import BasicLLMRequest, BasicLLMResponse, ToolsServer
from neco.llm.chain.graph import BasicGraph
from neco.llm.chain.node import ToolsNodes

class PlanAndExecuteAgentResponse(BasicLLMResponse):
    pass

class PlanAndExecuteAgentRequest(BasicLLMRequest):
    pass

class PlanAndExecuteAgentState(TypedDict):
    """çœŸæ­£çš„Plan and Execute AgentçŠ¶æ€ç®¡ç†"""
    messages: Annotated[List[BaseMessage], add_messages]
    graph_request: PlanAndExecuteAgentRequest
    
    # è®¡åˆ’ç›¸å…³
    original_plan: List[str]      # åŸå§‹è®¡åˆ’
    current_plan: List[str]       # å½“å‰å‰©ä½™æ­¥éª¤
    
    # æ‰§è¡Œç›¸å…³
    execution_prompt: Optional[str]  # å½“å‰æ­¥éª¤çš„æ‰§è¡Œæç¤º
    execution_count: int              # æ‰§è¡Œè®¡æ•°å™¨
    step_history: List[str]           # æ­¥éª¤æ‰§è¡Œå†å²ï¼Œç”¨äºæ£€æµ‹å¾ªç¯
    
    # æœ€ç»ˆç»“æœ
    final_response: Optional[str]

class Plan(BaseModel):
    """åŠ¨æ€è®¡åˆ’æ¨¡å‹"""
    steps: List[str] = Field(description="å½“å‰å‰©ä½™çš„æ‰§è¡Œæ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åº”è¯¥å…·ä½“æ˜ç¡®ä¸”å¯æ‰§è¡Œ")

class PlanResponse(BaseModel):
    """è®¡åˆ’å“åº”æ¨¡å‹"""
    plan: Plan = Field(description="ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’")
    reasoning: str = Field(description="è®¡åˆ’åˆ¶å®šçš„æ¨ç†è¿‡ç¨‹")

class ReplanResponse(BaseModel):
    """é‡æ–°è§„åˆ’å“åº”æ¨¡å‹"""
    updated_plan: Plan = Field(description="æ›´æ–°åçš„å‰©ä½™æ­¥éª¤")
    reasoning: str = Field(description="é‡æ–°è§„åˆ’çš„æ¨ç†è¿‡ç¨‹")
    is_complete: bool = Field(description="ä»»åŠ¡æ˜¯å¦å·²ç»å®Œæˆï¼Œæ— éœ€ç»§ç»­æ‰§è¡Œ")

class PlanAndExecuteAgentNode(ToolsNodes):
    """Plan and Execute Agent - æ™ºèƒ½è®¡åˆ’ç”Ÿæˆä¸æ‰§è¡Œ"""

    async def planner_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """åŠ¨æ€è®¡åˆ’ç”ŸæˆèŠ‚ç‚¹ - çœŸæ­£çš„Plan and Execute Agent"""
        
        user_message = config["configurable"]["graph_request"].user_message
        
        # åŠ¨æ€è®¡åˆ’ç”Ÿæˆæç¤º
        planning_prompt = TemplateLoader.render_template("prompts/plan_and_execute_agent/planning_prompt",{
            "user_message": user_message,
            "tools_description": self.get_tools_description()
        })

        plan_response = await self.structured_output_parser.parse_with_structured_output(
            user_message=planning_prompt,
            pydantic_class=PlanResponse
        )
        
        plan_steps = plan_response.plan.steps
        reasoning = plan_response.reasoning
        
        # æ”¹è¿›è§„åˆ’æ˜¾ç¤ºï¼Œè®©ç»“æ„æ›´æ¸…æ™°ï¼Œæ˜¾ç¤ºè¯¦ç»†è®¡åˆ’
        plan_display = f"ğŸ¯ **æ‰§è¡Œè®¡åˆ’å·²åˆ¶å®š** ({len(plan_steps)} ä¸ªæ­¥éª¤)\n\n"
        plan_display += f"ğŸ“ **è®¡åˆ’æ¨ç†**: {reasoning}\n\n"
        plan_display += "ğŸ“‹ **æ‰§è¡Œæ­¥éª¤**:\n\n"
        for i, step in enumerate(plan_steps, 1):
            plan_display += f"   **{i}.** {step}\n\n"
        plan_display += f"\n\nğŸš€ å¼€å§‹æ‰§è¡Œè®¡åˆ’...\n\n"
        
        return {
            "messages": [AIMessage(content=plan_display)],
            "original_plan": plan_steps,
            "current_plan": plan_steps,
            "execution_count": 0,
            "step_history": [],
            "final_response": None
        }

    async def executor_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        current_plan = state.get("current_plan", [])
        if not current_plan:
            # æ²¡æœ‰å¾…æ‰§è¡Œæ­¥éª¤ï¼Œç›´æ¥è¿›å…¥æ€»ç»“ - ä¸è®¾ç½®final_responseï¼Œè®©should_continueå†³å®š
            return {**state}
        
        current_step = current_plan[0]  # å–ç¬¬ä¸€ä¸ªå¾…æ‰§è¡Œæ­¥éª¤
        
        # è®°å½•å³å°†æ‰§è¡Œçš„æ­¥éª¤
        step_history = state.get("step_history", [])
        execution_count = state.get("execution_count", 0)

        execution_prompt = TemplateLoader.render_template("prompts/plan_and_execute_agent/execute_node_prompt",{
                "current_step": current_step,
                "user_message": config["configurable"]["graph_request"].user_message
            }
        )
        
        # æ›´æ–°æ‰§è¡Œè®¡æ•°å’Œæ­¥éª¤å†å²
        new_step_history = step_history + [current_step]
        new_execution_count = execution_count + 1
        
        # ä¼ é€’æ‰§è¡Œæç¤ºç»™ReactèŠ‚ç‚¹ä½¿ç”¨ï¼Œä¸æ·»åŠ é¢å¤–çš„æ˜¾ç¤ºæ¶ˆæ¯
        return {
            **state,
            "execution_prompt": execution_prompt,
            "step_history": new_step_history,
            "execution_count": new_execution_count
        }

    async def replanner_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """æ™ºèƒ½é‡æ–°è§„åˆ’èŠ‚ç‚¹ - åŸºäºæ‰§è¡Œç»“æœåæ€å¹¶è°ƒæ•´å‰©ä½™è®¡åˆ’"""
        
        current_plan = state.get("current_plan", [])
        original_plan = state.get("original_plan", [])
        step_history = state.get("step_history", [])
        execution_count = state.get("execution_count", 0)
        
        if not current_plan:
            # è®¡åˆ’ä¸ºç©ºï¼Œåªæ›´æ–°current_planï¼Œä¸ä¼ é€’ä»»ä½•æ¶ˆæ¯
            logger.debug("[replanner_node] è®¡åˆ’ä¸ºç©ºï¼Œå‡†å¤‡è¿›å…¥æ€»ç»“")
            return {
                "current_plan": []
            }
        
        # æ­»å¾ªç¯æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦é‡å¤æ‰§è¡Œç›¸åŒæ­¥éª¤
        current_step = current_plan[0]
        step_occurrences = step_history.count(current_step)
        
        # å¦‚æœåŒä¸€æ­¥éª¤æ‰§è¡Œè¶…è¿‡2æ¬¡ï¼Œå¼ºåˆ¶å®Œæˆä»»åŠ¡
        if step_occurrences >= 2:
            logger.warning(f"[replanner_node] æ£€æµ‹åˆ°å¾ªç¯: æ­¥éª¤ '{current_step}' å·²æ‰§è¡Œ {step_occurrences} æ¬¡ï¼Œå¼ºåˆ¶å®Œæˆä»»åŠ¡")
            
            loop_warning = f"\n\nâš ï¸ **æ£€æµ‹åˆ°é‡å¤æ‰§è¡Œæ¨¡å¼**\n\n"
            loop_warning += f"æ­¥éª¤ \"{current_step}\" å·²ç»æ‰§è¡Œäº† {step_occurrences} æ¬¡ï¼Œä¸ºé¿å…æ— é™å¾ªç¯ï¼Œä»»åŠ¡å°†è¢«æ ‡è®°ä¸ºå®Œæˆã€‚\n\n"
            loop_warning += "ğŸ“ **å»ºè®®**: å¦‚éœ€ç»§ç»­æ‰§è¡Œï¼Œè¯·é‡æ–°å®šä¹‰å…·ä½“çš„ã€å¯æ‰§è¡Œçš„æ­¥éª¤ã€‚\n\n"
            
            return {
                "messages": [AIMessage(content=loop_warning)],
                "current_plan": []
            }
        
        # å¦‚æœæ€»æ‰§è¡Œæ¬¡æ•°è¶…è¿‡åŸè®¡åˆ’çš„2å€ï¼Œä¹Ÿå¼ºåˆ¶å®Œæˆ
        max_iterations = len(original_plan) * 2 if original_plan else 20
        if execution_count >= max_iterations:
            logger.warning(f"[replanner_node] æ‰§è¡Œæ¬¡æ•° ({execution_count}) è¶…è¿‡é™åˆ¶ ({max_iterations})ï¼Œå¼ºåˆ¶å®Œæˆä»»åŠ¡")
            
            limit_warning = f"\n\nâš ï¸ **æ‰§è¡Œæ¬¡æ•°è¶…é™**\n\n"
            limit_warning += f"å·²æ‰§è¡Œ {execution_count} ä¸ªæ­¥éª¤ï¼Œè¶…è¿‡é¢„æœŸçš„ {max_iterations} æ­¥ï¼Œä»»åŠ¡å°†è¢«æ ‡è®°ä¸ºå®Œæˆã€‚\n\n"
            
            return {
                "messages": [AIMessage(content=limit_warning)],
                "current_plan": []
            }
        
        # è®¡ç®—æ‰§è¡Œè¿›åº¦ - æ­£ç¡®è®¡ç®—å·²å®Œæˆæ­¥éª¤æ•°
        total_steps = len(original_plan) if original_plan else 1
        completed_count = total_steps - len(current_plan) + 1  # +1 è¡¨ç¤ºåˆšå®Œæˆäº†ä¸€æ­¥
        
        # å‡†å¤‡æ¨¡æ¿å˜é‡ - åªè·å–æœ€è¿‘çš„éé‡å¤æ¶ˆæ¯å†…å®¹
        messages = state.get("messages", [])
        recent_messages = []
        seen_contents = set()
        
        # ä»åå¾€å‰éå†ï¼Œé¿å…é‡å¤å†…å®¹
        for msg in reversed(messages[-5:]):  # åªçœ‹æœ€è¿‘5æ¡æ¶ˆæ¯
            if hasattr(msg, 'content') and msg.content:
                content = msg.content.strip()
                if content and content not in seen_contents:
                    recent_messages.insert(0, content)  # ä¿æŒæ—¶é—´é¡ºåº
                    seen_contents.add(content)
        
        # ä½¿ç”¨æ¨¡æ¿æ„å»ºæ™ºèƒ½é‡æ–°è§„åˆ’æç¤º
        replan_prompt = TemplateLoader.render_template("prompts/plan_and_execute_agent/replan_prompt",{
            "user_message": config["configurable"]["graph_request"].user_message,
            "original_plan": original_plan,
            "current_plan": current_plan,
            "recent_messages": recent_messages,
            "step_history": step_history,
            "execution_count": execution_count
        })

        replan_response = await self.structured_output_parser.parse_with_structured_output(
            user_message=replan_prompt,
            pydantic_class=ReplanResponse
        )
        
        updated_steps = replan_response.updated_plan.steps
        reasoning = replan_response.reasoning
        is_complete = replan_response.is_complete

        logger.debug(f"[replanner_node] é‡æ–°è§„åˆ’ç»“æœ: is_complete={is_complete}, updated_steps={len(updated_steps)}")

        if is_complete or not updated_steps:
            # ä»»åŠ¡å®Œæˆ - æ¸…ç©ºcurrent_planï¼Œä¸æ·»åŠ ä»»ä½•æ¶ˆæ¯
            logger.debug("[replanner_node] ä»»åŠ¡å®Œæˆï¼Œæ¸…ç©ºè®¡åˆ’")
            return {
                "current_plan": []
            }
        else:
            # è¿˜æœ‰å‰©ä½™æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œ
            logger.debug(f"[replanner_node] è¿˜æœ‰ {len(updated_steps)} ä¸ªæ­¥éª¤å¾…æ‰§è¡Œ")
            
            # åªæœ‰å½“æ­¥éª¤å‘ç”Ÿå®é™…å˜åŒ–æ—¶æ‰æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
            expected_remaining = current_plan[1:] if len(current_plan) > 1 else []
            
            if updated_steps != expected_remaining:
                # è®¡åˆ’å‘ç”Ÿäº†è°ƒæ•´ï¼Œæ˜¾ç¤ºè°ƒæ•´ä¿¡æ¯
                progress_display = f"\n\nğŸ“Š **æ­¥éª¤ {completed_count}/{total_steps} å®Œæˆ**\n\n"
                progress_display += f"\n\nğŸ”„ **è®¡åˆ’å·²è°ƒæ•´**: {reasoning}\n\n"
                progress_display += f"\n\nğŸ“‹ **å‰©ä½™æ­¥éª¤**:\n\n"
                for i, step in enumerate(updated_steps, 1):
                    progress_display += f"   **{i}.** {step}\n\n"
                progress_display += f"\n\n"
                
                return {
                    "messages": [AIMessage(content=progress_display)],
                    "current_plan": updated_steps
                }
            else:
                # è®¡åˆ’æ²¡æœ‰å˜åŒ–ï¼Œé™é»˜æ›´æ–°çŠ¶æ€ï¼Œä¸æ·»åŠ æ¶ˆæ¯
                return {
                    "current_plan": updated_steps
                }

    async def should_continue(self, state: PlanAndExecuteAgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–ç»“æŸ - ç»Ÿä¸€åˆ¤æ–­é€»è¾‘ï¼Œé¿å…é‡å¤è¿›å…¥summary"""
        current_plan = state.get("current_plan", [])
        
        logger.debug(f"[should_continue] current_plané•¿åº¦: {len(current_plan)}")
        
        # åªåŸºäºcurrent_planåˆ¤æ–­ï¼šæ²¡æœ‰å‰©ä½™æ­¥éª¤å°±ç»“æŸæ‰§è¡Œ
        if not current_plan:
            logger.debug("[should_continue] æ²¡æœ‰å‰©ä½™æ­¥éª¤ï¼Œè¿”å› summary")
            return "summary"
        
        # å¦åˆ™ç»§ç»­æ‰§è¡Œ
        logger.debug("[should_continue] è¿˜æœ‰å‰©ä½™æ­¥éª¤ï¼Œè¿”å› executor") 
        return "executor"

    async def summary_node(self, state: PlanAndExecuteAgentState, config: RunnableConfig):
        """æœ€ç»ˆæ€»ç»“èŠ‚ç‚¹ - ä½¿ç”¨LLMæ™ºèƒ½æ€»ç»“æ‰§è¡Œè¿‡ç¨‹å’Œç»“æœ"""
        
        logger.debug("[summary_node] å¼€å§‹ç”Ÿæˆæœ€ç»ˆæ€»ç»“")
        
        # è·å–åŸå§‹ç”¨æˆ·é—®é¢˜å’Œæ‰§è¡Œè®¡åˆ’
        user_message = config["configurable"]["graph_request"].user_message
        original_plan = state.get("original_plan", [])
        total_steps = len(original_plan)
        
        # æ”¶é›†æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹çš„æ¶ˆæ¯å†å²ï¼Œå»é‡å¤„ç†
        messages = state.get("messages", [])
        execution_history = []
        seen_contents = set()
        
        # æ•´ç†æ‰§è¡Œå†å²ï¼Œè¿‡æ»¤é‡å¤å†…å®¹
        for message in messages:
            if hasattr(message, 'content') and message.content:
                content = message.content.strip()
                # è¿‡æ»¤æ‰ç©ºå†…å®¹ã€é‡å¤å†…å®¹ä»¥åŠåŒ…å«"æœ€ç»ˆç»“æœ"çš„å†…å®¹ï¼ˆé¿å…åµŒå¥—ï¼‰
                if (content and 
                    content not in seen_contents and 
                    "ğŸ¯ **æœ€ç»ˆç»“æœ**" not in content):
                    execution_history.append(f"- {content}")
                    seen_contents.add(content)
        
        # ä½¿ç”¨æ¨¡æ¿æ„å»ºæ€»ç»“æç¤º
        summary_prompt = TemplateLoader.render_template("prompts/plan_and_execute_agent/summary_prompt",{
            "user_message": user_message,
            "total_steps": total_steps,
            "original_plan": original_plan,
            "execution_history": execution_history
        })

        # ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æ€»ç»“
        summary_response = await self.llm.ainvoke([
            HumanMessage(content=summary_prompt)
        ])

        # æ ¼å¼åŒ–æœ€ç»ˆæ€»ç»“æ˜¾ç¤º
        formatted_summary = f"\n\nğŸ¯ **æœ€ç»ˆç»“æœ**\n\n{summary_response.content}\n\n"
        
        logger.debug("[summary_node] æ€»ç»“ç”Ÿæˆå®Œæˆ")
        
        return {
            "messages": [AIMessage(content=formatted_summary)],
            "final_response": formatted_summary
        }

class PlanAndExecuteAgentGraph(BasicGraph):
    """Plan and Execute Agent - æ™ºèƒ½è®¡åˆ’ç”Ÿæˆä¸æ‰§è¡Œç³»ç»Ÿ"""

    async def compile_graph(self, request: PlanAndExecuteAgentRequest):
        """ç¼–è¯‘å·¥ä½œæµå›¾"""
        node_builder = PlanAndExecuteAgentNode()
        await node_builder.setup(request)

        graph_builder = StateGraph(PlanAndExecuteAgentState)
        last_edge = self.prepare_graph(graph_builder, node_builder)

        # æ·»åŠ æ ¸å¿ƒèŠ‚ç‚¹
        graph_builder.add_node("planner", node_builder.planner_node)
        graph_builder.add_node("executor", node_builder.executor_node)  
        graph_builder.add_node("replanner", node_builder.replanner_node)
        graph_builder.add_node("summary", node_builder.summary_node)
        
        # ä½¿ç”¨ç°æœ‰çš„ReActèŠ‚ç‚¹æ„å»ºæ–¹æ³•
        react_entry_node = await node_builder.build_react_nodes(
            graph_builder=graph_builder,
            composite_node_name="react_step_executor", 
            additional_system_prompt="ä½ æ˜¯ä»»åŠ¡æ‰§è¡ŒåŠ©æ‰‹ï¼Œä¸“æ³¨å®Œæˆç”¨æˆ·æœ€æ–°æ¶ˆæ¯ä¸­çš„å…·ä½“æ­¥éª¤ã€‚è¯·ä½¿ç”¨åˆé€‚çš„å·¥å…·å®Œæˆä»»åŠ¡ï¼Œå¹¶ç®€æ´åœ°æä¾›ç»“æœã€‚",
        )

        # è®¾ç½®å›¾è¾¹ç¼˜ - å®ç° Plan -> Execute -> Replan -> Execute å¾ªç¯
        graph_builder.add_edge(last_edge, "planner")                    # å¼€å§‹ -> è®¡åˆ’
        graph_builder.add_edge("planner", "executor")                   # è®¡åˆ’ -> å‡†å¤‡æ‰§è¡Œ
        graph_builder.add_edge("executor", "react_step_executor_wrapper")     # å‡†å¤‡æ‰§è¡Œ -> æ­¥éª¤åŒ…è£…
        graph_builder.add_edge("react_step_executor_wrapper", "replanner")  # æ­¥éª¤åŒ…è£… -> é‡æ–°è§„åˆ’
        
        graph_builder.add_conditional_edges(
            "replanner",
            node_builder.should_continue,
            {
                "executor": "executor",   # ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
                "summary": "summary"      # ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæ€»ç»“
            }
        )
        
        graph_builder.add_edge("summary", END)

        graph = graph_builder.compile()
        return graph