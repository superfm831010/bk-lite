import json
import uuid
from datetime import datetime
from typing import Dict, Any
from dataclasses import dataclass
from enum import Enum

from loguru import logger
from sanic import Blueprint, json as sanic_json
from sanic_ext import validate
from sanic.response import ResponseStream

from neco.sanic.auth.api_auth import auth
from neco.llm.agent.lats_agent import LatsAgentRequest, LatsAgentGraph
from src.services.agent_service import AgentService

lats_agent_router = Blueprint("lats_agent_router", url_prefix="/agent")


@lats_agent_router.post("/invoke_lats_agent")
@auth.login_required
@validate(json=LatsAgentRequest)
async def invoke_lats_agent(request, body: LatsAgentRequest):
    """åŒæ­¥è°ƒç”¨ LATS Agent"""
    try:
        graph = LatsAgentGraph()
        AgentService.prepare_request(body)

        logger.info(f"æ‰§è¡Œ LATS Agent: {body.user_message}")
        result = await graph.execute(body)

        logger.info(f"æ‰§è¡ŒæˆåŠŸï¼Œè¯„åˆ†: {getattr(result, 'score', 'N/A')}")
        return sanic_json(result.model_dump())

    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return sanic_json({"error": "æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"}, status=500)


@lats_agent_router.post("/invoke_lats_agent_sse")
@auth.login_required
@validate(json=LatsAgentRequest)
async def invoke_lats_agent_sse(request, body: LatsAgentRequest):
    """æµå¼è°ƒç”¨ LATS Agent"""
    try:
        workflow = LatsAgentGraph()
        AgentService.prepare_request(body)
        chat_id = str(uuid.uuid4())

        logger.info(f"å¯åŠ¨ LATS SSE: {body.user_message}, chat_id: {chat_id}")

        return ResponseStream(
            lambda res: stream_lats_response(
                workflow, body, chat_id, body.model, res),
            content_type="text/event-stream; charset=utf-8",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*"
            }
        )

    except Exception as e:
        logger.error(f"SSE å¯åŠ¨å¤±è´¥: {e}", exc_info=True)
        return sanic_json({"error": "å¯åŠ¨å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"}, status=500)


@dataclass
class LatsSSEConfig:
    """LATS SSE æ˜¾ç¤ºé…ç½®"""
    
    # æ˜¾ç¤ºé€‰é¡¹
    show_search_details: bool = True
    show_evaluation_progress: bool = True
    show_timing: bool = True
    enable_emojis: bool = True
    
    # å†…å®¹é•¿åº¦æ§åˆ¶
    candidate_content_max_length: int = 150
    evaluation_summary_max_length: int = 200
    
    # è‡ªå®šä¹‰æ˜¾ç¤ºæ–‡æœ¬
    phase_texts: Dict[str, str] = None
    
    def __post_init__(self):
        if self.phase_texts is None:
            self.phase_texts = {
                "analyzing": "ğŸ§  æ­£åœ¨æ™ºèƒ½åˆ†ææ‚¨çš„é—®é¢˜...",
                "searching": "ğŸŒ³ å¼€å§‹æ™ºèƒ½æ ‘æœç´¢ï¼Œå¯»æ‰¾æœ€ä¼˜è§£ç­”",
                "generating": "ğŸ’¡ ç”Ÿæˆå¤šä¸ªè§£å†³æ–¹æ¡ˆå€™é€‰",
                "evaluating": "ğŸ“Š è¯„ä¼°æ–¹æ¡ˆè´¨é‡",
                "optimizing": "âš¡ å‘ç°æ›´ä¼˜æ–¹æ¡ˆï¼Œç»§ç»­æ·±åº¦æœç´¢",
                "synthesizing": "âœ¨ æ•´åˆæœ€ä½³ç­”æ¡ˆ",
                "completed": "ğŸ‰ æ™ºèƒ½æœç´¢å®Œæˆ"
            }


class LatsExecutionPhase(Enum):
    """LATS æ‰§è¡Œé˜¶æ®µ"""
    ANALYZING = "analyzing"
    INITIAL_SEARCH = "initial_search"
    TREE_EXPANSION = "tree_expansion"
    EVALUATION = "evaluation"
    OPTIMIZATION = "optimization"
    SYNTHESIS = "synthesis"
    COMPLETED = "completed"


class LatsSSEFormatter:
    """LATS Agent SSE ä¼˜é›…æ ¼å¼åŒ–å™¨"""
    
    def __init__(self, chat_id: str, model: str, config: LatsSSEConfig = None):
        self.chat_id = chat_id
        self.model = model
        self.config = config or LatsSSEConfig()
        self.created_time = int(datetime.now().timestamp())
        self.current_phase = LatsExecutionPhase.ANALYZING
        self.search_iteration = 0
        self.total_candidates = 0
        self.best_score = 0.0
        self.start_time = datetime.now()
        
    def _create_base_response(self, 
                              delta_content: str = None, 
                              finish_reason: str = None,
                              metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ›å»ºåŸºç¡€ SSE å“åº”"""
        response = {
            "id": self.chat_id,
            "object": "chat.completion.chunk", 
            "created": self.created_time,
            "model": self.model,
            "choices": [{
                "delta": {"role": "assistant"},
                "index": 0,
                "finish_reason": finish_reason
            }],
            # LATS ç‰¹å®šå…ƒæ•°æ®
            "metis_metadata": {
                "execution_phase": self.current_phase.value,
                "search_iteration": self.search_iteration,
                "total_candidates": self.total_candidates,
                "best_score": self.best_score,
                **(metadata or {})
            }
        }
        
        if delta_content is not None:
            response["choices"][0]["delta"]["content"] = delta_content
            
        return response
    
    def _format_sse_data(self, response: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ– SSE æ•°æ®"""
        json_str = json.dumps(response, ensure_ascii=False, separators=(',', ':'))
        return f"data: {json_str}\n\n"
    
    def format_phase_transition(self, phase: LatsExecutionPhase) -> str:
        """æ ¼å¼åŒ–é˜¶æ®µè½¬æ¢"""
        self.current_phase = phase
        content = self.config.phase_texts.get(phase.value, f"è¿›å…¥ {phase.value} é˜¶æ®µ")
        
        response = self._create_base_response(
            delta_content=f"\n{content}\n",
            metadata={"phase_transition": True}
        )
        return self._format_sse_data(response)
    
    def format_search_iteration(self, iteration: int) -> str:
        """æ ¼å¼åŒ–æœç´¢è¿­ä»£å¼€å§‹"""
        self.search_iteration = iteration
        self.current_phase = LatsExecutionPhase.TREE_EXPANSION
        
        if iteration == 1:
            content = f"ğŸ¯ **å¯åŠ¨æ™ºèƒ½æœç´¢** - ç¬¬ {iteration} è½®æ¢ç´¢"
        else:
            content = f"ğŸ” **æ·±åº¦æœç´¢** - ç¬¬ {iteration} è½®ä¼˜åŒ– (å·²æ‰¾åˆ° {self.best_score:.1f}/10 åˆ†æ–¹æ¡ˆ)"
            
        response = self._create_base_response(
            delta_content=f"\n{content}\n",
            metadata={"search_iteration": iteration}
        )
        return self._format_sse_data(response)
    
    def format_candidate_generation(self, index: int, total: int) -> str:
        """æ ¼å¼åŒ–å€™é€‰ç”Ÿæˆè¿›åº¦"""
        content = f"ğŸ’¡ æ­£åœ¨ç”Ÿæˆæ–¹æ¡ˆ {index}/{total}..."
        
        response = self._create_base_response(
            delta_content=content,
            metadata={
                "candidate_generation": True,
                "progress": f"{index}/{total}"
            }
        )
        return self._format_sse_data(response)
    
    def format_evaluation_start(self, candidate_count: int) -> str:
        """æ ¼å¼åŒ–è¯„ä¼°å¼€å§‹"""
        self.current_phase = LatsExecutionPhase.EVALUATION
        self.total_candidates += candidate_count
        
        content = f"\nğŸ“Š **æ™ºèƒ½è¯„ä¼°** - åˆ†æ {candidate_count} ä¸ªå€™é€‰æ–¹æ¡ˆ\n"
        
        response = self._create_base_response(
            delta_content=content,
            metadata={"evaluation_start": True, "candidate_count": candidate_count}
        )
        return self._format_sse_data(response)
    
    def format_evaluation_result(self, index: int, score: float, is_solution: bool) -> str:
        """æ ¼å¼åŒ–å•ä¸ªè¯„ä¼°ç»“æœ"""
        self.best_score = max(self.best_score, score)
        
        if is_solution:
            content = f"ğŸ‰ å€™é€‰ {index}: **{score:.1f}/10** â­ ä¼˜è´¨è§£å†³æ–¹æ¡ˆ"
        elif score >= 8.0:
            content = f"âœ¨ å€™é€‰ {index}: **{score:.1f}/10** é«˜è´¨é‡ç­”æ¡ˆ"
        elif score >= 6.0:
            content = f"ğŸ‘ å€™é€‰ {index}: **{score:.1f}/10** è‰¯å¥½æ–¹æ¡ˆ"
        else:
            content = f"ğŸ“ å€™é€‰ {index}: **{score:.1f}/10** å¾…ä¼˜åŒ–"
            
        response = self._create_base_response(
            delta_content=content,
            metadata={
                "evaluation_result": True,
                "score": score,
                "is_solution": is_solution
            }
        )
        return self._format_sse_data(response)
    
    def format_search_summary(self, best_score: float, solutions_found: int) -> str:
        """æ ¼å¼åŒ–æœç´¢è½®æ¬¡æ€»ç»“"""
        self.best_score = max(self.best_score, best_score)
        
        if solutions_found > 0:
            content = f"\nğŸ† **æœ¬è½®æœ€ä½³: {best_score:.1f}/10** | âœ… å‘ç° {solutions_found} ä¸ªè§£å†³æ–¹æ¡ˆ"
        elif best_score >= 8.0:
            content = f"\nâ­ **æœ¬è½®æœ€ä½³: {best_score:.1f}/10** | ğŸ” ç»§ç»­å¯»æ‰¾æ›´ä¼˜æ–¹æ¡ˆ"
        else:
            content = f"\nğŸ“Š **æœ¬è½®æœ€ä½³: {best_score:.1f}/10** | âš¡ æ‰©å±•æœç´¢ç©ºé—´"
            
        response = self._create_base_response(
            delta_content=content,
            metadata={
                "search_summary": True,
                "round_best_score": best_score,
                "solutions_found": solutions_found
            }
        )
        return self._format_sse_data(response)
    
    def format_final_synthesis(self) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆåˆæˆé˜¶æ®µ"""
        self.current_phase = LatsExecutionPhase.SYNTHESIS
        
        elapsed = (datetime.now() - self.start_time).total_seconds()
        content = f"\nâœ¨ **æ™ºèƒ½æœç´¢å®Œæˆ** ({elapsed:.1f}s) | ğŸ¯ ä¸ºæ‚¨æ•´ç†æœ€ä½³ç­”æ¡ˆ..."
        
        response = self._create_base_response(
            delta_content=content,
            metadata={"final_synthesis": True, "elapsed_time": elapsed}
        )
        return self._format_sse_data(response)
    
    def format_tool_execution(self, tool_name: str) -> str:
        """æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œ"""
        display_name = {
            "naive_rag_search": "çŸ¥è¯†åº“æœç´¢",
            "web_search": "ç½‘ç»œæœç´¢"
        }.get(tool_name, tool_name)
        
        content = f"ğŸ”§ æ­£åœ¨ä½¿ç”¨ **{display_name}**"
        
        response = self._create_base_response(
            delta_content=content,
            metadata={"tool_execution": True, "tool_name": tool_name}
        )
        return self._format_sse_data(response)


async def stream_lats_response(workflow, body: Dict[str, Any], chat_id: str, model: str, res) -> None:
    """LATS Agent ä¼˜é›…æµå¼å“åº”"""
    formatter = LatsSSEFormatter(chat_id, model)
    sent_contents = set()
    has_shown_final_synthesis = False
    
    try:
        logger.info(f"[LATS SSE] å¼€å§‹ä¼˜é›…æµå¼å¤„ç†ï¼Œchat_id: {chat_id}")
        
        # 1. åˆå§‹åˆ†æé˜¶æ®µ
        start_content = formatter.format_phase_transition(LatsExecutionPhase.ANALYZING)
        await res.write(start_content.encode('utf-8'))
        
        stream_iter = await workflow.stream(body)
        
        async for chunk in stream_iter:
            if not chunk:
                continue
            
            # å¤„ç†æœ€ç»ˆçŠ¶æ€ - ç›´æ¥è¾“å‡ºç­”æ¡ˆ
            if _is_final_state(chunk):
                if not has_shown_final_synthesis:
                    synthesis_msg = formatter.format_final_synthesis()
                    await res.write(synthesis_msg.encode('utf-8'))
                    has_shown_final_synthesis = True
                
                await _handle_final_state_elegant(res, chunk, formatter, sent_contents)
                continue
            
            # å¤„ç†èŠ‚ç‚¹è½¬æ¢å’Œè¯„ä¼°ç»“æœ
            if isinstance(chunk, dict):
                # è¯„ä¼°ç»“æœå¤„ç†
                if 'evaluation_results' in chunk:
                    eval_results = chunk['evaluation_results']
                    if eval_results:
                        # æ˜¾ç¤ºè¯„ä¼°å¼€å§‹
                        eval_start_msg = formatter.format_evaluation_start(len(eval_results))
                        await res.write(eval_start_msg.encode('utf-8'))
                        
                        # æ˜¾ç¤ºæ¯ä¸ªè¯„ä¼°ç»“æœ
                        for i, result in enumerate(eval_results, 1):
                            score = result.get('score', 0)
                            is_solution = result.get('found_solution', False)
                            eval_result_msg = formatter.format_evaluation_result(i, score, is_solution)
                            await res.write(eval_result_msg.encode('utf-8'))
                        
                        # æ˜¾ç¤ºæœ¬è½®æ€»ç»“
                        best_score = max(r.get('score', 0) for r in eval_results)
                        solutions_count = sum(1 for r in eval_results if r.get('found_solution', False))
                        summary_msg = formatter.format_search_summary(best_score, solutions_count)
                        await res.write(summary_msg.encode('utf-8'))
                    continue
                
                # èŠ‚ç‚¹è½¬æ¢å¤„ç†
                node_keys = list(chunk.keys())
                if len(node_keys) == 1:
                    node_name = node_keys[0]
                    
                    if node_name == 'expand':
                        # æœç´¢è¿­ä»£
                        formatter.search_iteration += 1
                        iteration_msg = formatter.format_search_iteration(formatter.search_iteration)
                        await res.write(iteration_msg.encode('utf-8'))
                        continue
                    
                    elif node_name == 'generate_initial_response':
                        # åˆå§‹å“åº”ç”Ÿæˆ
                        initial_msg = formatter.format_phase_transition(LatsExecutionPhase.INITIAL_SEARCH)
                        await res.write(initial_msg.encode('utf-8'))
                        continue
                    
                    elif node_name == 'tools':
                        # å·¥å…·æ‰§è¡Œ
                        tool_name = _get_tool_name(chunk[node_name])
                        tool_msg = formatter.format_tool_execution(tool_name)
                        await res.write(tool_msg.encode('utf-8'))
                        continue
            
            # å¤„ç†æ¶ˆæ¯æµ - åªè¾“å‡ºé‡è¦å†…å®¹
            if isinstance(chunk, (tuple, list)) and len(chunk) > 0:
                message = chunk[0]
                if not message:
                    continue
                
                message_type = type(message).__name__
                
                # AIMessageChunk - ç›´æ¥æµå¼è¾“å‡º
                if message_type == "AIMessageChunk":
                    if hasattr(message, 'content') and message.content:
                        content_data = formatter._format_sse_data({
                            "id": chat_id,
                            "object": "chat.completion.chunk",
                            "created": formatter.created_time,
                            "model": model,
                            "choices": [{
                                "delta": {"role": "assistant", "content": message.content},
                                "index": 0,
                                "finish_reason": None
                            }]
                        })
                        await res.write(content_data.encode('utf-8'))
                    continue
                
                # AIMessage - è¿‡æ»¤å¹¶ä¼˜é›…æ˜¾ç¤º
                elif message_type == "AIMessage":
                    content = _extract_elegant_ai_content(message)
                    if content and content not in sent_contents:
                        content_data = formatter._format_sse_data({
                            "id": chat_id,
                            "object": "chat.completion.chunk", 
                            "created": formatter.created_time,
                            "model": model,
                            "choices": [{
                                "delta": {"role": "assistant", "content": content},
                                "index": 0,
                                "finish_reason": None
                            }]
                        })
                        await res.write(content_data.encode('utf-8'))
                        sent_contents.add(content)
        
        # å‘é€å®Œæˆæ ‡å¿—
        await _write_sse_end(res, chat_id, formatter.created_time, model)
        
        logger.info(f"[LATS SSE] ä¼˜é›…æµå¼å¤„ç†å®Œæˆï¼Œchat_id: {chat_id}ï¼Œæœç´¢è½®æ¬¡: {formatter.search_iteration}")
        
    except Exception as e:
        logger.error(f"[LATS SSE] å¤„ç†å‡ºé”™: {str(e)}", exc_info=True)
        error_msg = formatter._format_sse_data({
            "id": chat_id,
            "object": "chat.completion.chunk",
            "created": formatter.created_time, 
            "model": model,
            "choices": [{
                "delta": {"role": "assistant", "content": "\nâŒ **å¤„ç†é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•**"},
                "index": 0,
                "finish_reason": "stop"
            }]
        })
        await res.write(error_msg.encode('utf-8'))


async def _handle_final_state_elegant(res, chunk, formatter: LatsSSEFormatter, sent_contents: set):
    """ä¼˜é›…å¤„ç†æœ€ç»ˆçŠ¶æ€ - åªè¾“å‡ºæ¸…æ´çš„ç­”æ¡ˆ"""
    messages = chunk.get('messages', [])
    if not messages:
        return
    
    final_msg = messages[-1]
    if hasattr(final_msg, 'content') and final_msg.content:
        msg_type = type(final_msg).__name__
        if msg_type not in ['SystemMessage', 'HumanMessage']:
            # æ¸…ç†å’Œæ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆ
            content = _clean_final_answer(final_msg.content)
            if content and content not in sent_contents:
                content_data = formatter._format_sse_data({
                    "id": formatter.chat_id,
                    "object": "chat.completion.chunk",
                    "created": formatter.created_time,
                    "model": formatter.model,
                    "choices": [{
                        "delta": {"role": "assistant", "content": f"\n\n{content}"},
                        "index": 0,
                        "finish_reason": None
                    }]
                })
                await res.write(content_data.encode('utf-8'))
                sent_contents.add(content)


def _extract_elegant_ai_content(message) -> str:
    """æå–ä¼˜é›…çš„AIæ¶ˆæ¯å†…å®¹ - è¿‡æ»¤æŠ€æœ¯ç»†èŠ‚"""
    try:
        if not hasattr(message, 'content'):
            return ""
        
        content = message.content.strip()
        if not content:
            return ""
        
        # è¿‡æ»¤æŠ€æœ¯æ€§å†…å®¹
        filter_keywords = [
            '"reflections"', '"score"', '"found_solution"', 
            "è¯„åˆ†ï¼š", "/10", "ç½®ä¿¡åº¦:", "å€™é€‰", "è¯„ä¼°",
            "ğŸ” **ç”Ÿæˆå€™é€‰æ–¹æ¡ˆ", "ğŸ“Š **è¯„ä¼°", "âœ… å€™é€‰"
        ]
        
        if any(keyword in content for keyword in filter_keywords):
            return ""
        
        # è¿‡æ»¤è¿‡çŸ­æˆ–è¿‡äºæŠ€æœ¯æ€§çš„å†…å®¹
        if len(content) < 20 or content.startswith("æ­£åœ¨"):
            return ""
        
        return content
        
    except Exception as e:
        logger.debug(f"[LATS SSE] å†…å®¹æå–å¤±è´¥: {e}")
        return ""


def _clean_final_answer(content: str) -> str:
    """æ¸…ç†æœ€ç»ˆç­”æ¡ˆï¼Œç§»é™¤æŠ€æœ¯ç»†èŠ‚"""
    try:
        lines = []
        for line in content.split('\n'):
            line = line.strip()
            if not line:
                continue
            
            # è¿‡æ»¤æŠ€æœ¯æ€§è¡Œ
            if any(keyword in line for keyword in ['è¯„åˆ†', 'score', 'ç½®ä¿¡åº¦', 'åæ€', 'reflection']):
                continue
                
            lines.append(line)
        
        return '\n\n'.join(lines) if lines else content
        
    except Exception:
        return content


def _get_tool_name(data) -> str:
    """è·å–å·¥å…·åç§°"""
    try:
        if isinstance(data, dict) and 'name' in data:
            tool_mapping = {
                "naive_rag_search": "çŸ¥è¯†åº“æœç´¢",
                "web_search": "ç½‘ç»œæœç´¢",
            }
            return tool_mapping.get(data['name'], data['name'])

        if hasattr(data, 'name') and data.name:
            return data.name

        return "å·¥å…·"
    except Exception:
        return "å·¥å…·"


def _format_content(content: str) -> str:
    """æ ¼å¼åŒ–å†…å®¹"""
    lines = [line.strip() for line in content.split('\n') if line.strip()]
    return '\n\n'.join(lines)


def _is_final_state(chunk) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ç»ˆçŠ¶æ€"""
    return isinstance(chunk, dict) and 'messages' in chunk and 'root' in chunk


async def _write_sse_end(res, chat_id: str, created: int, model: str):
    """å†™å…¥SSEç»“æŸæ ‡å¿—"""
    end_response = {
        "id": chat_id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [{"delta": {}, "index": 0, "finish_reason": "stop"}]
    }
    json_str = json.dumps(end_response, ensure_ascii=False, separators=(',', ':'))
    await res.write(f"data: {json_str}\n\n".encode('utf-8'))
    await res.write("data: [DONE]\n\n".encode('utf-8'))
