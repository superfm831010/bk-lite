"""
LATS Agent SSE å¤„ç†å™¨

è´Ÿè´£å¤„ç† LATS Agent çš„æµå¼è¾“å‡ºï¼Œå°†æœç´¢è¿‡ç¨‹è½¬æ¢ä¸ºä¼˜é›…çš„ SSE å“åº”
"""
import asyncio
import json
import re
from typing import Dict, Any, AsyncGenerator, List
from datetime import datetime

from sanic.log import logger
from src.api.agent.lats_sse_formatter import LatsSSEFormatter


async def stream_lats_response(
    workflow,
    body: Dict[str, Any],
    chat_id: str,
    model: str,
    res
):
    """
    æµå¼å¤„ç† LATS Agent å“åº”
    æä¾›ä¼˜é›…çš„æ ‘æœç´¢è¿‡ç¨‹å¯è§†åŒ–

    Args:
        workflow: LATSå·¥ä½œæµå®ä¾‹
        body: è¯·æ±‚ä½“
        chat_id: èŠå¤©ID  
        model: æ¨¡å‹åç§°
        res: Sanic ResponseStream å¯¹è±¡
    """
    created = int(datetime.now().timestamp())
    formatter = LatsSSEFormatter(chat_id, model)
    sent_contents = set()  # ç”¨äºå»é‡

    # æœç´¢çŠ¶æ€è·Ÿè¸ª
    search_stats = {
        "iteration": 0,
        "tree_height": 0,
        "nodes_explored": 0,
        "best_score": 0.0,
        "solution_found": False,
        "in_tool_call": False,
        "current_tool": None
    }

    try:
        logger.info(f"[LATS SSE] å¼€å§‹æµå¼å¤„ç†ï¼Œchat_id: {chat_id}")

        # å‘é€åˆå§‹åŒ–æ¶ˆæ¯
        init_content = formatter.format_initialization()
        await res.write(init_content)
        await asyncio.sleep(0.3)

        # è·å–æµå¼è¿­ä»£å™¨
        stream_iter = await workflow.stream(body)

        # è·Ÿè¸ªå½“å‰å¤„ç†é˜¶æ®µ
        current_phase = "init"
        tool_calls_buffer = []
        candidate_evaluations = []

        async for chunk in stream_iter:
            logger.debug(f"[LATS SSE] æ”¶åˆ° chunk: {type(chunk)}")

            if not chunk or chunk is None:
                logger.debug(f"[LATS SSE] è·³è¿‡ç©ºçš„æˆ–Noneçš„chunk")
                continue

            # chunk æ˜¯ä¸€ä¸ª tupleï¼ŒåŒ…å«æ¶ˆæ¯å¯¹è±¡
            if isinstance(chunk, (tuple, list)) and len(chunk) > 0:
                message = chunk[0]

                if message is None:
                    logger.debug(f"[LATS SSE] è·³è¿‡Noneæ¶ˆæ¯")
                    continue

                # åˆ†ææ¶ˆæ¯å†…å®¹ï¼Œç¡®å®šå½“å‰é˜¶æ®µ
                content = _extract_message_content(message)
                logger.debug(
                    f"[LATS SSE] æå–åˆ°å†…å®¹: {content[:100]}..." if content else "[LATS SSE] å†…å®¹ä¸ºç©º")

                if not content:
                    continue

                # æ™ºèƒ½è¯†åˆ«æœç´¢é˜¶æ®µå¹¶ç”Ÿæˆç›¸åº”çš„ SSE å†…å®¹
                sse_content = await _process_lats_message(
                    content, message, formatter, search_stats, current_phase
                )

                if sse_content:
                    # é¿å…é‡å¤å‘é€ç›¸åŒçš„å†…å®¹
                    content_hash = hash(sse_content)
                    if content_hash not in sent_contents:
                        await res.write(sse_content)
                        sent_contents.add(content_hash)
                        logger.info(
                            f"[LATS SSE] å‘é€å†…å®¹: {_extract_content_preview(sse_content)}")

                        # æ ¹æ®å†…å®¹ç±»å‹è°ƒæ•´å»¶è¿Ÿ
                        if "æœç´¢è¿­ä»£" in sse_content:
                            await asyncio.sleep(0.4)
                        elif "è¯„ä¼°" in sse_content:
                            await asyncio.sleep(0.3)
                        elif "å·¥å…·" in sse_content:
                            await asyncio.sleep(0.2)
                        else:
                            await asyncio.sleep(0.1)

        # å‘é€å®Œæˆæ¶ˆæ¯
        completion_content = formatter.format_completion(search_stats)
        await res.write(completion_content)

        # å‘é€ç»“æŸæ ‡å¿—
        end_response = {
            "id": chat_id,
            "object": "chat.completion.chunk",
            "created": created,
            "model": model,
            "choices": [{
                "delta": {},
                "index": 0,
                "finish_reason": "stop"
            }]
        }

        json_str = json.dumps(
            end_response, ensure_ascii=False, separators=(',', ':'))
        await res.write(f"data: {json_str}\n\n")
        await res.write("data: [DONE]\n\n")

        logger.info(f"[LATS SSE] æµå¼å¤„ç†å®Œæˆï¼Œchat_id: {chat_id}")

    except Exception as e:
        logger.error(f"[LATS SSE] å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
        # å‘é€ä¼˜é›…çš„é”™è¯¯æ¶ˆæ¯
        error_content = f"\n\n---\n\nâŒ **LATS æœç´¢è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜**\n\nğŸ”§ **é”™è¯¯è¯¦æƒ…ï¼š**\n{str(e)}\n\nğŸ’¡ **å»ºè®®ï¼š**\nè¯·ç¨åé‡è¯•ï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©"
        error_sse = _create_sse_data(
            chat_id, created, model, error_content, finish_reason="stop")
        await res.write(error_sse)


async def _process_lats_message(
    content: str,
    message: Any,
    formatter: LatsSSEFormatter,
    search_stats: Dict[str, Any],
    current_phase: str
) -> str:
    """
    å¤„ç† LATS æ¶ˆæ¯ï¼Œè¿”å›æ ¼å¼åŒ–çš„ SSE å†…å®¹
    """
    try:
        message_type = type(message).__name__
        logger.debug(
            f"[LATS SSE] å¤„ç†æ¶ˆæ¯ç±»å‹: {message_type}, å†…å®¹é•¿åº¦: {len(content)}")

        # æ£€æµ‹ç‰¹å®šçš„ LATS é˜¶æ®µ

        # 1. æ£€æµ‹åˆå§‹å“åº”ç”Ÿæˆé˜¶æ®µ
        if _is_initial_generation_message(content):
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°åˆå§‹ç”Ÿæˆé˜¶æ®µ")
            return formatter.format_initial_generation_start()

        # 2. æ£€æµ‹å·¥å…·è°ƒç”¨
        if "ToolMessage" in message_type or _is_tool_call_message(content):
            tool_name = _extract_tool_name(content, message)
            if not search_stats["in_tool_call"]:
                search_stats["in_tool_call"] = True
                search_stats["current_tool"] = tool_name
                logger.info(f"[LATS SSE] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨å¼€å§‹: {tool_name}")
                return formatter.format_tool_call_start(tool_name)
            else:
                # å·¥å…·è°ƒç”¨ç»“æœ
                search_stats["in_tool_call"] = False
                tool_name = search_stats.get("current_tool", "å·¥å…·")
                logger.info(f"[LATS SSE] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ç»“æœ: {tool_name}")
                return formatter.format_tool_result(tool_name, content[:300])

        # 3. æ£€æµ‹åˆå§‹è¯„ä¼°ç»“æœ
        initial_eval = _extract_initial_evaluation(content)
        if initial_eval:
            search_stats["best_score"] = initial_eval["score"]
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°åˆå§‹è¯„ä¼°: è¯„åˆ† {initial_eval['score']}")
            return formatter.format_initial_evaluation(
                initial_eval["score"],
                initial_eval["reflection"],
                initial_eval.get("solution_preview")
            )

        # 4. æ£€æµ‹æœç´¢è¿­ä»£ä¿¡æ¯
        iteration_info = _extract_iteration_info(content)
        if iteration_info:
            search_stats.update(iteration_info)
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°æœç´¢è¿­ä»£: #{iteration_info['iteration']}")
            return formatter.format_tree_search_iteration_start(
                iteration_info["iteration"],
                iteration_info["tree_height"],
                iteration_info["nodes_explored"]
            )

        # 5. æ£€æµ‹å€™é€‰ç”Ÿæˆ
        if _is_candidate_generation_message(content):
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°å€™é€‰ç”Ÿæˆé˜¶æ®µ")
            return formatter.format_candidates_generation_start()

        # 6. æ£€æµ‹å€™é€‰è¯„ä¼°ç»“æœ
        evaluation_results = _extract_evaluation_results(content)
        if evaluation_results:
            search_stats["best_score"] = max(search_stats["best_score"],
                                             evaluation_results.get("best_score", 0))
            logger.info(
                f"[LATS SSE] æ£€æµ‹åˆ°è¯„ä¼°ç»“æœ: æœ€ä½³è¯„åˆ† {evaluation_results.get('best_score', 0)}")
            return formatter.format_candidates_evaluation_results(
                evaluation_results["evaluations"]
            )

        # 7. æ£€æµ‹è§£å†³æ–¹æ¡ˆå‘ç°
        solution_info = _extract_solution_found(content)
        if solution_info:
            search_stats["solution_found"] = True
            search_stats["best_score"] = solution_info["score"]
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°è§£å†³æ–¹æ¡ˆå‘ç°: è¯„åˆ† {solution_info['score']}")
            return formatter.format_solution_found(
                solution_info["score"],
                solution_info["preview"],
                search_stats
            )

        # 8. æ£€æµ‹æœç´¢æ·±åº¦é™åˆ¶
        if _is_depth_limit_message(content):
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°æœç´¢æ·±åº¦é™åˆ¶")
            return formatter.format_search_depth_limit(5)

        # 9. æ£€æµ‹æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ
        if _is_final_answer_message(content):
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ")
            return formatter.format_final_answer_start()

        # 10. å¤„ç†æœ€ç»ˆå†…å®¹è¾“å‡º - è¿™æ˜¯å®é™…çš„ç­”æ¡ˆå†…å®¹
        if _is_final_content(content, message_type):
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°æœ€ç»ˆå†…å®¹è¾“å‡º")
            return formatter.format_final_content(content)

        # 11. å¤„ç†æœ‰æ„ä¹‰çš„ä¸­é—´å†…å®¹
        if _is_meaningful_content(content):
            logger.info(f"[LATS SSE] æ£€æµ‹åˆ°æœ‰æ„ä¹‰çš„ä¸­é—´å†…å®¹")
            return _format_meaningful_message(content, formatter)

        # é»˜è®¤æƒ…å†µ - å¯èƒ½æ˜¯è°ƒè¯•ä¿¡æ¯ï¼Œä¸éœ€è¦æ˜¾ç¤º
        logger.debug(f"[LATS SSE] è·³è¿‡å†…éƒ¨æ¶ˆæ¯: {content[:50]}...")
        return ""

    except Exception as e:
        logger.error(f"[LATS SSE] å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
        return ""


def _extract_message_content(message: Any) -> str:
    """ä»æ¶ˆæ¯å¯¹è±¡ä¸­æå–å†…å®¹"""
    try:
        if message is None:
            return ""

        logger.debug(f"[LATS SSE] æå–æ¶ˆæ¯å†…å®¹ï¼Œæ¶ˆæ¯ç±»å‹: {type(message).__name__}")

        # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯å¯¹è±¡
        if hasattr(message, 'content'):
            content = message.content
            # æ£€æŸ¥ content æ˜¯å¦æ˜¯å­—ç¬¦ä¸²
            if isinstance(content, str):
                return content.strip()
            # å¦‚æœæ˜¯å¯è°ƒç”¨å¯¹è±¡ï¼ˆå‡½æ•°ï¼‰ï¼Œå°è¯•è°ƒç”¨
            elif callable(content):
                try:
                    result = content()
                    return str(result).strip() if result else ""
                except:
                    logger.debug(f"[LATS SSE] è°ƒç”¨ content å‡½æ•°å¤±è´¥")
                    return ""
            # å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²
            elif content is not None:
                return str(content).strip()

        # å°è¯•å…¶ä»–å±æ€§
        if hasattr(message, 'text') and message.text:
            return str(message.text).strip()

        if hasattr(message, 'data') and message.data:
            return str(message.data).strip()

        # å¦‚æœæ¶ˆæ¯å¯¹è±¡æœ¬èº«æ˜¯å­—ç¬¦ä¸²
        if isinstance(message, str):
            return message.strip()

        # æ‰“å°æ¶ˆæ¯çš„æ‰€æœ‰å±æ€§ä»¥ä¾¿è°ƒè¯•
        attrs = [attr for attr in dir(message) if not attr.startswith('_')]
        logger.debug(f"[LATS SSE] æ¶ˆæ¯å±æ€§: {attrs[:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ªå±æ€§

        return ""
    except Exception as e:
        logger.error(f"[LATS SSE] æå–æ¶ˆæ¯å†…å®¹å¤±è´¥: {str(e)}")
        return ""


def _is_initial_generation_message(content: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯åˆå§‹ç”Ÿæˆæ¶ˆæ¯"""
    patterns = [
        "å¼€å§‹ç”Ÿæˆåˆå§‹å“åº”",
        "ç”Ÿæˆåˆå§‹å›ç­”",
        "åˆå§‹å›ç­”ç”Ÿæˆå®Œæˆ",
        "GenerateInitialCandidate",
        "initial_answer_chain",
        "get_initial_answer_chain"
    ]
    return any(pattern in content for pattern in patterns)


def _is_tool_call_message(content: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨ç›¸å…³æ¶ˆæ¯"""
    patterns = [
        "tool_call",
        "å·¥å…·è°ƒç”¨",
        "æ‰§è¡Œå·¥å…·",
        "è°ƒç”¨å·¥å…·",
        "tool_name",
        "ToolNode",
        "tool_responses"
    ]
    return any(pattern in content for pattern in patterns)


def _extract_tool_name(content: str, message: Any) -> str:
    """æå–å·¥å…·åç§°"""
    try:
        # ä»æ¶ˆæ¯å±æ€§ä¸­æå–
        if hasattr(message, 'name') and message.name:
            return message.name

        # ä»å†…å®¹ä¸­æå–å¸¸è§çš„å·¥å…·åç§°
        common_tools = [
            "naive_rag_search",
            "web_search",
            "playwright_tools",
            "python_repl",
            "file_reader",
            "calculator"
        ]

        content_lower = content.lower()
        for tool in common_tools:
            if tool in content_lower:
                return tool

        # ä»ä¸­æ–‡æè¿°ä¸­æå–
        tool_patterns = [
            r"è°ƒç”¨å·¥å…·[ï¼š:]\s*(\w+)",
            r"æ‰§è¡Œå·¥å…·[ï¼š:]\s*(\w+)",
            r"ä½¿ç”¨\s*(\w+)\s*å·¥å…·"
        ]

        for pattern in tool_patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1)

        return "æ™ºèƒ½å·¥å…·"
    except Exception:
        return "å·¥å…·"


def _extract_initial_evaluation(content: str) -> Dict[str, Any]:
    """æå–åˆå§‹è¯„ä¼°ä¿¡æ¯"""
    try:
        # æŸ¥æ‰¾è¯„åˆ†ä¿¡æ¯
        score_patterns = [
            r"è¯„åˆ†[ï¼š:]\s*(\d+(?:\.\d+)?)",
            r"åˆ†æ•°[ï¼š:]\s*(\d+(?:\.\d+)?)",
            r"score[\"']?\s*:\s*(\d+(?:\.\d+)?)"
        ]

        score = None
        for pattern in score_patterns:
            match = re.search(pattern, content)
            if match:
                score = float(match.group(1))
                break

        if score is None:
            return None

        # æå–åæ€å†…å®¹
        reflection_patterns = [
            r"åæ€[ï¼š:](.+?)(?:\n|$)",
            r"è¯„ä¼°[ï¼š:](.+?)(?:\n|$)",
            r"reflections[\"']?\s*:\s*[\"'](.+?)[\"']"
        ]

        reflection = ""
        for pattern in reflection_patterns:
            match = re.search(pattern, content, re.DOTALL)
            if match:
                reflection = match.group(1).strip()
                break

        return {
            "score": score,
            "reflection": reflection,
            "solution_preview": content[:200] if len(content) > 200 else content
        }

    except Exception as e:
        logger.debug(f"[LATS SSE] æå–åˆå§‹è¯„ä¼°å¤±è´¥: {str(e)}")
        return None


def _extract_iteration_info(content: str) -> Dict[str, Any]:
    """æå–æœç´¢è¿­ä»£ä¿¡æ¯"""
    try:
        iteration_patterns = [
            r"æœç´¢è¿­ä»£\s*#?(\d+)",
            r"è¿­ä»£\s*#?(\d+)",
            r"iteration\s*:?\s*(\d+)"
        ]

        height_patterns = [
            r"æ ‘é«˜åº¦[ï¼š:]\s*(\d+)",
            r"é«˜åº¦[ï¼š:]\s*(\d+)",
            r"height[ï¼š:]\s*(\d+)"
        ]

        nodes_patterns = [
            r"å·²æ¢ç´¢[ï¼š:]\s*(\d+)",
            r"èŠ‚ç‚¹æ•°[ï¼š:]\s*(\d+)",
            r"nodes_explored[ï¼š:]\s*(\d+)"
        ]

        iteration = None
        tree_height = 0
        nodes_explored = 0

        for pattern in iteration_patterns:
            match = re.search(pattern, content)
            if match:
                iteration = int(match.group(1))
                break

        for pattern in height_patterns:
            match = re.search(pattern, content)
            if match:
                tree_height = int(match.group(1))
                break

        for pattern in nodes_patterns:
            match = re.search(pattern, content)
            if match:
                nodes_explored = int(match.group(1))
                break

        if iteration is not None:
            return {
                "iteration": iteration,
                "tree_height": tree_height,
                "nodes_explored": nodes_explored
            }

        return None

    except Exception as e:
        logger.debug(f"[LATS SSE] æå–è¿­ä»£ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None


def _is_candidate_generation_message(content: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯å€™é€‰ç”Ÿæˆæ¶ˆæ¯"""
    patterns = [
        "ç”Ÿæˆ.*å€™é€‰",
        "å€™é€‰è§£å†³æ–¹æ¡ˆ",
        "generate.*candidate",
        "æ–°å€™é€‰",
        "å€™é€‰æ–¹æ¡ˆ"
    ]
    return any(re.search(pattern, content, re.IGNORECASE) for pattern in patterns)


def _extract_evaluation_results(content: str) -> Dict[str, Any]:
    """æå–è¯„ä¼°ç»“æœä¿¡æ¯"""
    try:
        # æŸ¥æ‰¾è¯„ä¼°ç»“æœæ±‡æ€»çš„æ¨¡å¼
        if "è¯„ä¼°ç»“æœæ±‡æ€»" in content or "candidate.*evaluation" in content.lower():

            # æå–æœ€é«˜è¯„åˆ†
            best_score = 0
            score_patterns = [
                r"æœ€é«˜è¯„åˆ†[ï¼š:]\s*(\d+(?:\.\d+)?)",
                r"æœ€ä½³[ï¼š:]\s*(\d+(?:\.\d+)?)",
                r"max.*score[ï¼š:]\s*(\d+(?:\.\d+)?)"
            ]

            for pattern in score_patterns:
                match = re.search(pattern, content)
                if match:
                    best_score = float(match.group(1))
                    break

            # æå–è§£å†³æ–¹æ¡ˆæ•°é‡
            solutions_count = 0
            solution_patterns = [
                r"æ‰¾åˆ°\s*(\d+)\s*ä¸ªè§£å†³æ–¹æ¡ˆ",
                r"(\d+)\s*ä¸ªè§£å†³æ–¹æ¡ˆ",
                r"solutions[ï¼š:]\s*(\d+)"
            ]

            for pattern in solution_patterns:
                match = re.search(pattern, content)
                if match:
                    solutions_count = int(match.group(1))
                    break

            # æ„å»ºè¯„ä¼°åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
            evaluations = []
            for i in range(min(5, 3)):  # æœ€å¤š3ä¸ªå€™é€‰
                evaluations.append({
                    "score": best_score - i * 0.5,
                    "found_solution": i < solutions_count
                })

            return {
                "best_score": best_score,
                "evaluations": evaluations
            }

        return None

    except Exception as e:
        logger.debug(f"[LATS SSE] æå–è¯„ä¼°ç»“æœå¤±è´¥: {str(e)}")
        return None


def _extract_solution_found(content: str) -> Dict[str, Any]:
    """æå–è§£å†³æ–¹æ¡ˆå‘ç°ä¿¡æ¯"""
    try:
        solution_patterns = [
            r"æ‰¾åˆ°.*è§£å†³æ–¹æ¡ˆ",
            r"solution.*found",
            r"é«˜è´¨é‡è§£å†³æ–¹æ¡ˆ",
            r"æœ€ä½³è§£å†³æ–¹æ¡ˆ"
        ]

        for pattern in solution_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                # æå–è¯„åˆ†
                score_match = re.search(r"è¯„åˆ†[ï¼š:]\s*(\d+(?:\.\d+)?)", content)
                score = float(score_match.group(1)) if score_match else 9.0

                return {
                    "score": score,
                    "preview": content[:300]
                }

        return None

    except Exception as e:
        logger.debug(f"[LATS SSE] æå–è§£å†³æ–¹æ¡ˆä¿¡æ¯å¤±è´¥: {str(e)}")
        return None


def _is_depth_limit_message(content: str) -> bool:
    """æ£€æµ‹æ˜¯å¦è¾¾åˆ°æœç´¢æ·±åº¦é™åˆ¶"""
    patterns = [
        "æœç´¢æ·±åº¦è¾¾åˆ°ä¸Šé™",
        "æ·±åº¦.*é™åˆ¶",
        "MAX_TREE_HEIGHT",
        "æœç´¢æ·±åº¦è¶…è¿‡"
    ]
    return any(pattern in content for pattern in patterns)


def _is_final_answer_message(content: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆç”Ÿæˆæ¶ˆæ¯"""
    patterns = [
        "æ•´ç†æœ€ç»ˆç­”æ¡ˆ",
        "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ",
        "final.*answer",
        "æœ€ç»ˆå›ç­”",
        "ç»¼åˆ.*ç­”æ¡ˆ"
    ]
    return any(pattern in content for pattern in patterns)


def _is_meaningful_content(content: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯æœ‰æ„ä¹‰çš„å†…å®¹ï¼Œå€¼å¾—å±•ç¤ºç»™ç”¨æˆ·"""
    if not content or len(content.strip()) < 10:
        return False

    # è¿‡æ»¤æ‰çº¯æŠ€æœ¯æ€§çš„å†…å®¹
    technical_patterns = [
        "tool_call_id:",
        "function_call:",
        "usage_metadata:",
        "response_metadata:",
        '"type":"function"',
        '"role":"function"',
        '{"id":"',
        '{"object":"',
        "uuid-",
        "token_usage:",
        "prompt_tokens:",
        "completion_tokens:",
        "Reflection(",
        "Node("
    ]

    content_lower = content.lower()
    for pattern in technical_patterns:
        if pattern in content_lower:
            return False

    # å¦‚æœåŒ…å«æœ‰æ„ä¹‰çš„å…³é”®è¯ï¼Œè®¤ä¸ºæ˜¯æœ‰ä»·å€¼çš„å†…å®¹
    meaningful_patterns = [
        "æ ¹æ®",
        "åˆ†æ",
        "å»ºè®®",
        "è§£å†³",
        "æ–¹æ¡ˆ",
        "å›ç­”",
        "é—®é¢˜",
        "ç»“æœ",
        "æ€»ç»“",
        "å› ä¸º",
        "æ‰€ä»¥",
        "é¦–å…ˆ",
        "å…¶æ¬¡",
        "æœ€å",
        "å…·ä½“",
        "è¯¦ç»†"
    ]

    for pattern in meaningful_patterns:
        if pattern in content:
            return True

    # å¦‚æœæ˜¯é•¿æ–‡æœ¬ä¸”ä¸åŒ…å«æŠ€æœ¯å…³é”®è¯ï¼Œå¯èƒ½æ˜¯æœ‰æ„ä¹‰çš„
    return len(content) > 50


def _format_meaningful_message(content: str, formatter: LatsSSEFormatter) -> str:
    """æ ¼å¼åŒ–æœ‰æ„ä¹‰çš„æ¶ˆæ¯å†…å®¹"""
    # æ ¹æ®å†…å®¹ç‰¹å¾è¿›è¡Œæ™ºèƒ½æ ¼å¼åŒ–
    if "æ€è€ƒ" in content or "åˆ†æ" in content:
        return formatter.format_final_content(f"ğŸ¤” **AI æ€è€ƒä¸­...**\n\n{content}")
    elif "æœç´¢" in content or "æŸ¥æ‰¾" in content:
        return formatter.format_final_content(f"ğŸ” **ä¿¡æ¯æœç´¢**\n\n{content}")
    elif "è¯„ä¼°" in content or "è¯„ä»·" in content:
        return formatter.format_final_content(f"ğŸ“Š **è¯„ä¼°åˆ†æ**\n\n{content}")
    elif "è§£å†³" in content or "æ–¹æ¡ˆ" in content:
        return formatter.format_final_content(f"ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**\n\n{content}")
    else:
        # é»˜è®¤ä½œä¸ºæ€è€ƒè¿‡ç¨‹å±•ç¤º
        return formatter.format_final_content(f"ğŸ’­ **å¤„ç†ä¸­**\n\n{content}")


def _is_final_content(content: str, message_type: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯æœ€ç»ˆå†…å®¹"""
    # å¦‚æœæ˜¯AIæ¶ˆæ¯ä¸”åŒ…å«å®è´¨æ€§å†…å®¹ï¼Œä¸”ä¸æ˜¯å†…éƒ¨å¤„ç†æ¶ˆæ¯
    if "AIMessage" in message_type and len(content) > 50:
        internal_patterns = [
            "å€™é€‰è§£å†³æ–¹æ¡ˆ",
            "è¯„ä¼°ç»“æœ",
            "æœç´¢è¿­ä»£",
            "å·¥å…·è°ƒç”¨",
            "reflection",
            "score"
        ]

        # å¦‚æœä¸åŒ…å«å†…éƒ¨å¤„ç†å…³é”®è¯ï¼Œå¯èƒ½æ˜¯æœ€ç»ˆå†…å®¹
        is_internal = any(pattern in content for pattern in internal_patterns)
        return not is_internal

    return False


def _format_generic_message(content: str, formatter: LatsSSEFormatter) -> str:
    """æ ¼å¼åŒ–é€šç”¨æ¶ˆæ¯"""
    # æ ¹æ®å†…å®¹ç‰¹å¾è¿›è¡Œç®€å•æ ¼å¼åŒ–
    if "æœç´¢" in content:
        return f"\nğŸ” **æœç´¢è¿›å±•**\n\n{content[:200]}...\n"
    elif "åˆ†æ" in content:
        return f"\nğŸ“Š **åˆ†æä¸­**\n\n{content[:200]}...\n"
    elif "è¯„ä¼°" in content:
        return f"\nğŸ“‹ **è¯„ä¼°è¿›å±•**\n\n{content[:200]}...\n"
    else:
        return f"\nğŸ’­ {content[:200]}...\n"


def _extract_content_preview(sse_content: str) -> str:
    """æå–SSEå†…å®¹çš„é¢„è§ˆ"""
    try:
        # å°è¯•è§£æJSON
        if "data: " in sse_content:
            json_part = sse_content.replace("data: ", "").strip()
            if json_part:
                data = json.loads(json_part)
                if "choices" in data and data["choices"]:
                    delta = data["choices"][0].get("delta", {})
                    content = delta.get("content", "")
                    if content:
                        # æ¸…ç†å†…å®¹ï¼Œç§»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
                        clean_content = re.sub(r'\n+', ' ', content.strip())
                        clean_content = re.sub(r'\s+', ' ', clean_content)
                        # è¿”å›åˆé€‚é•¿åº¦çš„é¢„è§ˆ
                        preview_length = 100
                        if len(clean_content) > preview_length:
                            return clean_content[:preview_length] + "..."
                        return clean_content

        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥å¤„ç†å­—ç¬¦ä¸²
        clean_content = re.sub(r'\n+', ' ', sse_content.strip())
        clean_content = re.sub(r'\s+', ' ', clean_content)
        return clean_content[:100] + "..." if len(clean_content) > 100 else clean_content

    except Exception as e:
        logger.debug(f"[LATS SSE] æå–å†…å®¹é¢„è§ˆå¤±è´¥: {str(e)}")
        return sse_content[:50] + "..." if len(sse_content) > 50 else sse_content


def _create_sse_data(chat_id: str, created: int, model: str, content: str, finish_reason: str = None) -> str:
    """åˆ›å»ºSSEæ•°æ®"""
    response = {
        "id": chat_id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [{
            "delta": {
                "role": "assistant",
                "content": content
            },
            "index": 0,
            "finish_reason": finish_reason
        }]
    }

    json_str = json.dumps(response, ensure_ascii=False, separators=(',', ':'))
    return f"data: {json_str}\n\n"


def _create_sse_data(chat_id: str, created: int, model: str, content: str, finish_reason: str = None) -> str:
    """åˆ›å»ºSSEæ•°æ®"""
    response = {
        "id": chat_id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [{
            "delta": {
                "role": "assistant",
                "content": content
            },
            "index": 0,
            "finish_reason": finish_reason
        }]
    }

    json_str = json.dumps(response, ensure_ascii=False, separators=(',', ':'))
    return f"data: {json_str}\n\n"
