"""
LATS Agent SSE å¤„ç†å™¨ - ä¼˜åŒ–ç‰ˆæœ¬

æä¾›ç®€æ´ã€é«˜æ•ˆçš„ LATS æœç´¢æµå¼å“åº”å¤„ç†
é‡ç‚¹ä¼˜åŒ–ç”¨æˆ·ä½“éªŒï¼Œå‡å°‘å†—ä½™ä»£ç ï¼Œæé«˜å¯ç»´æŠ¤æ€§
é˜²æ­¢æ¶ˆæ¯é”™ä¹±ï¼Œç¡®ä¿æµå¼è¾“å‡ºçš„é¡ºåºæ€§å’Œç¨³å®šæ€§
"""
import asyncio
import json
from typing import Dict, Any, List
from datetime import datetime

from sanic.log import logger
from src.api.agent.lats_sse_formatter import LatsSSEFormatter


class LatsSSEHandler:
    """LATS SSE å¤„ç†å™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""

    def __init__(self, chat_id: str, model: str):
        self.chat_id = chat_id
        self.model = model
        self.formatter = LatsSSEFormatter(chat_id, model)
        self.sent_messages = set()  # é˜²é‡å¤
        self.is_final_answer_started = False
        self._output_lock = asyncio.Lock()  # æ·»åŠ è¾“å‡ºé”ï¼Œé˜²æ­¢å¹¶å‘é”™ä¹±

    async def send_sse(self, res, message: str) -> None:
        """å‘é€ SSE æ¶ˆæ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå»é‡ï¼‰"""
        if not message:
            return

        async with self._output_lock:  # ç¡®ä¿æ¶ˆæ¯æŒ‰é¡ºåºå‘é€
            if message not in self.sent_messages:
                try:
                    await res.write(message.encode('utf-8'))
                    self.sent_messages.add(message)
                    # æå–æ¶ˆæ¯å†…å®¹çš„å‰50ä¸ªå­—ç¬¦ç”¨äºæ—¥å¿—
                    content_preview = message[:50].replace('\n', ' ').strip()
                    logger.info(f"[LATS SSE] å‘é€æ¶ˆæ¯: {content_preview}...")
                except Exception as e:
                    logger.error(f"[LATS SSE] å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            else:
                logger.debug(f"[LATS SSE] è·³è¿‡é‡å¤æ¶ˆæ¯: {message[:30]}...")

    async def handle_search_flow(self, res, workflow, body) -> None:
        """å¤„ç†æœç´¢æµç¨‹"""
        try:
            logger.info(f"[LATS SSE] å¼€å§‹å¤„ç†æœç´¢æµç¨‹ï¼Œchat_id: {self.chat_id}")

            # å‘é€åˆå§‹åŒ–æ¶ˆæ¯
            await self.send_sse(res, self.formatter.format_initialization())
            await self.send_sse(res, self.formatter.format_initial_generation())

            # å¤„ç†æœç´¢æµ
            iteration_count = 0
            async for chunk in await workflow.stream(body):
                await self.process_chunk(res, chunk, iteration_count)

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„è¿­ä»£
                if self._is_new_iteration(chunk):
                    iteration_count += 1

            # å‘é€å®Œæˆæ¶ˆæ¯
            await self.send_completion(res)

            logger.info(f"[LATS SSE] æœç´¢æµç¨‹å¤„ç†å®Œæˆï¼Œchat_id: {self.chat_id}")

        except Exception as e:
            logger.error(f"[LATS SSE] å¤„ç†å‡ºé”™: {str(e)}", exc_info=True)
            await self.send_sse(res, self.formatter.format_error(str(e)))

    async def process_chunk(self, res, chunk, iteration_count: int) -> None:
        """å¤„ç†æ•°æ®å—"""
        try:
            logger.debug(f"[LATS SSE] å¤„ç†chunk: {type(chunk).__name__}")

            # å¤„ç†æœ€ç»ˆçŠ¶æ€
            if self._is_final_state(chunk):
                await self.handle_final_state(res, chunk)
                return

            # å¤„ç†è¯„ä¼°ç»“æœ
            if self._is_evaluation_results(chunk):
                await self.handle_evaluation_results(res, chunk['evaluation_results'])
                return

            # å¤„ç†èŠ‚ç‚¹è½¬æ¢
            if self._is_node_transition(chunk):
                await self.handle_node_transition(res, chunk, iteration_count)
                return

            # å¤„ç†æ¶ˆæ¯æµ
            if self._is_message_stream(chunk):
                await self.handle_message_stream(res, chunk)
                return

            # å¤„ç†å…¶ä»–å¯èƒ½çš„æ•°æ®ç±»å‹
            if isinstance(chunk, dict):
                await self.handle_dict_chunk(res, chunk)

        except Exception as e:
            logger.error(f"[LATS SSE] å¤„ç†chunkå‡ºé”™: {e}")

    async def handle_dict_chunk(self, res, chunk: dict) -> None:
        """å¤„ç†å­—å…¸ç±»å‹çš„æ•°æ®å—"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ€è€ƒæˆ–åæ€å†…å®¹
        if 'thought' in chunk or 'thinking' in chunk:
            thought_content = chunk.get('thought') or chunk.get('thinking', '')
            if thought_content:
                await self.send_sse(res, self.formatter.format_thinking_process(str(thought_content)))

        elif 'reflection' in chunk:
            reflection_content = chunk.get('reflection', '')
            score = chunk.get('score')
            if reflection_content:
                await self.send_sse(res, self.formatter.format_reflection(str(reflection_content), score))

    def _is_final_state(self, chunk) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆçŠ¶æ€"""
        return isinstance(chunk, dict) and 'messages' in chunk and 'root' in chunk

    def _is_evaluation_results(self, chunk) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºè¯„ä¼°ç»“æœ"""
        return isinstance(chunk, dict) and 'evaluation_results' in chunk

    def _is_node_transition(self, chunk) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºèŠ‚ç‚¹è½¬æ¢"""
        return isinstance(chunk, dict) and len(chunk) == 1

    def _is_message_stream(self, chunk) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ¶ˆæ¯æµ"""
        return isinstance(chunk, (tuple, list)) and len(chunk) > 0

    def _is_new_iteration(self, chunk) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–°è¿­ä»£"""
        return (isinstance(chunk, dict) and 'expand' in chunk) or \
               (self._is_node_transition(chunk) and 'expand' in chunk)

    async def handle_final_state(self, res, chunk) -> None:
        """å¤„ç†æœ€ç»ˆçŠ¶æ€"""
        root_node = chunk.get('root')
        messages = chunk.get('messages', [])

        if not (root_node and messages):
            return

        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ
        if hasattr(root_node, 'is_solved') and root_node.is_solved:
            # è·å–æœ€ä½³è¯„åˆ†
            best_score = 10  # é»˜è®¤é«˜åˆ†
            if hasattr(root_node, 'reflection') and root_node.reflection:
                best_score = root_node.reflection.score

            await self.send_sse(res, self.formatter.format_solution_found(best_score))

        # å¼€å§‹æœ€ç»ˆç­”æ¡ˆ
        if not self.is_final_answer_started:
            await self.send_sse(res, self.formatter.format_final_answer_start())
            self.is_final_answer_started = True

        # è¾“å‡ºæœ€ç»ˆå†…å®¹
        if messages:
            final_message = messages[-1]
            if hasattr(final_message, 'content') and final_message.content:
                content = f"\n\nğŸ¯ **LATS è§£å†³æ–¹æ¡ˆ**\n\n{final_message.content}\n\n"
                await self.send_sse(res, self.formatter.format_content(content))

    async def handle_evaluation_results(self, res, evaluations: List[Dict[str, Any]]) -> None:
        """å¤„ç†è¯„ä¼°ç»“æœ"""
        if evaluations:
            logger.info(f"[LATS SSE] å±•ç¤º {len(evaluations)} ä¸ªå€™é€‰æ–¹æ¡ˆè¯„ä¼°ç»“æœ")
            await self.send_sse(res, self.formatter.format_candidates_evaluation(evaluations))

    async def handle_node_transition(self, res, chunk, iteration_count: int) -> None:
        """å¤„ç†èŠ‚ç‚¹è½¬æ¢"""
        node_name = next(iter(chunk.keys()))
        node_data = chunk[node_name]

        if node_name == "generate_initial_response":
            # è¾“å‡ºåˆå§‹å“åº”ç”Ÿæˆçš„æ€è€ƒè¿‡ç¨‹
            await self.send_sse(res, self.formatter.format_content("\nğŸ¤” **åˆ†æé—®é¢˜ï¼Œç”Ÿæˆåˆå§‹å›ç­”...**\n\n"))
        elif node_name == "expand":
            await self.send_sse(res, self.formatter.format_search_iteration(iteration_count + 1))
        elif node_name == "tools":
            await self.send_sse(res, self.formatter.format_tool_execution("search_tool"))
        elif node_name == "reflect":
            await self.send_sse(res, self.formatter.format_content("\nğŸ” **è¯„ä¼°å½“å‰è§£å†³æ–¹æ¡ˆè´¨é‡...**\n\n"))
        elif node_name == "should_continue":
            await self.send_sse(res, self.formatter.format_content("\nâš–ï¸ **åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æœç´¢...**\n\n"))
        else:
            # è¾“å‡ºå…¶ä»–èŠ‚ç‚¹çš„å¤„ç†ä¿¡æ¯
            await self.send_sse(res, self.formatter.format_content(f"\nğŸ”„ **æ‰§è¡Œ {node_name} èŠ‚ç‚¹...**\n\n"))

    async def handle_message_stream(self, res, chunk) -> None:
        """å¤„ç†æ¶ˆæ¯æµ"""
        message = chunk[0] if chunk else None
        if not message:
            return

        message_type = type(message).__name__
        logger.debug(f"[LATS SSE] å¤„ç†æ¶ˆæ¯ç±»å‹: {message_type}")

        # å¤„ç† AI æ¶ˆæ¯å—
        if message_type == "AIMessageChunk" and hasattr(message, 'content') and message.content:
            await self.send_sse(res, self.formatter.format_content(message.content))

        # å¤„ç†å·¥å…·æ¶ˆæ¯ - å±•ç¤ºå·¥å…·è°ƒç”¨çš„æ€è€ƒè¿‡ç¨‹
        elif "Tool" in message_type and "Message" in message_type:
            if hasattr(message, 'content') and message.content:
                tool_content = message.content
                if tool_content and len(tool_content) > 10:  # é¿å…è¾“å‡ºè¿‡çŸ­çš„æ— æ„ä¹‰å†…å®¹
                    await self.send_sse(res, self.formatter.format_content(f"\n\nğŸ”§ **å·¥å…·æ‰§è¡Œç»“æœï¼š**\n\n{tool_content}\n\n"))
            elif hasattr(message, 'name'):
                tool_name = getattr(message, 'name', 'unknown_tool')
                await self.send_sse(res, self.formatter.format_tool_execution(tool_name))

    async def send_completion(self, res) -> None:
        """å‘é€å®Œæˆæ¶ˆæ¯"""
        try:
            # å‘é€å®Œæˆç»Ÿè®¡
            await self.send_sse(res, self.formatter.format_completion())

            # å‘é€ç»“æŸä¿¡å·
            end_response = {
                "id": self.chat_id,
                "object": "chat.completion.chunk",
                "created": int(datetime.now().timestamp()),
                "model": self.model,
                "choices": [{"delta": {}, "index": 0, "finish_reason": "stop"}]
            }

            json_str = json.dumps(
                end_response, ensure_ascii=False, separators=(',', ':'))

            async with self._output_lock:  # ç¡®ä¿ç»“æŸä¿¡å·æŒ‰é¡ºåºå‘é€
                await res.write(f"data: {json_str}\n\n".encode('utf-8'))
                await res.write("data: [DONE]\n\n".encode('utf-8'))

        except Exception as e:
            logger.error(f"[LATS SSE] å‘é€å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")


async def stream_lats_response(workflow, body: Dict[str, Any], chat_id: str, model: str, res) -> None:
    """
    ä¼˜åŒ–çš„ LATS Agent æµå¼å“åº”å¤„ç†å‡½æ•°

    ç®€åŒ–é€»è¾‘ï¼Œæå‡æ€§èƒ½ï¼Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒ
    é˜²æ­¢æ¶ˆæ¯é”™ä¹±ï¼Œç¡®ä¿è¾“å‡ºé¡ºåº
    """
    handler = LatsSSEHandler(chat_id, model)
    await handler.handle_search_flow(res, workflow, body)
