"""
LATS Agent SSE å¤„ç†å™¨

åŸºäºLATS AgentèŠ‚ç‚¹çŠ¶æ€å’Œç±»å‹çš„æ™ºèƒ½SSEè¾“å‡ºå¤„ç†

è®¾è®¡ç†å¿µï¼š
1. å®Œå…¨åŸºäºLATS Agentçš„èŠ‚ç‚¹ç±»å‹å’ŒçŠ¶æ€è¿›è¡Œè¾“å‡ºæ§åˆ¶
2. é¿å…å…³é”®è¯åŒ¹é…ï¼Œä½¿ç”¨èŠ‚ç‚¹è¯­ä¹‰å’ŒçŠ¶æ€åˆ¤æ–­
3. æ ¹æ®ä¸åŒèŠ‚ç‚¹çš„ä½œç”¨è¾“å‡ºç›¸åº”çš„ç”¨æˆ·å‹å¥½ä¿¡æ¯
4. ç¡®ä¿åªæœ‰çœŸæ­£çš„æœ€ç»ˆç­”æ¡ˆè¢«è¾“å‡ºç»™ç”¨æˆ·

æ”¯æŒçš„èŠ‚ç‚¹ç±»å‹ï¼š
- generate_initial_response: ç”Ÿæˆåˆå§‹å“åº”
- expand: æ‰©å±•æœç´¢æ ‘ï¼Œç”Ÿæˆå€™é€‰æ–¹æ¡ˆ
- reflect: åæ€è¯„ä¼°ï¼ˆå†…éƒ¨å¤„ç†ï¼‰
- select: é€‰æ‹©æœ€ä½³æ–¹æ¡ˆï¼ˆå†…éƒ¨å¤„ç†ï¼‰
- tools: å·¥å…·è°ƒç”¨å¤„ç†
"""
import asyncio
import json
from typing import Dict, Any, Optional
from datetime import datetime

from sanic.log import logger


async def stream_lats_response(
    workflow,
    body: Dict[str, Any],
    chat_id: str,
    model: str,
    res
):
    """
    æµå¼å¤„ç† LATS Agent å“åº”
    åŸºäºèŠ‚ç‚¹ç±»å‹å’ŒçŠ¶æ€è¿›è¡Œæ™ºèƒ½è¾“å‡ºæ§åˆ¶
    """
    created = int(datetime.now().timestamp())
    sent_contents = set()  # ç”¨äºå»é‡
    iteration_counter = 0  # è¿­ä»£è®¡æ•°å™¨
    current_node_type = None  # å½“å‰èŠ‚ç‚¹ç±»å‹
    lats_state = {
        'is_searching': False,
        'has_initial_response': False,
        'search_iterations': 0,
        'final_solution_found': False
    }

    try:
        logger.info(f"[LATS SSE] å¼€å§‹æµå¼å¤„ç†ï¼Œchat_id: {chat_id}")

        # å‘é€æœç´¢å¼€å§‹æ¶ˆæ¯
        start_content = "ğŸ” **æ­£åœ¨å¯åŠ¨ LATS æ™ºèƒ½æœç´¢...**\n\nğŸ§  åˆå§‹åŒ–è¯­è¨€è¾…åŠ©æ ‘æœç´¢å¼•æ“\n\nğŸ’¡ å‡†å¤‡ç”Ÿæˆå¤šä¸ªå€™é€‰è§£å†³æ–¹æ¡ˆå¹¶è¿›è¡Œæ·±åº¦æœç´¢"
        await _send_sse_data(res, chat_id, created, model, start_content)
        sent_contents.add(start_content)
        await asyncio.sleep(0.3)

        # è·å–æµå¼è¿­ä»£å™¨
        stream_iter = await workflow.stream(body)

        async for chunk in stream_iter:
            logger.debug(f"[LATS SSE] æ”¶åˆ° chunk: {chunk}")

            # å¤„ç†èŠ‚ç‚¹è½¬æ¢
            if isinstance(chunk, dict) and len(chunk) == 1:
                node_name = next(iter(chunk.keys()))
                current_node_type = node_name
                logger.debug(f"[LATS SSE] èŠ‚ç‚¹è½¬æ¢: {node_name}")

                # æ ¹æ®èŠ‚ç‚¹ç±»å‹æ›´æ–°çŠ¶æ€å’Œå‘é€æ¶ˆæ¯
                await _handle_node_transition(
                    node_name, lats_state, iteration_counter,
                    res, chat_id, created, model, sent_contents
                )

                if node_name == "expand":
                    iteration_counter += 1
                    lats_state['search_iterations'] = iteration_counter
                continue

            # å¤„ç†æ¶ˆæ¯æµ
            if isinstance(chunk, (tuple, list)) and len(chunk) > 0:
                message = chunk[0]

                if message is None:
                    continue

                # åŸºäºèŠ‚ç‚¹ç±»å‹å’ŒçŠ¶æ€å¤„ç†æ¶ˆæ¯
                content = await _process_node_message(
                    message, current_node_type, lats_state, iteration_counter
                )

                if content and content not in sent_contents:
                    await _send_sse_data(res, chat_id, created, model, content)
                    sent_contents.add(content)
                    logger.info(f"[LATS SSE] å‘é€å†…å®¹: {content[:50]}...")
                    await _adaptive_delay(content)

        # å‘é€æœç´¢å®Œæˆæ¶ˆæ¯
        if lats_state['final_solution_found']:
            completion_content = "\n\n---\n\nâœ¨ **LATS æœç´¢æˆåŠŸå®Œæˆï¼**\n\nğŸ‰ å·²æ‰¾åˆ°æœ€ä½³è§£å†³æ–¹æ¡ˆ\n\nğŸ’« å¸Œæœ›æˆ‘çš„å›ç­”å¯¹æ‚¨æœ‰å¸®åŠ©"
        else:
            completion_content = "\n\n---\n\nâœ¨ **LATS æœç´¢å®Œæˆï¼**\n\nğŸ‰ å·²å®Œæˆæ·±åº¦æœç´¢å’Œå¤šå€™é€‰æ–¹æ¡ˆè¯„ä¼°\n\nğŸ’« åŸºäºå½“å‰æœ€ä½³æ–¹æ¡ˆä¸ºæ‚¨æä¾›å›ç­”"

        await _send_sse_data(res, chat_id, created, model, completion_content)

        # å‘é€ç»“æŸæ ‡å¿—
        await _send_end_signal(res, chat_id, created, model)
        logger.info(f"[LATS SSE] æµå¼å¤„ç†å®Œæˆï¼Œchat_id: {chat_id}")

    except Exception as e:
        logger.error(f"[LATS SSE] å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
        error_content = f"\n\n---\n\nâŒ **LATS æœç´¢è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜**\n\nğŸ”§ **é”™è¯¯è¯¦æƒ…ï¼š**\n{str(e)}\n\nğŸ’¡ **å»ºè®®ï¼š**\nè¯·ç¨åé‡è¯•"
        await _send_sse_data(res, chat_id, created, model, error_content, finish_reason="stop")


async def _handle_node_transition(
    node_name: str,
    lats_state: Dict[str, Any],
    iteration_counter: int,
    res, chat_id: str, created: int, model: str,
    sent_contents: set
) -> None:
    """å¤„ç†èŠ‚ç‚¹è½¬æ¢ï¼Œå‘é€é€‚å½“çš„çŠ¶æ€æ¶ˆæ¯"""

    node_messages = {
        "generate_initial_response": "\nğŸŒ± **ç”Ÿæˆåˆå§‹è§£å†³æ–¹æ¡ˆ**\n\nğŸ¯ åˆ†æé—®é¢˜å¹¶æ„å»ºç¬¬ä¸€ä¸ªå€™é€‰å›ç­”",
        "expand": f"\n\n---\n\nğŸŒ³ **æœç´¢è¿­ä»£ #{iteration_counter + 1}**\n\nğŸ” æ¢ç´¢æœç´¢æ ‘æ–°åˆ†æ”¯ï¼Œä¼˜åŒ–å€™é€‰è§£å†³æ–¹æ¡ˆ",
        "tools": "\nğŸ”§ **è°ƒç”¨ä¸“ä¸šå·¥å…·**\n\nâš™ï¸ æ‰§è¡Œå¿…è¦çš„å·¥å…·æ“ä½œè·å–ä¿¡æ¯",
    }

    # æ›´æ–°çŠ¶æ€
    if node_name == "generate_initial_response":
        lats_state['has_initial_response'] = True
    elif node_name == "expand":
        lats_state['is_searching'] = True

    # å‘é€èŠ‚ç‚¹çŠ¶æ€æ¶ˆæ¯
    node_message = node_messages.get(node_name)
    if node_message and node_message not in sent_contents:
        await _send_sse_data(res, chat_id, created, model, node_message)
        sent_contents.add(node_message)
        await asyncio.sleep(0.3)


async def _process_node_message(
    message: Any,
    current_node_type: str,
    lats_state: Dict[str, Any],
    iteration_counter: int
) -> Optional[str]:
    """
    åŸºäºèŠ‚ç‚¹ç±»å‹å’ŒçŠ¶æ€å¤„ç†æ¶ˆæ¯
    é¿å…å…³é”®è¯åŒ¹é…ï¼Œå®Œå…¨ä¾èµ–èŠ‚ç‚¹è¯­ä¹‰
    """
    try:
        if not hasattr(message, 'content') or not message.content:
            return None

        message_type = type(message).__name__
        content = message.content.strip()

        if not content:
            return None

        logger.debug(
            f"[LATS SSE] å¤„ç†èŠ‚ç‚¹æ¶ˆæ¯: {current_node_type}, æ¶ˆæ¯ç±»å‹: {message_type}")

        # åŸºäºèŠ‚ç‚¹ç±»å‹å¤„ç†
        if current_node_type == "generate_initial_response":
            return _handle_initial_response_message(message_type, content, lats_state)

        elif current_node_type == "expand":
            return _handle_expand_message(message_type, content, lats_state, iteration_counter)

        elif current_node_type == "tools":
            return _handle_tools_message(message_type, content, lats_state)

        # å¯¹äºå…¶ä»–èŠ‚ç‚¹æˆ–æ— æ˜ç¡®èŠ‚ç‚¹çš„æƒ…å†µ
        else:
            return _handle_general_message(message_type, content, lats_state)

    except Exception as e:
        logger.error(f"[LATS SSE] å¤„ç†èŠ‚ç‚¹æ¶ˆæ¯å¤±è´¥: {str(e)}")
        return None


def _handle_initial_response_message(message_type: str, content: str, lats_state: Dict[str, Any]) -> Optional[str]:
    """å¤„ç†åˆå§‹å“åº”èŠ‚ç‚¹çš„æ¶ˆæ¯"""
    if "ToolMessage" in message_type:
        return "\nğŸ”§ **åˆå§‹ä¿¡æ¯æ”¶é›†å®Œæˆ**\n\nğŸ“Š æ­£åœ¨åˆ†æè·å–çš„ä¿¡æ¯...\n"

    elif "AIMessage" in message_type:
        # åˆå§‹å“åº”é˜¶æ®µçš„AIæ¶ˆæ¯
        if _is_substantial_response(content):
            lats_state['has_initial_response'] = True
            return f"\nğŸ’¡ **åˆå§‹è§£å†³æ–¹æ¡ˆ**\n\n{content}\n\n"
        elif len(content) > 30:
            return f"\nğŸ’¡ **åˆå§‹åˆ†æ**\n\n{content}\n\n"

    return None


def _handle_expand_message(message_type: str, content: str, lats_state: Dict[str, Any], iteration_counter: int) -> Optional[str]:
    """å¤„ç†æ‰©å±•æœç´¢èŠ‚ç‚¹çš„æ¶ˆæ¯"""
    if "ToolMessage" in message_type:
        return f"\nğŸ”§ **æœç´¢è¿­ä»£ #{iteration_counter} å·¥å…·è°ƒç”¨å®Œæˆ**\n\nğŸ“‹ è·å–åˆ°æ–°ä¿¡æ¯ï¼Œç»§ç»­å€™é€‰æ–¹æ¡ˆè¯„ä¼°...\n"

    elif "AIMessage" in message_type:
        # æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ ¼å¼çš„å†…éƒ¨è¯„ä¼°æ•°æ®
        if _is_internal_evaluation_data(content):
            # å†…éƒ¨è¯„ä¼°æ•°æ®ï¼Œä¸è¾“å‡º
            logger.debug(f"[LATS SSE] è¿‡æ»¤å†…éƒ¨è¯„ä¼°æ•°æ®: {content[:50]}...")
            return None

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆæ€§çš„æœ€ç»ˆç­”æ¡ˆ
        if _is_comprehensive_answer(content):
            lats_state['final_solution_found'] = True
            return f"\n\nğŸ¯ **LATS æœ€ç»ˆç­”æ¡ˆ**\n\n{content}\n\n"

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ„ä¹‰çš„å€™é€‰æ–¹æ¡ˆ
        elif _is_substantial_response(content):
            return f"\n\nğŸ’¡ **å€™é€‰æ–¹æ¡ˆ**\n\n{content}\n\n"

    return None


def _handle_tools_message(message_type: str, content: str, lats_state: Dict[str, Any]) -> Optional[str]:
    """å¤„ç†å·¥å…·è°ƒç”¨èŠ‚ç‚¹çš„æ¶ˆæ¯"""
    if "ToolMessage" in message_type:
        if len(content) > 500:
            return "\nğŸ”§ **å·¥å…·æ‰§è¡Œå®Œæˆ**\n\nğŸ“Š å·²è·å–è¯¦ç»†ä¿¡æ¯ï¼Œæ­£åœ¨æ•´ç†åˆ†æ...\n"
        else:
            return "\nğŸ”§ **å·¥å…·æ‰§è¡Œå®Œæˆ**\n\nğŸ“‹ å·²è·å–ç›¸å…³ä¿¡æ¯\n"

    elif "AIMessage" in message_type and _is_substantial_response(content):
        return f"\nğŸ”§ **å·¥å…·å¤„ç†ç»“æœ**\n\n{content}\n\n"

    return None


def _handle_general_message(message_type: str, content: str, lats_state: Dict[str, Any]) -> Optional[str]:
    """å¤„ç†ä¸€èˆ¬æ¶ˆæ¯"""
    if "AIMessage" in message_type:
        # è¿‡æ»¤å†…éƒ¨è¯„ä¼°æ•°æ®
        if _is_internal_evaluation_data(content):
            return None

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰ä»·å€¼çš„å›ç­”
        if _is_comprehensive_answer(content):
            lats_state['final_solution_found'] = True
            return f"\n\nğŸ¯ **è§£å†³æ–¹æ¡ˆ**\n\n{content}\n\n"
        elif _is_substantial_response(content):
            return f"\n\nğŸ’¬ **å›ç­”**\n\n{content}\n\n"

    return None


def _is_internal_evaluation_data(content: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯å†…éƒ¨è¯„ä¼°æ•°æ®ï¼ˆJSONæ ¼å¼çš„è¯„åˆ†ã€åæ€ç­‰ï¼‰"""
    content_stripped = content.strip()

    # æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ ¼å¼
    if (content_stripped.startswith('{') and content_stripped.endswith('}')) or \
       (content_stripped.startswith('[') and content_stripped.endswith(']')):

        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯„ä¼°ç›¸å…³çš„å­—æ®µ
        evaluation_fields = ["reflections",
                             "score", "found_solution", "evaluation"]
        content_lower = content.lower()

        if any(field in content_lower for field in evaluation_fields):
            return True

    return False


def _is_comprehensive_answer(content: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆæ€§çš„æœ€ç»ˆç­”æ¡ˆ"""
    # åŸºäºå†…å®¹é•¿åº¦å’Œç»“æ„å®Œæ•´æ€§åˆ¤æ–­
    if len(content) < 50:
        return False

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šç§ç±»å‹çš„ä¿¡æ¯ï¼ˆè¯´æ˜æ˜¯ç»¼åˆæ€§å›ç­”ï¼‰
    content_indicators = [
        len([char for char in content if char in 'ã€‚ï¼ï¼Ÿ.!?']) >= 2,  # åŒ…å«å¤šä¸ªå¥å­
        'ï¼š' in content or ':' in content,  # åŒ…å«è¯´æ˜æ€§å†…å®¹
        len(content.split()) >= 15,  # åŒ…å«è¶³å¤Ÿçš„è¯æ±‡
        any(word in content for word in [
            'æ•°æ®åº“', 'ç³»ç»Ÿ', 'äº§å“', 'æŠ€æœ¯', 'è§£å†³æ–¹æ¡ˆ', 'ä»‹ç»', 'ç‰¹ç‚¹', 'åŠŸèƒ½', 'åº”ç”¨']),  # åŒ…å«å®è´¨æ€§å†…å®¹
        len(content) > 80,  # å†…å®¹é•¿åº¦è¶³å¤Ÿ
    ]

    # å¦‚æœæ»¡è¶³å¤šä¸ªæŒ‡æ ‡ï¼Œè®¤ä¸ºæ˜¯ç»¼åˆæ€§ç­”æ¡ˆ
    return sum(content_indicators) >= 3


def _is_substantial_response(content: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰å®è´¨å†…å®¹çš„å›ç­”"""
    if len(content) < 10:
        return False

    # æ’é™¤æ˜æ˜¾çš„ç³»ç»Ÿæ¶ˆæ¯æˆ–æç¤º
    system_indicators = [
        content.startswith('System:'),
        content.startswith('Human:'),
        content.startswith('Assistant:'),
        'tool_call' in content.lower(),
        'function_call' in content.lower(),
        content.strip().endswith('...'),  # çœç•¥å·ç»“å°¾é€šå¸¸æ˜¯ä¸å®Œæ•´å†…å®¹
        len(content.strip().split()) < 3,  # è¯æ±‡å¤ªå°‘
    ]

    return not any(system_indicators)


async def _send_sse_data(res, chat_id: str, created: int, model: str, content: str, finish_reason: str = None) -> None:
    """å‘é€SSEæ•°æ®"""
    response = {
        "id": chat_id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [{
            "delta": {
                "role": "assistant",
                "content": content
            },
            "index": 0,
            "finish_reason": finish_reason
        }]
    }

    json_str = json.dumps(response, ensure_ascii=False, separators=(',', ':'))
    await res.write(f"data: {json_str}\n\n".encode('utf-8'))


async def _send_end_signal(res, chat_id: str, created: int, model: str) -> None:
    """å‘é€ç»“æŸä¿¡å·"""
    end_response = {
        "id": chat_id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [{
            "delta": {},
            "index": 0,
            "finish_reason": "stop"
        }]
    }

    json_str = json.dumps(
        end_response, ensure_ascii=False, separators=(',', ':'))
    await res.write(f"data: {json_str}\n\n".encode('utf-8'))
    await res.write("data: [DONE]\n\n".encode('utf-8'))


async def _adaptive_delay(content: str) -> None:
    """æ ¹æ®å†…å®¹ç±»å‹è‡ªé€‚åº”å»¶è¿Ÿ"""
    if "æœç´¢è¿­ä»£" in content or "å€™é€‰è§£å†³æ–¹æ¡ˆ" in content:
        await asyncio.sleep(0.4)
    elif "å·¥å…·" in content or "è°ƒç”¨" in content:
        await asyncio.sleep(0.3)
    elif "æœ€ç»ˆç­”æ¡ˆ" in content or "è§£å†³æ–¹æ¡ˆ" in content:
        await asyncio.sleep(0.2)
    else:
        await asyncio.sleep(0.1)
