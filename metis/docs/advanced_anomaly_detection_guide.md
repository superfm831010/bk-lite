# AIOps å¼‚å¸¸æ£€æµ‹ç®—æ³•ä¼˜åŒ–æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¼ä¸šçº§çš„AIOpså¼‚å¸¸æ£€æµ‹è§£å†³æ–¹æ¡ˆï¼ŒåŸºäºéšæœºæ£®æ—ç®—æ³•ï¼Œé›†æˆäº†å…ˆè¿›çš„ç‰¹å¾å·¥ç¨‹ã€è¶…å‚æ•°ä¼˜åŒ–å’ŒMLflowå®éªŒç®¡ç†åŠŸèƒ½ã€‚

## ğŸš€ æ ¸å¿ƒä¼˜åŒ–ç‰¹æ€§

### 1. å¢å¼ºçš„ç‰¹å¾å·¥ç¨‹
- **50+ æ—¶åºç‰¹å¾**ï¼šç»Ÿè®¡ç‰¹å¾ã€å·®åˆ†ç‰¹å¾ã€è¶‹åŠ¿ç‰¹å¾ã€å‘¨æœŸæ€§ç‰¹å¾ç­‰
- **æ™ºèƒ½ç¼ºå¤±å€¼å¤„ç†**ï¼šçº¿æ€§æ’å€¼ + å‰åå‘å¡«å…… + å‡å€¼å¡«å……
- **å¼‚å¸¸å€¼æ£€æµ‹ç‰¹å¾**ï¼šIQRæ–¹æ³•å’ŒZ-scoreæ–¹æ³•
- **æ—¶é—´ç¼–ç **ï¼šsin/cosç¼–ç å¤„ç†å‘¨æœŸæ€§

### 2. æ™ºèƒ½è¶…å‚æ•°ä¼˜åŒ–
- **å¤šå±‚æ¬¡æœç´¢ç©ºé—´**ï¼šç”Ÿäº§/å¼€å‘/å¿«é€Ÿæµ‹è¯•æ¨¡å¼
- **æ—©åœæœºåˆ¶**ï¼šé¿å…è¿‡åº¦æœç´¢ï¼Œæå‡æ•ˆç‡
- **æœ€ä¼˜é˜ˆå€¼è‡ªåŠ¨å‘ç°**ï¼šåŸºäºéªŒè¯é›†çš„F1åˆ†æ•°ä¼˜åŒ–
- **å‚æ•°é‡è¦æ€§åˆ†æ**ï¼šäº†è§£å“ªäº›å‚æ•°æœ€å½±å“æ¨¡å‹æ€§èƒ½

### 3. å…¨é¢çš„æ¨¡å‹è¯„ä¼°
- **å¤šç»´åº¦æŒ‡æ ‡**ï¼šF1ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€AUCã€ç‰¹å¼‚æ€§ç­‰
- **äº¤å‰éªŒè¯**ï¼š5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯ç¡®ä¿æ¨¡å‹ç¨³å®šæ€§
- **ç‰¹å¾ç¨³å®šæ€§åˆ†æ**ï¼šè¯„ä¼°ç‰¹å¾åœ¨ä¸åŒæ•°æ®å­é›†ä¸Šçš„ä¸€è‡´æ€§
- **æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Š**ï¼šè¯¦ç»†çš„åˆ†ç±»æ€§èƒ½åˆ†æ

### 4. ä¼ä¸šçº§MLflowé›†æˆ
- **å®Œæ•´å®éªŒè¿½è¸ª**ï¼šå‚æ•°ã€æŒ‡æ ‡ã€æ¨¡å‹ã€é…ç½®æ–‡ä»¶
- **è‡ªåŠ¨æ¨¡å‹æ³¨å†Œ**ï¼šæ”¯æŒæ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œé˜¶æ®µè½¬æ¢
- **å¯è§†åŒ–åˆ†æ**ï¼šROC/PRæ›²çº¿ã€ç‰¹å¾é‡è¦æ€§ã€å‚æ•°æ¢ç´¢å†å²
- **å®éªŒæ¯”è¾ƒ**ï¼šå¤šä¸ªå®éªŒè¿è¡Œçš„å¯¹æ¯”åˆ†æ

### 5. æ•°æ®ä¸å¹³è¡¡å¤„ç†
- **ç±»åˆ«æƒé‡å¹³è¡¡**ï¼šè‡ªåŠ¨è®¡ç®—æœ€ä¼˜ç±»åˆ«æƒé‡
- **SMOTEè¿‡é‡‡æ ·**ï¼šåˆæˆå°‘æ•°ç±»æ ·æœ¬
- **æ¬ é‡‡æ ·**ï¼šéšæœºæ¬ é‡‡æ ·å¤„ç†æ•°æ®ä¸å¹³è¡¡

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

### åŸºç¡€ä½¿ç”¨

```python
from src.anomaly_detection.random_forest_detector import RandomForestAnomalyDetector

# åˆ›å»ºæ£€æµ‹å™¨
detector = RandomForestAnomalyDetector()

# è®­ç»ƒæ¨¡å‹
results = detector.train(
    experiment_name="my_anomaly_detection",
    train_data_path="data/train.csv",
    val_data_path="data/val.csv", 
    test_data_path="data/test.csv",
    freq='5T',  # 5åˆ†é’Ÿé¢‘ç‡
    window=24,  # 2å°æ—¶çª—å£
    data_balance_strategy='class_weight'
)

# é¢„æµ‹å¼‚å¸¸
predictions = detector.predict(new_data, "my_anomaly_detection")
```

### é«˜çº§é…ç½®

```python
# ä½¿ç”¨é¢„è®¾é…ç½®
from config.anomaly_detection_config import get_config_for_scenario

# ç”Ÿäº§ç¯å¢ƒé…ç½®
config = get_config_for_scenario("production")

results = detector.train(
    experiment_name="production_anomaly_detection",
    train_data_path="data/train.csv",
    val_data_path="data/val.csv",
    test_data_path="data/test.csv",
    **config
)
```

### è‡ªå®šä¹‰è¶…å‚æ•°æœç´¢

```python
# è‡ªå®šä¹‰è¶…å‚æ•°ä¼˜åŒ–é…ç½®
hyperopt_config = {
    "search_mode": "default",
    "max_evals": 100,
    "early_stop_patience": 20,
    "space": {
        "n_estimators": {"type": "choice", "options": [200, 300, 500]},
        "max_depth": {"type": "choice", "options": [15, 20, None]},
        "class_weight": {"type": "choice", "options": ["balanced"]}
    }
}

results = detector.train(
    experiment_name="custom_optimization",
    # ... å…¶ä»–å‚æ•°
    hyperopt_config=hyperopt_config
)
```

## ğŸ“Š æ•°æ®æ ¼å¼è¦æ±‚

### è¾“å…¥æ•°æ®æ ¼å¼
CSVæ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š
- `timestamp`: æ—¶é—´æˆ³ (æ ¼å¼ï¼šYYYY-MM-DD HH:MM:SS)
- `value`: ç›‘æ§æŒ‡æ ‡æ•°å€¼
- `label`: æ ‡ç­¾ (0=æ­£å¸¸, 1=å¼‚å¸¸)

ç¤ºä¾‹ï¼š
```csv
timestamp,value,label
2024-01-01 00:00:00,45.2,0
2024-01-01 00:05:00,47.1,0
2024-01-01 00:10:00,89.5,1
```

### é¢„æµ‹è¾“å‡ºæ ¼å¼
```csv
timestamp,value,anomaly_probability,is_anomaly,confidence
2024-01-01 00:00:00,45.2,0.1,0,0.8
2024-01-01 00:05:00,47.1,0.15,0,0.7
2024-01-01 00:10:00,89.5,0.85,1,0.7
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®é¢‘ç‡é€‰æ‹©
- **é«˜é¢‘æ•°æ®** (ç§’çº§): ä½¿ç”¨è¾ƒå¤§çª—å£(60-120), è¾ƒå°‘æ ‘(100-200)
- **ä¸­é¢‘æ•°æ®** (åˆ†é’Ÿçº§): ä½¿ç”¨ä¸­ç­‰çª—å£(24-48), ä¸­ç­‰æ ‘æ•°(200-300)
- **ä½é¢‘æ•°æ®** (å°æ—¶çº§): ä½¿ç”¨è¾ƒå°çª—å£(7-24), è¾ƒå¤šæ ‘(300-500)

### 2. çª—å£å¤§å°å»ºè®®
- **1å°æ—¶çª—å£**: window=12 (5åˆ†é’Ÿé¢‘ç‡)
- **2å°æ—¶çª—å£**: window=24 (5åˆ†é’Ÿé¢‘ç‡)
- **4å°æ—¶çª—å£**: window=48 (5åˆ†é’Ÿé¢‘ç‡)
- **1å¤©çª—å£**: window=24 (1å°æ—¶é¢‘ç‡)

### 3. è¶…å‚æ•°ä¼˜åŒ–ç­–ç•¥
- **å¿«é€Ÿæµ‹è¯•**: max_evals=20, early_stop_patience=5
- **å¼€å‘é˜¶æ®µ**: max_evals=50, early_stop_patience=15
- **ç”Ÿäº§éƒ¨ç½²**: max_evals=100, early_stop_patience=20

### 4. æ•°æ®ä¸å¹³è¡¡å¤„ç†
- **è½»å¾®ä¸å¹³è¡¡** (1-10%): ä½¿ç”¨class_weight='balanced'
- **ä¸­åº¦ä¸å¹³è¡¡** (0.1-1%): ä½¿ç”¨class_weight='balanced_subsample'
- **ä¸¥é‡ä¸å¹³è¡¡** (<0.1%): ä½¿ç”¨SMOTEè¿‡é‡‡æ ·

## ğŸ“ˆ MLflowå®éªŒç®¡ç†

### æŸ¥çœ‹å®éªŒç»“æœ
```bash
# å¯åŠ¨MLflow UI
mlflow ui --backend-store-uri <your_mlflow_uri>
```

### å…³é”®æŒ‡æ ‡å«ä¹‰
- **val_f1**: éªŒè¯é›†F1åˆ†æ•°ï¼ˆä¸»è¦ä¼˜åŒ–ç›®æ ‡ï¼‰
- **test_f1**: æµ‹è¯•é›†F1åˆ†æ•°ï¼ˆæœ€ç»ˆæ€§èƒ½ï¼‰
- **optimal_threshold**: æœ€ä¼˜åˆ†ç±»é˜ˆå€¼
- **feature_importance_***: ç‰¹å¾é‡è¦æ€§
- **cv_f1_mean**: äº¤å‰éªŒè¯å¹³å‡F1åˆ†æ•°

### æ¨¡å‹é€‰æ‹©å‡†åˆ™
1. **éªŒè¯F1åˆ†æ•°** > 0.8
2. **æµ‹è¯•F1åˆ†æ•°** ä¸éªŒè¯F1åˆ†æ•°å·®å¼‚ < 0.05
3. **äº¤å‰éªŒè¯æ ‡å‡†å·®** < 0.02
4. **ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ** åˆç†ï¼ˆéè¿‡åº¦é›†ä¸­ï¼‰

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - å‡å°‘`n_estimators`å‚æ•°
   - å‡å°‘`max_evals`å‚æ•°
   - ä½¿ç”¨`max_samples`å‚æ•°é™åˆ¶é‡‡æ ·

2. **è®­ç»ƒæ—¶é—´è¿‡é•¿**
   - ä½¿ç”¨"quick"æœç´¢æ¨¡å¼
   - å‡å°‘`window`å¤§å°
   - è®¾ç½®è¾ƒå°çš„`early_stop_patience`

3. **æ¨¡å‹æ€§èƒ½å·®**
   - æ£€æŸ¥æ•°æ®è´¨é‡å’Œæ ‡ç­¾æ­£ç¡®æ€§
   - å¢åŠ `window`å¤§å°
   - å°è¯•ä¸åŒçš„`data_balance_strategy`
   - å¢åŠ è®­ç»ƒæ•°æ®é‡

4. **ç‰¹å¾é‡è¦æ€§å¼‚å¸¸**
   - æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰æ•°æ®æ³„éœ²
   - éªŒè¯æ—¶é—´ç‰¹å¾çš„ç¼–ç æ˜¯å¦æ­£ç¡®
   - æ£€æŸ¥æ˜¯å¦æœ‰å¸¸æ•°ç‰¹å¾

### è°ƒè¯•æ¨¡å¼
```python
import logging
logging.basicConfig(level=logging.INFO)

# å¯ç”¨è¯¦ç»†æ—¥å¿—
detector.train(
    # ... å‚æ•°
    enable_cross_validation=True,  # å¯ç”¨äº¤å‰éªŒè¯è°ƒè¯•
    enable_feature_selection=True  # å¯ç”¨ç‰¹å¾åˆ†æ
)
```

## ğŸ“š API å‚è€ƒ

### RandomForestAnomalyDetector

#### train()æ–¹æ³•
```python
def train(
    experiment_name: str,           # MLflowå®éªŒåç§°
    train_data_path: str,          # è®­ç»ƒæ•°æ®è·¯å¾„
    val_data_path: str,            # éªŒè¯æ•°æ®è·¯å¾„ 
    test_data_path: str,           # æµ‹è¯•æ•°æ®è·¯å¾„
    freq: str = 'infer',           # æ—¶é—´é¢‘ç‡
    window: int = 30,              # æ»‘åŠ¨çª—å£å¤§å°
    random_state: int = 42,        # éšæœºç§å­
    hyperopt_config: Dict = None,  # è¶…å‚æ•°ä¼˜åŒ–é…ç½®
    enable_feature_selection: bool = True,    # å¯ç”¨ç‰¹å¾é€‰æ‹©
    enable_cross_validation: bool = True,     # å¯ç”¨äº¤å‰éªŒè¯
    data_balance_strategy: str = 'class_weight'  # æ•°æ®å¹³è¡¡ç­–ç•¥
) -> Dict[str, Any]
```

#### predict()æ–¹æ³•  
```python
def predict(
    data: pd.DataFrame,    # è¾“å…¥æ•°æ®
    model_name: str        # æ¨¡å‹åç§°
) -> pd.DataFrame
```

### AiopsUtils

ä¸»è¦å·¥å…·æ–¹æ³•ï¼š
- `load_timestamp_csv_data()`: åŠ è½½æ—¶åºæ•°æ®
- `prepare_timestamp_features()`: ç‰¹å¾å·¥ç¨‹
- `calculate_comprehensive_metrics()`: è®¡ç®—è¯„ä¼°æŒ‡æ ‡
- `cross_validate_model()`: äº¤å‰éªŒè¯
- `prepare_balanced_data()`: æ•°æ®å¹³è¡¡å¤„ç†

## ğŸ‰ ç¤ºä¾‹è¿è¡Œ

è¿è¡Œå®Œæ•´ç¤ºä¾‹ï¼š
```bash
# å®Œæ•´æ¼”ç¤º
python examples/advanced_anomaly_detection_example.py --mode full

# å¿«é€Ÿæ¼”ç¤º  
python examples/advanced_anomaly_detection_example.py --mode quick
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0 (å½“å‰ç‰ˆæœ¬)
- âœ… 50+ å¢å¼ºæ—¶åºç‰¹å¾
- âœ… æ™ºèƒ½è¶…å‚æ•°ä¼˜åŒ–
- âœ… ä¼ä¸šçº§MLflowé›†æˆ
- âœ… æ•°æ®ä¸å¹³è¡¡å¤„ç†
- âœ… äº¤å‰éªŒè¯å’Œç¨³å®šæ€§åˆ†æ
- âœ… æœ€ä¼˜é˜ˆå€¼è‡ªåŠ¨å‘ç°
- âœ… å…¨é¢çš„æ¨¡å‹è¯Šæ–­

### v1.0 (åŸç‰ˆæœ¬)
- åŸºç¡€éšæœºæ£®æ—å®ç°
- ç®€å•ç‰¹å¾å·¥ç¨‹
- åŸºç¡€MLflowè®°å½•

---

ğŸ¯ **æ ¸å¿ƒä»·å€¼**: é€šè¿‡ç§‘å­¦çš„æ–¹æ³•è®ºå’Œå·¥ç¨‹æœ€ä½³å®è·µï¼Œæ‰“é€ é«˜ç²¾åº¦ã€é«˜ç¨³å®šæ€§çš„AIOpså¼‚å¸¸æ£€æµ‹è§£å†³æ–¹æ¡ˆã€‚
