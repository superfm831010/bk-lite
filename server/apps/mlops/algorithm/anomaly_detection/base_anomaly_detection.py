import abc
from math import log
from typing import Any, Dict
from functools import lru_cache
import time
import threading

from apps.mlops.models.anomaly_detection_train_job import AnomalyDetectionTrainJob
from config.components.mlflow import MLFLOW_TRACKER_URL
import mlflow
import json
import pandas as pd
import numpy as np
from hyperopt import hp, fmin, tpe, Trials, STATUS_OK
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, balanced_accuracy_score
from imblearn.metrics import geometric_mean_score
from apps.core.logger import mlops_logger as logger


class BaseAnomalyDetection(abc.ABC):
    # ç±»çº§åˆ«çš„æ¨¡å‹ç¼“å­˜ï¼Œçº¿ç¨‹å®‰å…¨
    _model_cache = {}
    _cache_lock = threading.Lock()
    _cache_expiry_time = 3600  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    
    def __init__(self):
        super().__init__()

    @classmethod
    def _get_cache_key(cls, model_name: str, model_version: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{model_name}:{model_version}"
    
    @classmethod
    def _is_cache_valid(cls, cache_entry: dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if not cache_entry:
            return False
        
        current_time = time.time()
        cache_time = cache_entry.get('cached_at', 0)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡è¿‡æœŸæ—¶é—´
        return (current_time - cache_time) < cls._cache_expiry_time
    
    @classmethod
    def _load_model_with_cache(cls, model_name: str, model_version: str):
        """
        å¸¦ç¼“å­˜çš„æ¨¡å‹åŠ è½½æ–¹æ³•
        
        Args:
            model_name: æ¨¡å‹åç§°
            model_version: æ¨¡å‹ç‰ˆæœ¬
            
        Returns:
            åŠ è½½çš„æ¨¡å‹å¯¹è±¡
        """
        cache_key = cls._get_cache_key(model_name, model_version)
        
        with cls._cache_lock:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
            if cache_key in cls._model_cache and cls._is_cache_valid(cls._model_cache[cache_key]):
                logger.info(f"ğŸ¯ ä½¿ç”¨ç¼“å­˜æ¨¡å‹: {model_name}:{model_version}")
                return cls._model_cache[cache_key]['model']
            
            # ç¼“å­˜æœªå‘½ä¸­æˆ–å·²è¿‡æœŸï¼Œé‡æ–°åŠ è½½æ¨¡å‹
            logger.info(f"ğŸ“¥ ä»MLflowåŠ è½½æ¨¡å‹: {model_name}:{model_version}")
            
            try:
                mlflow.set_tracking_uri(MLFLOW_TRACKER_URL)
                model_uri = f"models:/{model_name}/{model_version}"
                model = mlflow.sklearn.load_model(model_uri)
                
                # æ›´æ–°ç¼“å­˜
                cls._model_cache[cache_key] = {
                    'model': model,
                    'cached_at': time.time(),
                    'model_name': model_name,
                    'model_version': model_version
                }
                
                logger.info(f"âœ… æ¨¡å‹å·²ç¼“å­˜: {model_name}:{model_version}")
                return model
                
            except Exception as e:
                logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {model_name}:{model_version}, é”™è¯¯: {str(e)}")
                raise
    
    @classmethod
    def clear_model_cache(cls, model_name: str = None, model_version: str = None):
        """
        æ¸…ç†æ¨¡å‹ç¼“å­˜
        
        Args:
            model_name: å¯é€‰ï¼ŒæŒ‡å®šè¦æ¸…ç†çš„æ¨¡å‹åç§°
            model_version: å¯é€‰ï¼ŒæŒ‡å®šè¦æ¸…ç†çš„æ¨¡å‹ç‰ˆæœ¬
        """
        with cls._cache_lock:
            if model_name and model_version:
                # æ¸…ç†æŒ‡å®šæ¨¡å‹
                cache_key = cls._get_cache_key(model_name, model_version)
                if cache_key in cls._model_cache:
                    del cls._model_cache[cache_key]
                    logger.info(f"ğŸ—‘ï¸  å·²æ¸…ç†æŒ‡å®šæ¨¡å‹ç¼“å­˜: {model_name}:{model_version}")
            else:
                # æ¸…ç†æ‰€æœ‰ç¼“å­˜
                cls._model_cache.clear()
                logger.info(f"ğŸ—‘ï¸  å·²æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜")
    
    @classmethod
    def get_cache_info(cls) -> dict:
        """è·å–ç¼“å­˜ä¿¡æ¯ç”¨äºç›‘æ§"""
        with cls._cache_lock:
            cache_info = {
                'total_cached_models': len(cls._model_cache),
                'cache_expiry_seconds': cls._cache_expiry_time,
                'cached_models': []
            }
            
            current_time = time.time()
            for cache_key, cache_entry in cls._model_cache.items():
                cache_age = current_time - cache_entry.get('cached_at', 0)
                is_valid = cls._is_cache_valid(cache_entry)
                
                cache_info['cached_models'].append({
                    'model_name': cache_entry.get('model_name'),
                    'model_version': cache_entry.get('model_version'),
                    'cache_age_seconds': cache_age,
                    'is_valid': is_valid
                })
                
            return cache_info

    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray, subprefix: str) -> Dict[str, float]:
        """è®¡ç®—åˆ†ç±»è¯„ä¼°æŒ‡æ ‡"""
        return {
            f"{subprefix}_accuracy": accuracy_score(y_true, y_pred),
            f"{subprefix}_precision": precision_score(y_true, y_pred, zero_division=0),
            f"{subprefix}_recall": recall_score(y_true, y_pred, zero_division=0),
            f"{subprefix}_f1": f1_score(y_true, y_pred, zero_division=0),
        }

    def prepare_features(cls, windows_size: int, df: pd.DataFrame, freq: str = 'infer') :
        # ç¡®ä¿timestampåˆ—è½¬æ¢ä¸ºdatetimeæ ¼å¼
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
        df = df.set_index('timestamp')
        predict_freq = freq
        if freq == 'infer':
            predict_freq = pd.infer_freq(df.index)
            
        logger.info(f"ğŸ” æŒ‡æ ‡é—´éš”: {predict_freq}, çª—å£å¤§å°: {windows_size}")
        df = df.asfreq(predict_freq)
        df['value'] = df['value'].interpolate('linear').bfill().ffill()

        # è®¡ç®—æ»šåŠ¨çª—å£ç»Ÿè®¡é‡
        rolling = df['value'].rolling(windows_size, min_periods=1)
        df['rolling_mean'] = rolling.mean()
        df['rolling_std'] = rolling.std().fillna(1e-5)  # é¿å…é™¤ä»¥0

        df_features = {
            # åŸå§‹å€¼
            'value': df['value'],

            # ç»Ÿè®¡ç‰¹å¾
            'rolling_min': rolling.min(),
            'rolling_max': rolling.max(),
            'rolling_median': rolling.median(),

            # å·®åˆ†ç‰¹å¾
            'diff_1': df['value'].diff().fillna(0),
            'diff_2': df['value'].diff().diff().fillna(0),

            # å½’ä¸€åŒ–ç‰¹å¾
            'zscore': (df['value'] - df['rolling_mean']) / df['rolling_std'],

            # è¶‹åŠ¿ç‰¹å¾
            'trend': rolling.apply(lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0),

            # è‡ªç›¸å…³ç‰¹å¾
            'autocorr_1': df['value'].rolling(windows_size * 2, min_periods=windows_size)
            .apply(lambda x: x.autocorr(lag=1) if len(x) > windows_size else 0)
            if len(df) >= windows_size * 2 else pd.Series(0, index=df.index),

            # æ—¶é—´ç‰¹å¾
            'hour': df.index.hour,
            'minute': df.index.minute,
            'dayofweek': df.index.dayofweek,
            'month': df.index.month,
            'is_weekend': (df.index.dayofweek >= 5).astype(int),
        }

        features_df = pd.DataFrame(df_features, index=df.index)

        if 'label' in df.columns:
            features_df['label'] = df['label']

        features_df = features_df.dropna()

        feature_columns = [
            col for col in features_df.columns if col != 'label']
        return features_df, feature_columns, predict_freq

    def predict(self, data: pd.DataFrame, model_name: str, model_version: str = "latest") -> pd.DataFrame:
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå¼‚å¸¸æ£€æµ‹é¢„æµ‹ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰

        Args:
            data: åŒ…å«timestampå’Œvalueåˆ—çš„DataFrame
            model_name: æ¨¡å‹åç§°
            model_version: æ¨¡å‹ç‰ˆæœ¬ï¼Œé»˜è®¤ä¸ºlatest

        Returns:
            åŒ…å«é¢„æµ‹ç»“æœçš„DataFrame
        """
        # ä½¿ç”¨ç¼“å­˜æœºåˆ¶åŠ è½½æ¨¡å‹
        model = self._load_model_with_cache(model_name, model_version)

        test_df, feature_columns, _ = self.prepare_features(model.window, data, model.freq)

        # è·å–å¼‚å¸¸æ¦‚ç‡ï¼Œå¤„ç†å•ç±»åˆ«æƒ…å†µ
        probabilities = model.predict_proba(test_df[feature_columns])[:, 1]
        return pd.DataFrame({
            'value': test_df['value'],
            'anomaly_probability': probabilities,
        })

    def train(
        self,
        entity: AnomalyDetectionTrainJob,
    ) -> None:
        mlflow.set_tracking_uri(MLFLOW_TRACKER_URL)
        experiment_name = f"{entity.id}_{entity.name}"
        mlflow.set_experiment(experiment_name)
        logger.info(f"ğŸ” å¼€å§‹è®­ç»ƒä»»åŠ¡: å®éªŒ: {experiment_name}")

        train_df = pd.DataFrame(entity.train_data_id.train_data)

        # åŸºäºmetadataä¸­çš„å¼‚å¸¸ç‚¹ç´¢å¼•ç”Ÿæˆlabelåˆ—
        # åˆå§‹åŒ–æ‰€æœ‰ç‚¹ä¸ºæ­£å¸¸ï¼ˆ0ï¼‰
        train_df['label'] = 0

        # è·å–å¼‚å¸¸ç‚¹ç´¢å¼•åˆ—è¡¨
        anomaly_indices = entity.train_data_id.metadata['anomaly_point']
        if anomaly_indices and isinstance(anomaly_indices, list):
            # å°†æŒ‡å®šç´¢å¼•ä½ç½®æ ‡è®°ä¸ºå¼‚å¸¸ï¼ˆ1ï¼‰
            valid_indices = [idx for idx in anomaly_indices if 0 <= idx < len(train_df)]
            train_df.loc[valid_indices, 'label'] = 1
        train_df, feature_columns, freq = self.prepare_features(entity.windows_size, train_df)
        X_train, y_train = train_df[feature_columns].values, train_df['label'].values
        logger.info(f"ğŸ“ è®­ç»ƒé›†: æ ·æœ¬æ•°: {len(X_train)}")

        val_df = pd.DataFrame(entity.val_data_id.train_data)

        # åŸºäºmetadataä¸­çš„å¼‚å¸¸ç‚¹ç´¢å¼•ç”ŸæˆéªŒè¯é›†labelåˆ—
        # åˆå§‹åŒ–æ‰€æœ‰ç‚¹ä¸ºæ­£å¸¸ï¼ˆ0ï¼‰
        val_df['label'] = 0

        # è·å–éªŒè¯é›†å¼‚å¸¸ç‚¹ç´¢å¼•åˆ—è¡¨
        val_anomaly_indices = entity.val_data_id.metadata['anomaly_point']
        if val_anomaly_indices and isinstance(val_anomaly_indices, list):
            # å°†æŒ‡å®šç´¢å¼•ä½ç½®æ ‡è®°ä¸ºå¼‚å¸¸ï¼ˆ1ï¼‰
            val_valid_indices = [idx for idx in val_anomaly_indices if 0 <= idx < len(val_df)]
            val_df.loc[val_valid_indices, 'label'] = 1

        val_df, _, _ = self.prepare_features(entity.windows_size, val_df)
        X_val, y_val = val_df[feature_columns].values, val_df['label'].values
        logger.info(f"ğŸ“ éªŒè¯é›†: æ ·æœ¬æ•°: {len(X_val)}")

        test_df = pd.DataFrame(entity.test_data_id.train_data)

        # åŸºäºmetadataä¸­çš„å¼‚å¸¸ç‚¹ç´¢å¼•ç”Ÿæˆæµ‹è¯•é›†labelåˆ—
        # åˆå§‹åŒ–æ‰€æœ‰ç‚¹ä¸ºæ­£å¸¸ï¼ˆ0ï¼‰
        test_df['label'] = 0

        # è·å–æµ‹è¯•é›†å¼‚å¸¸ç‚¹ç´¢å¼•åˆ—è¡¨
        test_anomaly_indices = entity.test_data_id.metadata['anomaly_point']
        if test_anomaly_indices and isinstance(test_anomaly_indices, list):
            # å°†æŒ‡å®šç´¢å¼•ä½ç½®æ ‡è®°ä¸ºå¼‚å¸¸ï¼ˆ1ï¼‰
            test_valid_indices = [idx for idx in test_anomaly_indices if 0 <= idx < len(test_df)]
            test_df.loc[test_valid_indices, 'label'] = 1

        test_df, _, _ = self.prepare_features(entity.windows_size, test_df)
        X_test, y_test = test_df[feature_columns].values, test_df['label'].values
        logger.info(f"ğŸ“ æµ‹è¯•é›†: æ ·æœ¬æ•°: {len(X_test)}")

        hyperopt_config = {}
        for key, value in entity.hyperopt_config.items():
            if value['type'] == 'randint':
                hyperopt_config[key] = hp.randint(key, value['min'], value['max'])
            if value['type'] == 'choice':
                options = []
                for choice in value['choice']:
                    if choice == 'none':
                        options.append(None)
                    elif choice == 'true':
                        options.append(True)
                    elif choice == 'false':
                        options.append(False)
                    else:
                        options.append(choice)
                hyperopt_config[key] = hp.choice(key, options)
        logger.info(f"ğŸš€ è¶…å‚æ•°ä¼˜åŒ–: æœ€å¤§è¯„ä¼°{entity.max_evals}")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        logger.info(f"ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ…å«å¼‚å¸¸å€¼æˆ–å¸¸æ•°åˆ—
        feature_stats = pd.DataFrame(train_df[feature_columns]).describe()
        constant_features = []
        for col in feature_columns:
            if train_df[col].nunique() <= 1:
                constant_features.append(col)
        
        if constant_features:
            logger.warning(f"âš ï¸  å‘ç°å¸¸æ•°ç‰¹å¾: {constant_features}")
            logger.warning(f"   è¿™äº›ç‰¹å¾å¯èƒ½å½±å“æ¨¡å‹è®­ç»ƒæ•ˆæœ")
        
        # æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
        train_positive_ratio = np.mean(y_train)
        val_positive_ratio = np.mean(y_val) 
        test_positive_ratio = np.mean(y_test)
        
        logger.info(f"ğŸ“Š è¯¦ç»†æ•°æ®ç»Ÿè®¡:")
        logger.info(f"   - è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, å¼‚å¸¸: {int(train_positive_ratio * len(X_train))}, æ¯”ä¾‹: {train_positive_ratio:.4f}")
        logger.info(f"   - éªŒè¯é›†: {len(X_val)} æ ·æœ¬, å¼‚å¸¸: {int(val_positive_ratio * len(X_val))}, æ¯”ä¾‹: {val_positive_ratio:.4f}")
        logger.info(f"   - æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬, å¼‚å¸¸: {int(test_positive_ratio * len(X_test))}, æ¯”ä¾‹: {test_positive_ratio:.4f}")
        
        # åˆ†å¸ƒä¸€è‡´æ€§æ£€æŸ¥
        ratio_diff = max(abs(train_positive_ratio - val_positive_ratio), 
                        abs(train_positive_ratio - test_positive_ratio),
                        abs(val_positive_ratio - test_positive_ratio))
        
        if ratio_diff > 0.2:
            logger.warning(f"âš ï¸  æ•°æ®é›†é—´å¼‚å¸¸æ¯”ä¾‹å·®å¼‚è¿‡å¤§: {ratio_diff:.4f}")
            logger.warning(f"   å¯èƒ½å½±å“æ¨¡å‹æ³›åŒ–æ€§èƒ½")
        
        # ç‰¹å¾å€¼èŒƒå›´æ£€æŸ¥
        train_feature_ranges = pd.DataFrame(X_train).describe()
        extreme_features = []
        for i, col in enumerate(feature_columns):
            col_data = X_train[:, i]
            if np.any(np.isinf(col_data)) or np.any(np.isnan(col_data)):
                extreme_features.append(col)
        
        if extreme_features:
            logger.error(f"âŒ å‘ç°å¼‚å¸¸ç‰¹å¾å€¼: {extreme_features}")
            logger.error(f"   åŒ…å«infæˆ–nanå€¼ï¼Œéœ€è¦æ•°æ®é¢„å¤„ç†")
        
        trials = Trials()
        step_counter = 0
        best_loss = float('inf')
        best_model = None  # åœ¨å¤–éƒ¨ä½œç”¨åŸŸä¿å­˜æœ€ä½³æ¨¡å‹

        def objective(params: Dict[str, Any]) -> Dict[str, Any]:
            nonlocal step_counter, best_loss, best_model
            step_counter += 1

            model = self.build_model(params)
            model.fit(X_train, y_train)

            # éªŒè¯é›†è¯„ä¼°
            y_val_pred = model.predict(X_val)
            val_metrics = self.calculate_metrics(
                y_val, y_val_pred, subprefix='val')
            val_accuracy = (y_val == y_val_pred).mean()

            # æµ‹è¯•é›†è¯„ä¼°ï¼ˆä»…ç”¨äºç›‘æ§ï¼Œä¸å‚ä¸ä¼˜åŒ–å†³ç­–ï¼‰
            y_test_pred = model.predict(X_test)
            test_metrics = self.calculate_metrics(
                y_test, y_test_pred, subprefix='test')
            test_accuracy = (y_test == y_test_pred).mean()

            # è·å–åŸºç¡€æŒ‡æ ‡
            recall = val_metrics.get('val_recall', 0.0)
            precision = val_metrics.get('val_precision', 0.0)
            f1 = val_metrics.get('val_f1', 0.0)
            
            # è®¡ç®—ç±»åˆ«åˆ†å¸ƒä¿¡æ¯
            positive_ratio = np.mean(y_val)  # å¼‚å¸¸æ ·æœ¬æ¯”ä¾‹
            
            # ä½¿ç”¨ç»å…¸çš„å¼‚å¸¸æ£€æµ‹æŸå¤±å‡½æ•° - é€‰æ‹©å…¶ä¸­ä¸€ç§
            
            # æ–¹æ¡ˆ1: F-betaæŸå¤± (æ¨èç”¨äºå¼‚å¸¸æ£€æµ‹ï¼Œbeta=2åå‘å¬å›ç‡)
            fbeta_2 = fbeta_score(y_val, y_val_pred, beta=2, zero_division=0)
            current_loss = 1.0 - fbeta_2
            
            # æ–¹æ¡ˆ2: å‡ ä½•å¹³å‡æŸå¤± (å¯¹ä¸å¹³è¡¡æ•°æ®æ•ˆæœå¥½)
            # geometric_mean = geometric_mean_score(y_val, y_val_pred)
            # current_loss = 1.0 - geometric_mean
            
            # æ–¹æ¡ˆ3: å¹³è¡¡å‡†ç¡®ç‡æŸå¤± (sklearnå†…ç½®ï¼Œå¤„ç†ä¸å¹³è¡¡æ•°æ®)
            # balanced_acc = balanced_accuracy_score(y_val, y_val_pred)
            # current_loss = 1.0 - balanced_acc
            
            # æ–¹æ¡ˆ4: Matthewsç›¸å…³ç³»æ•°æŸå¤± (å¯¹ä¸å¹³è¡¡æ•°æ®é²æ£’)
            # from sklearn.metrics import matthews_corrcoef
            # mcc = matthews_corrcoef(y_val, y_val_pred)
            # current_loss = 1.0 - (mcc + 1) / 2  # å½’ä¸€åŒ–åˆ°0-1
            
            # æ–¹æ¡ˆ5: åŠ æƒF1æŸå¤± (ç®€å•æœ‰æ•ˆ)
            # weight_recall = 0.7  # å¼‚å¸¸æ£€æµ‹åå‘å¬å›ç‡
            # weight_precision = 0.3
            # weighted_f1 = 2 * (weight_recall * recall * weight_precision * precision) / \
            #               (weight_recall * recall + weight_precision * precision + 1e-8)
            # current_loss = 1.0 - weighted_f1
            
            # æ·»åŠ ç¨³å®šæ€§æ‰°åŠ¨
            param_hash = hash(str(sorted(params.items()))) % 10000
            stability_term = param_hash * 1e-6
            current_loss += stability_term
            
            # è¯¦ç»†çš„æ€§èƒ½ä¿¡æ¯æ—¥å¿—è¾“å‡º
            logger.info(f"ğŸ“Š Step {step_counter:3d} | "
                       f"F1: {f1:.4f} | "
                       f"F2: {fbeta_2:.4f} | "
                       f"Recall: {recall:.4f} | "
                       f"Precision: {precision:.4f} | "
                       f"Loss: {current_loss:.6f}")
            
            # æ¯10æ­¥è¾“å‡ºä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
            if step_counter % 10 == 0:
                # è®¡ç®—é¢å¤–çš„è¯„ä¼°æŒ‡æ ‡ç”¨äºå¯¹æ¯”
                balanced_acc = balanced_accuracy_score(y_val, y_val_pred)
                geometric_mean = geometric_mean_score(y_val, y_val_pred)
                
                # è¿‡æ‹Ÿåˆæ£€æµ‹ï¼šéªŒè¯é›†ä¸æµ‹è¯•é›†æ€§èƒ½å·®å¼‚
                test_f1 = test_metrics.get('test_f1', 0.0)
                test_recall = test_metrics.get('test_recall', 0.0)
                test_precision = test_metrics.get('test_precision', 0.0)
                
                # è®¡ç®—éªŒè¯é›†å’Œæµ‹è¯•é›†çš„æ€§èƒ½å·®å¼‚
                f1_gap = abs(f1 - test_f1)
                recall_gap = abs(recall - test_recall)
                precision_gap = abs(precision - test_precision)
                
                # å®Œç¾åˆ†æ•°æ£€æµ‹ - å¯èƒ½çš„è¿‡æ‹Ÿåˆæˆ–æ•°æ®æ³„æ¼ä¿¡å·
                is_perfect_score = (f1 == 1.0 and recall == 1.0 and precision == 1.0)
                is_suspicious = (f1 > 0.99 or recall > 0.99 or precision > 0.99)
                
                logger.info(f"ğŸ” è¯¦ç»†åˆ†æ Step {step_counter}:")
                logger.info(f"   - éªŒè¯é›†æŒ‡æ ‡: F1={f1:.4f}, F2={fbeta_2:.4f}, Recall={recall:.4f}, Precision={precision:.4f}")
                logger.info(f"   - å¹³è¡¡æŒ‡æ ‡: Balanced_Acc={balanced_acc:.4f}, G-Mean={geometric_mean:.4f}")
                logger.info(f"   - æµ‹è¯•é›†æŒ‡æ ‡: F1={test_f1:.4f}, Recall={test_recall:.4f}, Precision={test_precision:.4f}")
                logger.info(f"   - æ€§èƒ½å·®å¼‚: F1_gap={f1_gap:.4f}, Recall_gap={recall_gap:.4f}, Precision_gap={precision_gap:.4f}")
                logger.info(f"   - æ•°æ®åˆ†å¸ƒ: å¼‚å¸¸æ¯”ä¾‹={positive_ratio:.4f}")
                logger.info(f"   - å½“å‰æŸå¤±: {current_loss:.6f} (åŸºäºF-beta score)")
                
                # è¿‡æ‹Ÿåˆè­¦å‘Š
                if is_perfect_score:
                    logger.warning(f"ğŸš¨ æ£€æµ‹åˆ°å®Œç¾åˆ†æ•° - å¯èƒ½å­˜åœ¨ä¸¥é‡è¿‡æ‹Ÿåˆæˆ–æ•°æ®æ³„æ¼!")
                    logger.warning(f"   å»ºè®®æ£€æŸ¥:")
                    logger.warning(f"   1. ç‰¹å¾å·¥ç¨‹æ˜¯å¦å¼•å…¥äº†æœªæ¥ä¿¡æ¯")
                    logger.warning(f"   2. æ•°æ®é›†åˆ’åˆ†æ˜¯å¦æ­£ç¡®")
                    logger.warning(f"   3. æ¨¡å‹å¤æ‚åº¦æ˜¯å¦è¿‡é«˜")
                    logger.warning(f"   4. æ ‡ç­¾ç”Ÿæˆé€»è¾‘æ˜¯å¦æ­£ç¡®")
                elif is_suspicious:
                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ°å¼‚å¸¸é«˜åˆ† - è¯·æ£€æŸ¥æ˜¯å¦è¿‡æ‹Ÿåˆ")
                
                # éªŒè¯é›†ä¸æµ‹è¯•é›†å·®å¼‚è¿‡å¤§è­¦å‘Š
                if f1_gap > 0.2 or recall_gap > 0.2 or precision_gap > 0.2:
                    logger.warning(f"âš ï¸  éªŒè¯é›†ä¸æµ‹è¯•é›†æ€§èƒ½å·®å¼‚è¿‡å¤§ - å¯èƒ½è¿‡æ‹Ÿåˆ")
                    logger.warning(f"   F1å·®å¼‚: {f1_gap:.4f}, å¬å›ç‡å·®å¼‚: {recall_gap:.4f}, ç²¾ç¡®ç‡å·®å¼‚: {precision_gap:.4f}")
                
                # æ•°æ®åˆ†å¸ƒåˆç†æ€§æ£€æŸ¥
                if positive_ratio > 0.8 or positive_ratio < 0.05:
                    logger.warning(f"âš ï¸  æ•°æ®é›†æ ‡ç­¾åˆ†å¸ƒå¼‚å¸¸: å¼‚å¸¸æ¯”ä¾‹={positive_ratio:.4f}")
                    if positive_ratio > 0.8:
                        logger.warning(f"   å¼‚å¸¸æ ·æœ¬è¿‡å¤šï¼Œå¯èƒ½ä¸æ˜¯çœŸå®çš„å¼‚å¸¸æ£€æµ‹åœºæ™¯")
                    else:
                        logger.warning(f"   å¼‚å¸¸æ ·æœ¬è¿‡å°‘ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹å­¦ä¹ å›°éš¾")

            # æ›´æ–°æœ€ä½³æ¨¡å‹
            if current_loss < best_loss:
                improvement = best_loss - current_loss
                best_loss = current_loss
                best_model = model
                logger.info(f"ğŸ¯ å‘ç°æ›´å¥½çš„æ¨¡å‹! Step {step_counter}")
                logger.info(f"   âœ¨ æ–°æœ€ä½³Loss: {current_loss:.6f} (æ”¹è¿›: {improvement:.6f})")
                logger.info(f"   âœ¨ éªŒè¯é›†è¡¨ç°: F1={f1:.4f}, F2={fbeta_2:.4f}, Recall={recall:.4f}, Precision={precision:.4f}")
                logger.info(f"   âœ¨ æµ‹è¯•é›†è¡¨ç°: F1={test_metrics.get('test_f1', 0.0):.4f}, "
                           f"Recall={test_metrics.get('test_recall', 0.0):.4f}, "
                           f"Precision={test_metrics.get('test_precision', 0.0):.4f}")
                
                # æ˜¾ç¤ºå½“å‰æœ€ä½³æ¨¡å‹çš„å‚æ•°
                param_str = ", ".join([f"{k}={v}" for k, v in params.items()])
                logger.info(f"   ğŸ”§ æ¨¡å‹å‚æ•°: {param_str}")
            
            # æ€§èƒ½è­¦å‘Š
            if fbeta_2 < 0.1 and step_counter > 5:
                logger.warning(f"âš ï¸  F-betaæ€§èƒ½è¾ƒå·® (F2={fbeta_2:.4f}) - å¯èƒ½éœ€è¦è°ƒæ•´è¶…å‚æ•°")
            
            if recall < 0.1 and step_counter > 5:
                logger.warning(f"âš ï¸  å¬å›ç‡è¿‡ä½ (Recall={recall:.4f}) - å¼‚å¸¸æ£€æµ‹æ¼æ£€ä¸¥é‡")

            # è®°å½•è¯¦ç»†çš„ä¼˜åŒ–ä¿¡æ¯
            mlflow.log_metric("optimization_loss", current_loss, step=step_counter)
            mlflow.log_metric("fbeta_2", fbeta_2, step=step_counter)
            mlflow.log_metric("balanced_accuracy", balanced_accuracy_score(y_val, y_val_pred), step=step_counter)
            mlflow.log_metric("geometric_mean", geometric_mean_score(y_val, y_val_pred), step=step_counter)
            mlflow.log_metric("positive_ratio", positive_ratio, step=step_counter)
            
            # è®°å½•éªŒè¯é›†æŒ‡æ ‡ï¼ˆç”¨äºä¼˜åŒ–ï¼‰
            mlflow.log_metric("val_f1", f1, step=step_counter)
            mlflow.log_metric("val_recall", recall, step=step_counter)
            mlflow.log_metric("val_precision", precision, step=step_counter)
            mlflow.log_metric("val_accuracy", val_accuracy, step=step_counter)

            # è®°å½•æµ‹è¯•é›†æŒ‡æ ‡ï¼ˆä»…ç›‘æ§ï¼Œä¸ç”¨äºä¼˜åŒ–å†³ç­–ï¼‰
            mlflow.log_metric("test_f1", test_metrics.get(
                'test_f1', 0.0), step=step_counter)
            mlflow.log_metric("test_recall", test_metrics.get(
                'test_recall', 0.0), step=step_counter)
            mlflow.log_metric("test_precision", test_metrics.get(
                'test_precision', 0.0), step=step_counter)
            mlflow.log_metric("test_accuracy", test_accuracy,
                              step=step_counter)

            return {"loss": current_loss, "status": STATUS_OK, "model": model, "val_f1": f1}

        with mlflow.start_run() as run:
            # è®°å½•ä¼˜åŒ–ç­–ç•¥ä¿¡æ¯
            mlflow.log_param("optimization_strategy", "enhanced_multi_objective_anomaly_detection")
            mlflow.log_param("recall_priority", True)
            mlflow.log_param("imbalance_aware", True)
            mlflow.log_param("loss_design_version", "v2_enhanced_discrimination")
            
            # è®°å½•æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
            train_positive_ratio = np.mean(y_train)
            val_positive_ratio = np.mean(y_val) 
            test_positive_ratio = np.mean(y_test)
            
            mlflow.log_param("train_positive_ratio", train_positive_ratio)
            mlflow.log_param("val_positive_ratio", val_positive_ratio)
            mlflow.log_param("test_positive_ratio", test_positive_ratio)
            
            logger.info(f"ğŸš€ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ– - æœ€å¤§è¯„ä¼°æ¬¡æ•°: {entity.max_evals}")
            logger.info(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
            logger.info(f"   - è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, å¼‚å¸¸æ¯”ä¾‹: {train_positive_ratio:.4f}")
            logger.info(f"   - éªŒè¯é›†: {len(X_val)} æ ·æœ¬, å¼‚å¸¸æ¯”ä¾‹: {val_positive_ratio:.4f}")
            logger.info(f"   - æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬, å¼‚å¸¸æ¯”ä¾‹: {test_positive_ratio:.4f}")
            logger.info(f"ğŸ¯ ä¼˜åŒ–ç›®æ ‡: å¬å›ç‡ä¼˜å…ˆçš„å¤šç›®æ ‡ä¼˜åŒ– (Lossè®¾è®¡ç‰ˆæœ¬: v2)")
            
            fmin(
                fn=objective,
                space=hyperopt_config,
                algo=tpe.suggest,
                max_evals=entity.max_evals,
                trials=trials,
                verbose=True
            )

            # ç¡®ä¿æœ€ä½³æ¨¡å‹å­˜åœ¨
            if best_model is None:
                logger.error("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³æ¨¡å‹")
                raise ValueError("è®­ç»ƒè¿‡ç¨‹ä¸­æœªèƒ½äº§ç”Ÿæœ‰æ•ˆæ¨¡å‹")

            # ä¸ºæœ€ä½³æ¨¡å‹æ·»åŠ å¿…è¦å±æ€§
            best_model.window = entity.windows_size
            best_model.freq = freq

            # æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°
            y_test_pred_final = best_model.predict(X_test)
            final_test_metrics = self.calculate_metrics(
                y_test, y_test_pred_final, subprefix='final_test')
            
            # è®¡ç®—æœ€ç»ˆéªŒè¯é›†F1åˆ†æ•°ç”¨äºè®°å½•
            y_val_pred_final = best_model.predict(X_val)
            final_val_metrics = self.calculate_metrics(
                y_val, y_val_pred_final, subprefix='final_val')
            val_f1 = final_val_metrics.get('final_val_f1', 0.0)

            # è¾“å‡ºæœ€ç»ˆè®­ç»ƒç»“æœæ€»ç»“
            logger.info(f"ğŸ† è®­ç»ƒå®Œæˆ! æœ€ç»ˆç»“æœæ€»ç»“:")
            logger.info(f"   ğŸ’ æœ€ä½³Loss: {best_loss:.6f}")
            logger.info(f"   ğŸ“ˆ éªŒè¯é›†æœ€ç»ˆè¡¨ç°:")
            logger.info(f"      - F1 Score: {val_f1:.4f}")
            logger.info(f"      - Recall: {final_val_metrics.get('final_val_recall', 0.0):.4f}")
            logger.info(f"      - Precision: {final_val_metrics.get('final_val_precision', 0.0):.4f}")
            logger.info(f"   ğŸ“Š æµ‹è¯•é›†æœ€ç»ˆè¡¨ç°:")
            logger.info(f"      - F1 Score: {final_test_metrics.get('final_test_f1', 0.0):.4f}")
            logger.info(f"      - Recall: {final_test_metrics.get('final_test_recall', 0.0):.4f}")
            logger.info(f"      - Precision: {final_test_metrics.get('final_test_precision', 0.0):.4f}")
            
            # æ€§èƒ½è¯„ä¼°å»ºè®®
            final_f1 = final_test_metrics.get('final_test_f1', 0.0)
            final_recall = final_test_metrics.get('final_test_recall', 0.0)
            final_precision = final_test_metrics.get('final_test_precision', 0.0)
            
            if final_f1 >= 0.8:
                logger.info(f"âœ… æ¨¡å‹æ€§èƒ½ä¼˜ç§€ (F1={final_f1:.4f})")
            elif final_f1 >= 0.6:
                logger.info(f"âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½ (F1={final_f1:.4f})")
            elif final_f1 >= 0.4:
                logger.info(f"âš ï¸  æ¨¡å‹æ€§èƒ½ä¸€èˆ¬ (F1={final_f1:.4f}) - å»ºè®®è°ƒä¼˜")
            else:
                logger.warning(f"âŒ æ¨¡å‹æ€§èƒ½è¾ƒå·® (F1={final_f1:.4f}) - éœ€è¦é‡æ–°è®¾è®¡")
                
            if final_recall < 0.5:
                logger.warning(f"âš ï¸  å¬å›ç‡åä½ (Recall={final_recall:.4f}) - å¯èƒ½å­˜åœ¨æ¼æ£€é£é™©")
                
            if final_precision < 0.3:
                logger.warning(f"âš ï¸  ç²¾ç¡®ç‡åä½ (Precision={final_precision:.4f}) - è¯¯æŠ¥ç‡è¾ƒé«˜")

            # è®°å½•æœ€ç»ˆæŒ‡æ ‡åˆ°MLflow
            for metric_name, metric_value in final_test_metrics.items():
                mlflow.log_metric(metric_name, metric_value)
            
            for metric_name, metric_value in final_val_metrics.items():
                mlflow.log_metric(metric_name, metric_value)

            # è®°å½•æ¨¡å‹é…ç½®å‚æ•°
            mlflow.log_param("windows_size", entity.windows_size)
            mlflow.log_param("feature_count", len(feature_columns))
            mlflow.log_param("frequency", freq)
            mlflow.log_param("train_samples", len(X_train))
            mlflow.log_param("val_samples", len(X_val))
            mlflow.log_param("test_samples", len(X_test))

            # è·å–æœ€ä½³å‚æ•°å¹¶è®°å½•
            best_trial = min(trials.trials, key=lambda x: x['result']['loss'])
            best_params = best_trial['misc']['vals']
            
            # è§£ææœ€ä½³å‚æ•°ï¼ˆå¤„ç†hyperoptçš„å‚æ•°æ ¼å¼ï¼‰
            for param_name, param_values in best_params.items():
                if param_values:  # éç©ºåˆ—è¡¨
                    param_value = param_values[0]  # hyperoptå°†å‚æ•°å­˜å‚¨ä¸ºåˆ—è¡¨
                    mlflow.log_param(f"best_{param_name}", param_value)

            # æ³¨å†Œæ¨¡å‹åˆ°MLflowæ¨¡å‹æ³¨å†Œè¡¨
            model_name = f"{entity.algorithm}_{entity.id}"
            logger.info(f"ğŸ“¦ æ­£åœ¨æ³¨å†Œæ¨¡å‹åˆ°MLflow: {model_name}")
            
            # æ³¨å†Œsklearnæ¨¡å‹
            registered_model = mlflow.sklearn.log_model(
                sk_model=best_model,
                registered_model_name=model_name,
                input_example=pd.DataFrame(
                    X_train, 
                    columns=feature_columns
                ).head(1)
            )
            
            # è·å–æ³¨å†Œåçš„æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯
            logger.info(f"âœ… æ¨¡å‹æ³¨å†ŒæˆåŠŸ!")
            logger.info(f"   ğŸ“‹ æ¨¡å‹åç§°: {model_name}")
            logger.info(f"   ğŸ“Š æœ€ç»ˆæ€§èƒ½: F1={final_f1:.4f}, Recall={final_recall:.4f}, Precision={final_precision:.4f}")
    